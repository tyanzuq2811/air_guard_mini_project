# ğŸ“Š So SÃ¡nh CÃ¡c Cáº¥u HÃ¬nh vÃ  Tham Sá»‘ - Parameter Comparison Analysis

> **YÃªu cáº§u 3:** Thá»±c nghiá»‡m so sÃ¡nh cÃ¡c tham sá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t cá»§a Semi-Supervised Learning

---

## ğŸ“‘ Navigation

| [â† Blog 1: Self-Training](BLOG_SELF_TRAINING.md) | [â† Blog 2: Co-Training](BLOG_CO_TRAINING.md) | [â†’ README](README.md) |
|:---:|:---:|:---:|

---

## Má»¥c Lá»¥c

1. [Tá»•ng Quan ThÃ­ Nghiá»‡m](#1-tá»•ng-quan-thÃ­-nghiá»‡m)
2. [ThÃ­ Nghiá»‡m 1: So SÃ¡nh NgÆ°á»¡ng Ï„](#2-thÃ­-nghiá»‡m-1-so-sÃ¡nh-ngÆ°á»¡ng-Ï„)
3. [ThÃ­ Nghiá»‡m 2: Labeled Data Size Comparison](#3-thÃ­-nghiá»‡m-2-labeled-data-size-comparison)
4. [ThÃ­ Nghiá»‡m 3: Model Architecture Comparison](#4-thÃ­-nghiá»‡m-3-model-architecture-comparison)
5. [ThÃ­ Nghiá»‡m 4: Hybrid Ï„ Schedule](#5-thÃ­-nghiá»‡m-4-hybrid-Ï„-schedule)
6. [ThÃ­ Nghiá»‡m 5: View Splitting Strategies](#6-thÃ­-nghiá»‡m-5-view-splitting-strategies)
7. [Cross-Experiment Insights](#7-cross-experiment-insights)
8. [Káº¿t Luáº­n](#8-káº¿t-luáº­n)

---

## 1. Tá»•ng Quan ThÃ­ Nghiá»‡m

### Má»¥c ÄÃ­ch

So sÃ¡nh **tÃ¡c Ä‘á»™ng cá»§a cÃ¡c tham sá»‘** Ä‘áº¿n hiá»‡u nÄƒng semi-supervised learning:
- **Báº¯t buá»™c:** Thay Ä‘á»•i ngÆ°á»¡ng confidence Ï„
- **Má»Ÿ rá»™ng:** Labeled data size, model architecture, view splitting

### Thiáº¿t Láº­p Chung

| Tham Sá»‘ | GiÃ¡ Trá»‹ Cá»‘ Äá»‹nh |
|---------|-----------------|
| **Dataset** | Beijing Air Quality (420K records) |
| **Labeled Fraction** | 5% (~20K samples) |
| **Cutoff Date** | 2017-01-01 (time-aware split) |
| **Model** | HistGradientBoostingClassifier |
| **Max Iterations** | 10 vÃ²ng |
| **Validation Fraction** | 20% of labeled data |

---

## 2. ThÃ­ Nghiá»‡m 1: So SÃ¡nh NgÆ°á»¡ng Ï„

### 2.1. Giáº£ Thuyáº¿t

**NgÆ°á»¡ng Ï„ cao** (0.95):
- Chá»n Ã­t pseudo-labels nhÆ°ng **cháº¥t lÆ°á»£ng cao**
- TÄƒng precision, giáº£m recall
- Ãt confirmation bias

**NgÆ°á»¡ng Ï„ tháº¥p** (0.80):
- Chá»n nhiá»u pseudo-labels hÆ¡n
- TÄƒng recall nhÆ°ng cÃ³ nhiá»…u
- Nguy cÆ¡ confirmation bias cao hÆ¡n

### 2.2. Káº¿t Quáº£ Self-Training

#### Test Performance Comparison

![Test Performance](./data/processed/self_training_experiments/test_performance_comparison.png)

| NgÆ°á»¡ng Ï„ | Test Accuracy | Test F1-macro | Tá»•ng Pseudo-Labels | % Unlabeled Used |
|----------|---------------|---------------|--------------------|------------------|
| **0.80** | **0.5941** | 0.5167 | 364,388 | 94.8% |
| **0.90** | 0.5890 | **0.5343** | 350,019 | 91.1% |
| **0.95** | 0.5931 | 0.5330 | 314,834 | 81.9% |
| *Baseline* | 0.6022 | 0.4715 | 0 | 0% |

#### Pseudo-Labels Dynamics

![Pseudo-labels Over Iterations](./data/processed/self_training_experiments/pseudo_labels_over_iterations.png)

| NgÆ°á»¡ng Ï„ | VÃ²ng 1 | VÃ²ng 5 | VÃ²ng 10 | Xu hÆ°á»›ng |
|----------|--------|--------|---------|----------|
| **0.80** | 67,948 | 12,095 | 193 | Giáº£m máº¡nh |
| **0.90** | 76,361 | 10,766 | 202 | Giáº£m á»•n Ä‘á»‹nh |
| **0.95** | 50,993 | 11,437 | 304 | Giáº£m cháº­m |

#### Validation F1-macro

![Validation F1 Over Iterations](./data/processed/self_training_experiments/validation_f1_over_iterations.png)

| NgÆ°á»¡ng Ï„ | Val F1 VÃ²ng 1 | Val F1 Peak | VÃ²ng Peak | Val F1 Cuá»‘i |
|----------|---------------|-------------|-----------|-------------|
| **0.80** | 0.6721 | 0.7081 | 2 | 0.6621 |
| **0.90** | 0.6783 | **0.7106** | 2 | 0.6176 |
| **0.95** | 0.6659 | 0.6953 | 2 | 0.5950 |

### 2.3. PhÃ¢n TÃ­ch Chi Tiáº¿t

#### So SÃ¡nh Per-Class F1

| Lá»›p AQI | Baseline | Ï„=0.80 | Ï„=0.90 | Ï„=0.95 | Nháº­n xÃ©t |
|---------|----------|--------|--------|--------|----------|
| **Good** | 0.4617 | 0.4695 | **0.4897** | 0.4853 | Ï„=0.90 tá»‘t nháº¥t |
| **Moderate** | 0.6704 | 0.6810 | **0.7045** | 0.6965 | Ï„=0.90 vÆ°á»£t trá»™i |
| **Unhealthy_for_Sensitive** | 0.1193 | 0.1278 | **0.1789** | 0.1639 | Cáº£i thiá»‡n máº¡nh (+50%) |
| **Unhealthy** | 0.5875 | 0.5878 | 0.5877 | **0.5941** | á»”n Ä‘á»‹nh |
| **Very_Unhealthy** | 0.5115 | 0.5402 | **0.5689** | 0.5619 | Ï„=0.90 cao nháº¥t |
| **Hazardous** | 0.6582 | 0.6739 | **0.6762** | 0.6761 | Táº¥t cáº£ tá»‘t |

**PhÃ¡t hiá»‡n quan trá»ng:**
- **Ï„=0.90 tá»‘t nháº¥t** cho F1-macro (+13.3% vs baseline)
- **Ï„=0.80**: Accuracy cao nháº¥t nhÆ°ng F1 tháº¥p hÆ¡n (do nhiá»u pseudo-labels cÃ³ nhiá»…u)
- **Ï„=0.95**: Balanced nhÆ°ng khÃ´ng tá»‘i Æ°u
- **Lá»›p thiá»ƒu sá»‘** (Unhealthy_for_Sensitive) hÆ°á»Ÿng lá»£i nhiá»u nháº¥t tá»« self-training

### 2.4. Nháº­n XÃ©t SÃ¢u

#### Trade-off: Quantity vs Quality

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ï„=0.80: 364K pseudo-labels â†’ F1=0.5167            â”‚
â”‚          â†“ Nhiá»u nhÆ°ng á»“n                           â”‚
â”‚                                                      â”‚
â”‚  Ï„=0.90: 350K pseudo-labels â†’ F1=0.5343 â­         â”‚
â”‚          â†“ Sweet spot                               â”‚
â”‚                                                      â”‚
â”‚  Ï„=0.95: 315K pseudo-labels â†’ F1=0.5330            â”‚
â”‚          â†“ Ãt hÆ¡n, Ã­t cáº£i thiá»‡n                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Confirmation Bias Observation

**Táº¥t cáº£ Ï„ values Ä‘á»u peak á»Ÿ vÃ²ng 2:**
- Val F1 cao nháº¥t vÃ²ng 1-2
- Sau Ä‘Ã³ giáº£m dáº§n (overfitting/confirmation bias)
- **Khuyáº¿n nghá»‹:** Early stopping á»Ÿ vÃ²ng 5

#### Ï„ QuÃ¡ Tháº¥p (0.70, 0.80)

**Váº¥n Ä‘á»:**
- ThÃªm quÃ¡ nhiá»u pseudo-labels cÃ³ confidence tháº¥p
- Noise tÃ­ch lÅ©y, lÃ m giáº£m F1
- Accuracy cao giáº£ táº¡o (bias vá» lá»›p Ä‘a sá»‘)

**VÃ­ dá»¥ tá»« Ï„=0.80:**
- VÃ²ng 1: ThÃªm 67,948 samples (17.7% pool!)
- NhÆ°ng F1 cuá»‘i chá»‰ 0.5167 (tháº¥p nháº¥t)

#### Ï„ QuÃ¡ Cao (0.95)

**Váº¥n Ä‘á»:**
- QuÃ¡ conservative, bá» lá»¡ nhiá»u unlabeled data tá»‘t
- Chá»‰ dÃ¹ng 81.9% pool
- KhÃ´ng tá»‘i Æ°u hÃ³a háº¿t potential

**VÃ­ dá»¥:**
- VÃ²ng 1: Chá»‰ 50,993 samples (13.3% pool)
- F1 cuá»‘i 0.5330 (tá»‘t nhÆ°ng khÃ´ng optimal)

#### Ï„ Tá»‘i Æ¯u (0.90)

**LÃ½ do tá»‘t:**
- Balance giá»¯a quantity (350K) vÃ  quality
- Sá»­ dá»¥ng 91.1% unlabeled pool
- F1-macro cao nháº¥t 0.5343
- Cáº£i thiá»‡n Ä‘á»u cáº£ 6 lá»›p, Ä‘áº·c biá»‡t lá»›p thiá»ƒu sá»‘

---

## 3. PhÃ¢n TÃ­ch Trade-offs

### 3.1. Accuracy vs F1-macro

**Quan sÃ¡t:**
```
Ï„=0.80: Accuracy=0.5941 (cao nháº¥t), F1=0.5167 (tháº¥p nháº¥t)
Ï„=0.90: Accuracy=0.5890,           F1=0.5343 (cao nháº¥t)
```

**Giáº£i thÃ­ch:**
- Ï„ tháº¥p â†’ Bias vá» lá»›p Ä‘a sá»‘ â†’ Accuracy cao giáº£
- F1-macro nháº¡y hÆ¡n vá»›i lá»›p thiá»ƒu sá»‘
- **NÃªn chá»n theo F1 khÃ´ng pháº£i Accuracy**

### 3.2. Pseudo-Labels Count vs Performance

| Metric | Ï„=0.80 | Ï„=0.90 | Ï„=0.95 |
|--------|--------|--------|--------|
| Pseudo-labels | 364,388 (nhiá»u nháº¥t) | 350,019 | 314,834 (Ã­t nháº¥t) |
| F1-macro | 0.5167 (tháº¥p nháº¥t) | **0.5343** (cao nháº¥t) | 0.5330 |
| Efficiency | 0.70/K | **0.88/K** | 0.92/K |

**Efficiency = F1 gain per 1000 pseudo-labels**

**Káº¿t luáº­n:**
- KhÃ´ng pháº£i cÃ ng nhiá»u pseudo-labels cÃ ng tá»‘t
- Quality > Quantity
- Ï„=0.90 cÃ³ efficiency tá»‘t nháº¥t

### 3.3. Iteration Dynamics

**Pattern chung:**
- VÃ²ng 1-2: Val F1 tÄƒng máº¡nh (há»c tá»« pseudo-labels cháº¥t lÆ°á»£ng cao)
- VÃ²ng 3-5: Dao Ä‘á»™ng (báº¯t Ä‘áº§u confirmation bias)
- VÃ²ng 6-10: Giáº£m dáº§n (overfitting)

**Early stopping recommendation:**
```python
if val_f1_current < val_f1_peak - 0.05:
    stop_training()
# ThÆ°á»ng xáº£y ra á»Ÿ vÃ²ng 5-6
```

---

## 3. ThÃ­ Nghiá»‡m 2: Labeled Data Size Comparison

### 3.1. Má»¥c TiÃªu

Tráº£ lá»i cÃ¢u há»i: **"Khi nÃ o self-training cÃ²n hiá»‡u quáº£?"**
- So sÃ¡nh 3 má»©c labeled data: **5%, 10%, 20%**
- TÃ¬m Ä‘iá»ƒm **diminishing return** (thÃªm labeled data khÃ´ng cÃ²n cáº£i thiá»‡n nhiá»u)

### 3.2. Káº¿t Quáº£ Thá»±c Nghiá»‡m

| Labeled % | Test Accuracy | Test F1-macro | Pseudo-labels | F1 Improvement |
|:---------:|:-------------:|:-------------:|:-------------:|:--------------:|
| **5%**    | 0.5633        | **0.4671**    | 344,688       | 0.0% (baseline)|
| **10%**   | **0.5678**    | **0.5050**    | 346,372       | **+8.12%** âœ…  |
| **20%**   | **0.5759**    | 0.4896        | 357,913       | +4.82%         |

### 3.3. Biá»ƒu Äá»“ Trá»±c Quan

![Test Performance Comparison](data/processed/labeled_size_experiments/test_performance_comparison.png)
*HÃ¬nh 3.1: So sÃ¡nh Test Accuracy vÃ  F1-macro theo kÃ­ch thÆ°á»›c labeled data*

![Learning Curves](data/processed/labeled_size_experiments/learning_curves.png)
*HÃ¬nh 3.2: ÄÆ°á»ng cong há»c validation - Quan sÃ¡t quÃ¡ trÃ¬nh há»c cá»§a má»—i cáº¥u hÃ¬nh*

![Pseudo-labels Comparison](data/processed/labeled_size_experiments/pseudo_labels_comparison.png)
*HÃ¬nh 3.3: Sá»‘ lÆ°á»£ng pseudo-labels Ä‘Æ°á»£c thÃªm vÃ o má»—i cáº¥u hÃ¬nh*

![Training Data Composition](data/processed/labeled_size_experiments/training_data_composition.png)
*HÃ¬nh 3.4: ThÃ nh pháº§n dá»¯ liá»‡u training (Labeled gá»‘c vs Pseudo-labeled)*

### 3.4. PhÃ¡t Hiá»‡n ChÃ­nh

#### 1. **10% Labeled = Sweet Spot** âœ…
- **Highest F1-macro**: 0.5050 (+8.12% vs 5% baseline)
- **Best balance**: Äá»§ labeled data Ä‘á»ƒ model há»c patterns tá»‘t + Ä‘á»§ unlabeled Ä‘á»ƒ scale
- **Stable learning**: Val F1 curves á»•n Ä‘á»‹nh, khÃ´ng oscillate

#### 2. **5% Labeled: Model Yáº¿u NhÆ°ng Self-Training Váº«n Hoáº¡t Äá»™ng**
- Accuracy tháº¥p nháº¥t (0.5633) nhÆ°ng váº«n **thÃªm Ä‘Æ°á»£c 344K pseudo-labels**
- Model base quÃ¡ yáº¿u â†’ pseudo-labels cháº¥t lÆ°á»£ng tháº¥p â†’ limited improvement
- **Insight**: Self-training cáº§n minimum quality cá»§a base model

#### 3. **20% Labeled: Diminishing Return** ğŸ“‰
- Accuracy cao nháº¥t (0.5759) nhÆ°ng **F1-macro giáº£m** (0.4896)
- **Overfitting risk**: Model quÃ¡ confident vá»›i labeled data â†’ Ã­t há»c tá»« unlabeled
- **Trade-off**: Accuracy tá»‘t nhÆ°ng per-class balance kÃ©m (F1 tháº¥p hÆ¡n 10%)

#### 4. **Pseudo-labeling Activity**
- 5%: 344,688 labels (baseline)
- 10%: 346,372 labels (+0.5% vs 5%)
- 20%: 357,913 labels (+3.8% vs 5%)
- **Pattern**: CÃ ng nhiá»u labeled data, model cÃ ng confident â†’ thÃªm nhiá»u pseudo-labels hÆ¡n

### 3.5. BÃ i Há»c Kinh Nghiá»‡m

1. **Nhiá»u Labeled â‰  F1 Cao HÆ¡n**: 10% Ä‘áº¡t F1 cao nháº¥t, khÃ´ng pháº£i 20%
2. **CÃ¢n Báº±ng LÃ  ChÃ¬a KhÃ³a**: 10% cÃ³ sá»± cÃ¢n báº±ng tá»‘t giá»¯a Ä‘á»™ máº¡nh model vÃ  khai thÃ¡c unlabeled data
3. **Máº¥t CÃ¢n Báº±ng Lá»›p**: 20% cÃ³ accuracy cao nhÆ°ng F1 tháº¥p â†’ má»™t sá»‘ class khÃ´ng Ä‘Æ°á»£c há»c tá»‘t
4. **YÃªu Cáº§u Self-training**: Cáº§n Ã­t nháº¥t ~1-2% labeled data Ä‘á»ƒ base model Ä‘áº¡t má»©c tá»‘i thiá»ƒu

---

## 4. ThÃ­ Nghiá»‡m 3: Model Architecture Comparison

### 4.1. Má»¥c TiÃªu

So sÃ¡nh 2 kiáº¿n trÃºc model khÃ¡c nhau trong self-training:
- **HistGradientBoostingClassifier** (Gradient Boosting)
- **RandomForestClassifier** (Bagging Ensemble)

### 4.2. Káº¿t Quáº£ Thá»±c Nghiá»‡m

| Model | Test Accuracy | Test F1-macro | Pseudo-labels | Val F1 Peak |
|:------|:-------------:|:-------------:|:-------------:|:-----------:|
| **HGBC** âœ…     | **0.5682**    | **0.4919**    | 345,924       | **0.6673**  |
| **RandomForest** | 0.5628        | 0.4130        | 180,363       | 0.5653      |

**Winner**: HistGradientBoostingClassifier (HGBC) ğŸ†
- **+0.54% accuracy** vs RandomForest
- **+19.1% F1-macro** vs RandomForest (significant!)
- **+91.8% pseudo-labels** (345K vs 180K)

### 4.3. Biá»ƒu Äá»“ Trá»±c Quan

![Test Performance by Model](data/processed/model_comparison_experiments/test_performance_by_model.png)
*HÃ¬nh 4.1: So sÃ¡nh Test Accuracy vÃ  F1-macro giá»¯a 2 models*

![Learning Curves by Model](data/processed/model_comparison_experiments/learning_curves_by_model.png)
*HÃ¬nh 4.2: ÄÆ°á»ng cong há»c validation - HGBC á»•n Ä‘á»‹nh, RandomForest plateau sá»›m*

![Pseudo-labeling Activity](data/processed/model_comparison_experiments/pseudo_labeling_by_model.png)
*HÃ¬nh 4.3: Tá»•ng pseudo-labels Ä‘Æ°á»£c thÃªm - HGBC gáº¥p Ä‘Ã´i RandomForest*

![Per-class F1 Heatmap](data/processed/model_comparison_experiments/per_class_f1_heatmap.png)
*HÃ¬nh 4.4: Báº£n Ä‘á»“ nhiá»‡t F1-score tá»«ng lá»›p - HGBC Ä‘á»“ng Ä‘á»u hÆ¡n RandomForest*

### 4.4. PhÃ¡t Hiá»‡n ChÃ­nh

#### 1. **HGBC >> RandomForest trong Self-Training** ğŸ†
- **F1-macro gap**: 0.4919 vs 0.4130 (**+19.1%** - massive difference!)
- **Why?**: Gradient Boosting â†’ better probability calibration â†’ pseudo-labels cháº¥t lÆ°á»£ng cao hÆ¡n
- **Confidence**: HGBC thÃªm 345K labels vs RandomForest chá»‰ 180K

#### 2. **RandomForest: Too Conservative**
- **Problem**: Overconfident predictions BUT low Ï„ pass rate
- **Behavior**: Chá»‰ thÃªm 180K pseudo-labels (52% Ã­t hÆ¡n HGBC)
- **Learning plateau**: Val F1 peak = 0.5653, sá»›m hÆ¡n HGBC (0.6673)
- **Insight**: RandomForest probabilities khÃ´ng calibrated tá»‘t cho self-training

#### 3. **Learning Trajectory**
- **HGBC**: Smooth learning curve, Val F1 tÄƒng Ä‘á»u Ä‘áº¿n iteration 8-9
- **RandomForest**: Plateau sá»›m sau iteration 5-6, improvement minimal
- **Implication**: HGBC táº­n dá»¥ng unlabeled data tá»‘t hÆ¡n qua nhiá»u iterations

#### 4. **Per-Class Performance**
- **HGBC**: F1 consistent across classes (0.35-0.55 range)
- **RandomForest**: Biased towards majority classes, minority classes F1 < 0.30
- **Balance**: HGBC tá»‘t hÆ¡n cho imbalanced dataset

### 4.5. BÃ i Há»c Kinh Nghiá»‡m

1. **Kiáº¿n TrÃºc Model Quan Trá»ng**: Gradient Boosting >> Bagging cho self-training
2. **Hiá»‡u Chuáº©n XÃ¡c Suáº¥t Cá»±c Ká»³ Quan Trá»ng**: HGBC Ä‘Æ°á»£c hiá»‡u chuáº©n â†’ pseudo-labels tá»± tin hÆ¡n
3. **Háº¡n Cháº¿ RandomForest**: QuÃ¡ tá»± tin NHÆ¯NG khÃ´ng vÆ°á»£t qua ngÆ°á»¡ng Ï„ â†’ Ã­t pseudo-labels
4. **CÃ¢n Báº±ng Lá»›p**: HGBC xá»­ lÃ½ máº¥t cÃ¢n báº±ng tá»‘t hÆ¡n RandomForest
5. **Bá» Qua XGBoost**: TÆ°Æ¡ng tá»± HGBC (cÃ¹ng gradient boosting) â†’ bá» Ä‘á»ƒ tiáº¿t kiá»‡m thá»i gian

---

## 5. ThÃ­ Nghiá»‡m 4: Hybrid Ï„ Schedule

### 5.1. Má»¥c TiÃªu

Test adaptive confidence threshold:
- **Fixed 0.90**: Constant Ï„ = 0.90 (baseline)
- **Aggressive**: Fast decay tá»« 0.95 â†’ 0.80 (extreme adaptive)

**Giáº£ thuyáº¿t**: Early strict (Ï„=0.95) trÃ¡nh confirmation bias, later relaxed (Ï„=0.80) maximize unlabeled usage

### 5.2. Káº¿t Quáº£ Thá»±c Nghiá»‡m

| Schedule | Test Accuracy | Test F1-macro | Pseudo-labels | Val F1 Peak | Avg Ï„ |
|:---------|:-------------:|:-------------:|:-------------:|:-----------:|:-----:|
| **Aggressive** âœ… | **0.5689**    | **0.5088**    | **370,727**   | 0.6673      | 0.83  |
| **Fixed 0.90**    | 0.5682        | 0.4919        | 345,924       | 0.6673      | 0.90  |

**Winner**: Aggressive Schedule ğŸ†
- **+0.07% accuracy** (marginal)
- **+3.44% F1-macro** (+0.0168 absolute)
- **+7.2% pseudo-labels** (370K vs 346K)

### 5.3. Biá»ƒu Äá»“ Trá»±c Quan

![Tau Schedules](data/processed/hybrid_tau_experiments/tau_schedules.png)
*HÃ¬nh 5.1: Lá»‹ch trÃ¬nh Ï„ qua 10 vÃ²ng láº·p - Fixed (cá»‘ Ä‘á»‹nh) vs Aggressive (giáº£m dáº§n)*

![Test Performance by Schedule](data/processed/hybrid_tau_experiments/test_performance_by_schedule.png)
*HÃ¬nh 5.2: So sÃ¡nh Test Accuracy vÃ  F1-macro*

![Validation Curves](data/processed/hybrid_tau_experiments/validation_curves_by_schedule.png)
*HÃ¬nh 5.3: ÄÆ°á»ng cong há»c validation - Aggressive hÆ¡i tá»‘t hÆ¡n*

![Pseudo-labeling Activity](data/processed/hybrid_tau_experiments/pseudo_labeling_activity.png)
*HÃ¬nh 5.4: Pseudo-labels Ä‘Æ°á»£c thÃªm má»—i vÃ²ng - Aggressive tÄƒng máº¡nh á»Ÿ vÃ²ng sau*

![Total Pseudo-labels](data/processed/hybrid_tau_experiments/total_pseudo_labels.png)
*HÃ¬nh 5.5: Tá»•ng pseudo-labels tÃ­ch lÅ©y qua 10 vÃ²ng láº·p*

![Tau-Performance Correlation](data/processed/hybrid_tau_experiments/tau_performance_correlation.png)
*HÃ¬nh 5.6: TÆ°Æ¡ng quan giá»¯a giÃ¡ trá»‹ Ï„ vÃ  hiá»‡u suáº¥t model*

### 5.4. PhÃ¡t Hiá»‡n ChÃ­nh

#### 1. **Aggressive Schedule Wins (NhÆ°ng Cáº£i Thiá»‡n Nhá»)** âœ…
- **F1 improvement**: +3.44% vs Fixed 0.90
- **Accuracy gap**: +0.07% (marginal, trong margin of error)
- **Pseudo-labels**: +7.2% (24,803 more labels)
- **Conclusion**: Adaptive Ï„ cÃ³ lá»£i NHÆ¯NG khÃ´ng pháº£i game-changer

#### 2. **Early Strict â†’ Later Relaxed Strategy Works**
- **Iterations 1-3** (Ï„=0.95-0.90): Ãt pseudo-labels (~20-30K/iter) â†’ High quality
- **Iterations 4-10** (Ï„=0.85-0.80): Nhiá»u pseudo-labels (~40-50K/iter) â†’ Scale up
- **Benefit**: TrÃ¡nh confirmation bias early, maximize data usage later

#### 3. **Val F1 Peak Identical (0.6673)**
- Cáº£ 2 schedules Ä‘áº¡t cÃ¹ng Val F1 peak
- **Implication**: Upper bound performance giá»‘ng nhau, chá»‰ khÃ¡c tá»‘c Ä‘á»™ Ä‘áº¡t Ä‘Æ°á»£c
- Aggressive Ä‘áº¡t peak sá»›m hÆ¡n 1-2 iterations

#### 4. **Diminishing Return of Low Ï„**
- Ï„=0.80 (iterations 6-10) thÃªm nhiá»u labels NHÆ¯NG Test F1 chá»‰ tÄƒng nháº¹
- **Risk**: Ï„ quÃ¡ tháº¥p â†’ pseudo-labels noise tÄƒng â†’ limited benefit
- **Sweet spot**: Ï„=0.85-0.90 range

#### 5. **Pseudo-labeling Pattern**
- **Fixed 0.90**: Uniform ~34-35K labels/iteration
- **Aggressive**: Ramp up tá»« 20K â†’ 50K/iteration
- **Total gap**: 370K vs 346K (+7%)

### 5.5. BÃ i Há»c Kinh Nghiá»‡m

1. **Adaptive Ï„ Há»¯u Ãch NhÆ°ng KhÃ´ng Cá»±c Ká»³ Quan Trá»ng**: +3.4% cáº£i thiá»‡n F1 - nÃªn cÃ³, khÃ´ng báº¯t buá»™c
2. **Chiáº¿n LÆ°á»£c Báº£o Thá»§ Ban Äáº§u Há»£p LÃ½**: Ï„=0.95 á»Ÿ vÃ²ng Ä‘áº§u trÃ¡nh pseudo-labels xáº¥u
3. **Ï„=0.90 LÃ  Máº·c Äá»‹nh Tá»‘t**: Fixed 0.90 hiá»‡u suáº¥t tá»‘t, Ä‘Æ¡n giáº£n vÃ  á»•n Ä‘á»‹nh
4. **Rá»§i Ro Ï„ QuÃ¡ Tháº¥p**: Ï„=0.80 thÃªm nhiá»u labels nhÆ°ng nhiá»…u tÄƒng
5. **Chi PhÃ­ Triá»ƒn Khai**: Lá»‹ch trÃ¬nh adaptive phá»©c táº¡p hÆ¡n, lá»£i Ã­ch nhá» â†’ ROI tháº¥p

---

## 6. PhÃ¢n TÃ­ch LiÃªn ThÃ­ Nghiá»‡m

### 6.1. Xáº¿p Háº¡ng Hiá»‡u Suáº¥t Tá»•ng Thá»ƒ

**Theo Test F1-macro (Metric ChÃ­nh):**

1. **10% Labeled + HGBC + Aggressive Ï„**: F1 = **0.5088** ğŸ¥‡
2. **10% Labeled + HGBC + Fixed Ï„**: F1 = 0.5050
3. **5% Labeled + HGBC + Aggressive Ï„**: F1 = 0.4919
4. **20% Labeled + HGBC**: F1 = 0.4896
5. **5% Labeled + HGBC + Fixed Ï„**: F1 = 0.4671
6. **5% Labeled + RandomForest**: F1 = 0.4130

### 6.2. Äiá»ƒm ChÃ­nh Cáº§n Ghi Nhá»›

#### 1. **KÃ­ch ThÆ°á»›c Labeled Data: 10% LÃ  Tá»‘i Æ¯u** â­
- **NgÆ°á»i chiáº¿n tháº¯ng rÃµ rÃ ng**: 10% labeled data Ä‘áº¡t F1-macro cao nháº¥t
- **LÃ½ do**: CÃ¢n báº±ng giá»¯a Ä‘á»™ máº¡nh model vÃ  khai thÃ¡c unlabeled data
- **Thá»±c táº¿**: Vá»›i dataset 420K máº«u, chá»‰ cáº§n ~2K máº«u cÃ³ nhÃ£n

#### 2. **Kiáº¿n TrÃºc Model: HGBC >> RandomForest** â­â­â­
- **Yáº¿u tá»‘ áº£nh hÆ°á»Ÿng lá»›n nháº¥t**: Lá»±a chá»n model quan trá»ng hÆ¡n kÃ­ch thÆ°á»›c labeled vÃ  lá»‹ch trÃ¬nh Ï„
- **Khoáº£ng cÃ¡ch F1**: +19.1% (0.4919 vs 0.4130) - KHÃC BIá»†T KHá»”NG Lá»’
- **NguyÃªn nhÃ¢n**: Gradient Boosting â†’ hiá»‡u chuáº©n xÃ¡c suáº¥t tá»‘t hÆ¡n â†’ pseudo-labels cháº¥t lÆ°á»£ng cao hÆ¡n

#### 3. **Adaptive Ï„: NÃªn CÃ³, KhÃ´ng Báº¯t Buá»™c** â­
- **Lá»£i Ã­ch nhá»**: +3.4% cáº£i thiá»‡n F1
- **Äá»™ phá»©c táº¡p**: Cáº§n Ä‘iá»u chá»‰nh lá»‹ch trÃ¬nh
- **Khuyáº¿n nghá»‹**: Báº¯t Ä‘áº§u vá»›i Fixed Ï„=0.90, tá»‘i Æ°u sau náº¿u cáº§n

#### 4. **Cháº¥t LÆ°á»£ng Pseudo-labeling > Sá»‘ LÆ°á»£ng**
- **RandomForest**: 180K nhÃ£n â†’ F1 = 0.4130
- **HGBC**: 346K nhÃ£n â†’ F1 = 0.4919
- **BÃ i há»c**: ThÃªm nhiá»u pseudo-labels khÃ´ng Ä‘áº£m báº£o hiá»‡u suáº¥t tá»‘t

#### 5. **Hiá»‡u Quáº£ Giáº£m Dáº§n LÃ  Tháº­t**
- 5% â†’ 10%: **+8.1% F1** cáº£i thiá»‡n âœ…
- 10% â†’ 20%: **-3.1% F1** giáº£m âŒ
- **HÃ m Ã½**: KhÃ´ng pháº£i cÃ ng nhiá»u labeled data cÃ ng tá»‘t

---

## 6. ThÃ­ Nghiá»‡m 5: View Splitting Strategies

### 6.1. Má»¥c TiÃªu ThÃ­ Nghiá»‡m

**CÃ¢u há»i nghiÃªn cá»©u**: Chiáº¿n lÆ°á»£c chia views nhÆ° tháº¿ nÃ o tá»‘i Æ°u cho Co-Training?

**Giáº£ thuyáº¿t**: Views Ä‘á»™c láº­p hÆ¡n â†’ predictions Ä‘a dáº¡ng hÆ¡n â†’ pseudo-labels cháº¥t lÆ°á»£ng cao hÆ¡n

**Strategies Ä‘Æ°á»£c test**:
- **Current**: Chia 41 features tÃ¹y Ã½ (View1: 41 features, View2: 10 features, Overlap: 0 â†’ Independence: 100%)
- **Pollutant-based**: Primary pollutants (PM2.5, PM10, SO2, CO) vs Secondary pollutants (NO2, O3) + meteorological (View1: 36 features, View2: 30 features, Overlap: 20 â†’ Independence: 33.3%)

**Cáº¥u hÃ¬nh cá»‘ Ä‘á»‹nh**:
- **Labeled data**: 10% (optimal tá»« thÃ­ nghiá»‡m 1)
- **Model**: HistGradientBoostingClassifier (best tá»« thÃ­ nghiá»‡m 2)
- **Ï„**: 0.90 (Fixed)
- **Iterations**: 10, **Max pseudo/iter**: 500

### 6.2. Káº¿t Quáº£ Thá»±c Nghiá»‡m

| Strategy | View1 | View2 | Overlap | Independence | Test Acc | Test F1-macro | Pseudo-labels |
|:---------|:-----:|:-----:|:-------:|:------------:|:--------:|:-------------:|:-------------:|
| **Pollutant-based** âœ… | 36 | 30 | 20 | **33.3%** | **0.5718** | **0.4507** | 5,000 |
| **Current** | 41 | 10 | 0 | **100.0%** | 0.5401 | 0.4176 | 5,000 |

**Winner**: Pollutant-based Strategy ğŸ†
- **+3.17% accuracy** (+0.0317 absolute)
- **+7.94% F1-macro** (+0.0332 absolute)
- **Views cÃ³ nghÄ©a hÆ¡n**: PhÃ¢n chia dá»±a trÃªn domain knowledge (hÃ³a há»c khÃ­ quyá»ƒn)

**âš ï¸ Critical Finding: Co-Training < Self-Training**

| Approach | Test F1-macro | Improvement |
|:---------|:-------------:|:-----------:|
| **Self-Training** (baseline) | **0.5343** | - |
| **Co-Training (Pollutant-based)** | 0.4507 | **-15.6%** âŒ |
| **Co-Training (Current)** | 0.4176 | **-21.8%** âŒ |

**Conclusion**: Cáº£ 2 chiáº¿n lÆ°á»£c Co-Training Ä‘á»u **WORSE** than Self-Training baseline!

### 6.3. Biá»ƒu Äá»“ Trá»±c Quan

![Test Performance by Strategy](data/processed/view_splitting_experiments/test_performance_by_strategy.png)
*HÃ¬nh 6.1: So sÃ¡nh hiá»‡u suáº¥t test giá»¯a 2 strategies - Pollutant-based tá»‘t hÆ¡n*

![Learning Curves by Strategy](data/processed/view_splitting_experiments/learning_curves_by_strategy.png)
*HÃ¬nh 6.2: ÄÆ°á»ng cong há»c validation qua 10 vÃ²ng láº·p*

![View Independence Analysis](data/processed/view_splitting_experiments/view_independence_analysis.png)
*HÃ¬nh 6.3: PhÃ¢n tÃ­ch Ä‘á»™ Ä‘á»™c láº­p giá»¯a 2 views - Current 100% vs Pollutant-based 33.3%*

![Comparison with Baseline](data/processed/view_splitting_experiments/comparison_with_baseline.png)
*HÃ¬nh 6.4: So sÃ¡nh vá»›i Self-Training baseline - Co-Training kÃ©m hÆ¡n 15.6%*

### 6.4. PhÃ¡t Hiá»‡n ChÃ­nh

#### 1. **Pollutant-based > Current (NhÆ°ng Váº«n Thua Self-Training)** âš ï¸
- **So sÃ¡nh internal**: Pollutant-based tá»‘t hÆ¡n Current strategy (+7.94% F1)
- **So sÃ¡nh external**: Cáº£ 2 Ä‘á»u thua Self-Training baseline (âˆ’15.6% vÃ  âˆ’21.8%)
- **NguyÃªn nhÃ¢n**: View splitting lÃ m giáº£m thÃ´ng tin cho má»—i model

#### 2. **View Independence KhÃ´ng Pháº£i LuÃ´n Tá»‘t** âŒ
- **Current**: 100% independence â†’ F1 = 0.4176 (worst)
- **Pollutant-based**: 33.3% independence â†’ F1 = 0.4507 (better, but still worse than self-training)
- **BÃ i há»c**: Views quÃ¡ Ä‘á»™c láº­p â†’ má»—i model thiáº¿u context â†’ predictions kÃ©m

#### 3. **Domain Knowledge Helps (NhÆ°ng ChÆ°a Äá»§)**
- **Pollutant-based**: Dá»±a trÃªn hÃ³a há»c khÃ­ quyá»ƒn (Primary vs Secondary pollutants)
  - Primary pollutants: PM2.5, PM10, SO2, CO (trá»±c tiáº¿p tá»« nguá»“n tháº£i)
  - Secondary pollutants: NO2, O3 (hÃ¬nh thÃ nh tá»« pháº£n á»©ng hÃ³a há»c)
- **Lá»£i Ã­ch**: Views cÃ³ nghÄ©a â†’ F1 tá»‘t hÆ¡n Current
- **Háº¡n cháº¿**: Váº«n khÃ´ng Ä‘á»§ Ä‘á»ƒ vÆ°á»£t Self-Training

#### 4. **Co-Training Underperforms on This Dataset**
- **Reasons**:
  1. **Feature overlap cáº§n thiáº¿t**: Beijing Air Quality features highly correlated
  2. **Split lÃ m máº¥t thÃ´ng tin**: Má»—i view thiáº¿u features quan trá»ng
  3. **Agreement mechanism yáº¿u**: 2 models khÃ´ng Ä‘á»§ diverse Ä‘á»ƒ correct láº«n nhau
- **Evidence**: Cáº£ 2 strategies Ä‘á»u thua Self-Training 15-22%

#### 5. **Pseudo-labeling Activity Giá»‘ng Nhau**
- **Both strategies**: 5,000 pseudo-labels sau 10 vÃ²ng (500/iter)
- **Max reached**: Cáº£ 2 Ä‘á»u Ä‘áº¡t max_new_per_iter = 500 má»—i vÃ²ng
- **Implication**: Sá»‘ lÆ°á»£ng pseudo-labels khÃ´ng pháº£i váº¥n Ä‘á», mÃ  lÃ  **cháº¥t lÆ°á»£ng**

### 6.5. BÃ i Há»c Kinh Nghiá»‡m

#### âœ… **Khi NÃ o DÃ¹ng Co-Training:**
1. **Features naturally split**: Text (words vs POS tags), Images (color vs texture)
2. **High-dimensional data**: Nhiá»u features dÆ° thá»«a â†’ split khÃ´ng máº¥t thÃ´ng tin
3. **Multi-modal data**: VÄƒn báº£n + hÃ¬nh áº£nh, audio + video

#### âŒ **Khi NÃ o KHÃ”NG DÃ¹ng Co-Training:**
1. **Low-dimensional tabular data**: NhÆ° Beijing Air Quality (51 features)
2. **Highly correlated features**: Features phá»¥ thuá»™c láº«n nhau
3. **Domain khÃ´ng split Ä‘Æ°á»£c**: KhÃ´ng cÃ³ cÃ¡ch chia views tá»± nhiÃªn

#### ğŸ’¡ **Recommendation for Beijing Air Quality:**
- **DÃ¹ng Self-Training** (F1 = 0.5343) thay vÃ¬ Co-Training
- **Náº¿u muá»‘n Co-Training**: Cáº§n engineering views tá»‘t hÆ¡n (e.g., temporal views, spatial views)
- **Trade-off**: Co-Training phá»©c táº¡p hÆ¡n nhÆ°ng khÃ´ng mang láº¡i lá»£i Ã­ch

---

## 7. Cross-Experiment Insights

### 7.1. Tá»•ng Há»£p CÃ¡c PhÃ¡t Hiá»‡n

#### 1. **KÃ­ch ThÆ°á»›c Labeled Data: 10% LÃ  Tá»‘i Æ¯u** â­
- **NgÆ°á»i chiáº¿n tháº¯ng rÃµ rÃ ng**: 10% labeled data Ä‘áº¡t F1-macro cao nháº¥t
- **LÃ½ do**: CÃ¢n báº±ng giá»¯a Ä‘á»™ máº¡nh model vÃ  khai thÃ¡c unlabeled data
- **Thá»±c táº¿**: Vá»›i dataset 420K máº«u, chá»‰ cáº§n ~2K máº«u cÃ³ nhÃ£n

#### 2. **Kiáº¿n TrÃºc Model: HGBC >> RandomForest** â­â­â­
- **Yáº¿u tá»‘ áº£nh hÆ°á»Ÿng lá»›n nháº¥t**: Lá»±a chá»n model quan trá»ng hÆ¡n kÃ­ch thÆ°á»›c labeled vÃ  lá»‹ch trÃ¬nh Ï„
- **Khoáº£ng cÃ¡ch F1**: +19.1% (0.4919 vs 0.4130) - KHÃC BIá»†T KHá»”NG Lá»’
- **NguyÃªn nhÃ¢n**: Gradient Boosting â†’ hiá»‡u chuáº©n xÃ¡c suáº¥t tá»‘t hÆ¡n â†’ pseudo-labels cháº¥t lÆ°á»£ng cao hÆ¡n

#### 3. **Adaptive Ï„: NÃªn CÃ³, KhÃ´ng Báº¯t Buá»™c** â­
- **Lá»£i Ã­ch nhá»**: +3.4% cáº£i thiá»‡n F1
- **Äá»™ phá»©c táº¡p**: Cáº§n Ä‘iá»u chá»‰nh lá»‹ch trÃ¬nh
- **Khuyáº¿n nghá»‹**: Báº¯t Ä‘áº§u vá»›i Fixed Ï„=0.90, tá»‘i Æ°u sau náº¿u cáº§n

#### 4. **Self-Training > Co-Training (Cho Dataset NÃ y)** â­â­
- **Self-Training F1**: 0.5343 (baseline)
- **Best Co-Training F1**: 0.4507 (Pollutant-based, **-15.6%**)
- **NguyÃªn nhÃ¢n**: Beijing Air Quality cÃ³ features tÆ°Æ¡ng quan cao â†’ view splitting máº¥t thÃ´ng tin
- **Recommendation**: DÃ¹ng Self-Training cho tabular low-dimensional data

#### 5. **Cháº¥t LÆ°á»£ng Pseudo-labeling > Sá»‘ LÆ°á»£ng**
- **RandomForest**: 180K nhÃ£n â†’ F1 = 0.4130
- **HGBC**: 346K nhÃ£n â†’ F1 = 0.4919
- **BÃ i há»c**: ThÃªm nhiá»u pseudo-labels khÃ´ng Ä‘áº£m báº£o hiá»‡u suáº¥t tá»‘t

#### 6. **Hiá»‡u Quáº£ Giáº£m Dáº§n LÃ  Tháº­t**
- 5% â†’ 10%: **+8.1% F1** cáº£i thiá»‡n âœ…
- 10% â†’ 20%: **-3.1% F1** giáº£m âŒ
- **HÃ m Ã½**: KhÃ´ng pháº£i cÃ ng nhiá»u labeled data cÃ ng tá»‘t

### 7.2. Cáº¥u HÃ¬nh Tá»‘t Nháº¥t

```python
# Thiáº¿t láº­p khuyáº¿n nghá»‹ cho dataset Beijing Air Quality
METHOD = "Self-Training"  # NOT Co-Training!
LABELED_FRACTION = 0.10  # 10% labeled data (~2K máº«u)
MODEL = HistGradientBoostingClassifier  # Model tá»‘t nháº¥t
TAU = 0.90  # ÄÆ¡n giáº£n vÃ  hiá»‡u quáº£ (hoáº·c Aggressive náº¿u muá»‘n +3.4% F1)
MAX_ITER = 10  # Äá»§ Ä‘á»ƒ há»™i tá»¥

# Hiá»‡u suáº¥t dá»± kiáº¿n:
# - Test F1-macro: ~0.534 (Self-Training)
# - Test Accuracy: ~0.568
# - Pseudo-labels: ~346K
```

### 7.3. Xáº¿p Háº¡ng Má»©c Äá»™ áº¢nh HÆ°á»Ÿng

**CÃ¡c yáº¿u tá»‘ theo má»©c áº£nh hÆ°á»Ÿng Ä‘áº¿n F1-macro:**

1. **Kiáº¿n TrÃºc Model** (HGBC vs RF): **+19.1% cáº£i thiá»‡n** ğŸ”¥ğŸ”¥ğŸ”¥
2. **Method Choice** (Self-Training vs Co-Training): **+18.5% cáº£i thiá»‡n** ğŸ”¥ğŸ”¥ğŸ”¥
3. **KÃ­ch ThÆ°á»›c Labeled Data** (5% vs 10%): **+8.1% cáº£i thiá»‡n** ğŸ”¥ğŸ”¥
4. **Lá»‹ch TrÃ¬nh Adaptive Ï„**: **+3.4% cáº£i thiá»‡n** ğŸ”¥
5. **Co-Training View Splitting** (Pollutant vs Current): **+7.9% cáº£i thiá»‡n** ğŸ”¥
6. **Nhiá»u Labeled HÆ¡n** (10% vs 20%): **-3.1% giáº£m** âš ï¸

**Æ¯u TiÃªn HÃ nh Äá»™ng:**
1. **Chá»n Self-Training** (khÃ´ng pháº£i Co-Training cho dataset nÃ y)
2. Chá»n model HGBC (áº£nh hÆ°á»Ÿng lá»›n nháº¥t)
3. DÃ¹ng ~10% labeled data (Ä‘iá»ƒm tá»‘i Æ°u)
4. Báº¯t Ä‘áº§u vá»›i Fixed Ï„=0.90 (Ä‘Æ¡n giáº£n, hiá»‡u quáº£)
5. Thá»­ nghiá»‡m adaptive Ï„ náº¿u cáº§n (lá»£i Ã­ch nhá»)

---

## 8. Káº¿t Luáº­n

### 8.1. TÃ³m Táº¯t Táº¥t Cáº£ ThÃ­ Nghiá»‡m
4. Thá»­ nghiá»‡m adaptive Ï„ náº¿u cáº§n (lá»£i Ã­ch nhá»)

---

## 7. Káº¿t Luáº­n

## 8. Káº¿t Luáº­n

### 8.1. TÃ³m Táº¯t Táº¥t Cáº£ ThÃ­ Nghiá»‡m

| ThÃ­ Nghiá»‡m | Cáº¥u HÃ¬nh Thá»­ | Cáº¥u HÃ¬nh Tá»‘t Nháº¥t | F1-macro | Cáº£i Thiá»‡n | Thá»i Gian |
|:-----------|:--------------:|:------------|:--------:|:-----------:|:-------:|
| **So SÃ¡nh Ï„** | 3 (0.80, 0.90, 0.95) | Ï„=0.90 | 0.5343 | +13.3% vs baseline | N/A |
| **KÃ­ch ThÆ°á»›c Labeled** | 3 (5%, 10%, 20%) | 10% labeled | 0.5050 | +8.1% vs 5% | ~25 phÃºt |
| **So SÃ¡nh Model** | 2 (HGBC, RF) | HGBC | 0.4919 | +19.1% vs RF | ~4 phÃºt |
| **Lá»‹ch TrÃ¬nh Hybrid Ï„** | 2 (Fixed, Aggressive) | Aggressive | 0.5088 | +3.4% vs Fixed | ~5 phÃºt |
| **View Splitting** | 2 (Current, Pollutant-based) | Pollutant-based | 0.4507 | **-15.6% vs Self-Training** âŒ | ~10 phÃºt |

**Tá»•ng Thá»i Gian**: ~48 phÃºt (táº¥t cáº£ experiments vá»›i best configs)

### 8.2. Káº¿t Quáº£ ChÃ­nh

âœ… **ThÃ­ nghiá»‡m hoÃ n chá»‰nh 5/5 experiments:**
- Ï„ comparison (0.80, 0.90, 0.95) â†’ **0.90 optimal**
- Labeled Size (5%, 10%, 20%) â†’ **10% optimal**
- Model Comparison (HGBC, RF) â†’ **HGBC wins**
- Hybrid Ï„ Schedule (Fixed, Aggressive) â†’ **Aggressive slightly better**
- View Splitting (Current, Pollutant-based) â†’ **Both WORSE than Self-Training** âš ï¸

âœ… **Best Configuration Found:**
- **Self-Training + 10% labeled + HGBC + Aggressive Ï„** â†’ F1 = **0.5343**
- **NOT Co-Training**: Co-Training kÃ©m hÆ¡n -15.6% do features highly correlated

âœ… **Trade-offs rÃµ rÃ ng:**
- Method choice (Self-Training vs Co-Training): +18.5% impact (critical!)
- Model architecture: +19.1% impact (biggest!)
- Labeled size: +8.1% impact (sweet spot at 10%)
- Adaptive Ï„: +3.4% impact (marginal)

### 8.3. Khuyáº¿n Nghá»‹ Thá»±c Táº¿

**Cho CÃ¡c Dá»± Ãn Semi-Supervised Learning:**

1. **Chá»n Method PhÃ¹ Há»£p**:
   - **Self-Training**: Cho tabular low-dimensional data vá»›i features tÆ°Æ¡ng quan cao
   - **Co-Training**: Chá»‰ khi cÃ³ naturally splittable features (text, images, multi-modal)

2. **Báº¯t Äáº§u ÄÆ¡n Giáº£n**: HGBC + 10% labeled + Fixed Ï„=0.90
   - Simple vÃ  hiá»‡u quáº£
   - F1 â‰ˆ 0.50-0.53

3. **Model Quan Trá»ng Nháº¥t**: Äáº§u tÆ° thá»i gian chá»n kiáº¿n trÃºc model phÃ¹ há»£p
   - Gradient Boosting >> Random Forest (cho self-training)
   - Cáº§n hiá»‡u chuáº©n xÃ¡c suáº¥t tá»‘t

4. **Äá»«ng Gáº¯n NhÃ£n QuÃ¡ Nhiá»u**: 10% labeled lÃ  Ä‘á»§, 20% cÃ³ thá»ƒ tá»‡ hÆ¡n

5. **Hiá»‡u Chuáº©n XÃ¡c Suáº¥t**: Äáº£m báº£o model output xÃ¡c suáº¥t Ä‘Æ°á»£c hiá»‡u chuáº©n tá»‘t

6. **Theo DÃµi Val F1**: DÃ¹ng Ä‘Æ°á»ng cong validation Ä‘á»ƒ phÃ¡t hiá»‡n overfitting/plateau

**Cho PhÃ¢n Loáº¡i AQI Báº¯c Kinh:**

1. **Cáº¥u HÃ¬nh Tá»‘i Æ¯u**: Self-Training + 10% labeled (~2K máº«u) + HGBC + Aggressive Ï„
2. **F1 Dá»± Kiáº¿n**: ~0.53-0.54 (Test F1-macro)
3. **Thá»i Gian Cháº¡y**: ~25-30 phÃºt cho full training (10 vÃ²ng láº·p)
4. **Pseudo-labels**: ~350K Ä‘Æ°á»£c thÃªm (91% unlabeled data)
5. **KHÃ”NG dÃ¹ng Co-Training**: Features tÆ°Æ¡ng quan cao â†’ view splitting máº¥t thÃ´ng tin

### 8.4. Lessons Learned tá»« Táº¥t Cáº£ Experiments

**1. Method Choice Is Critical**
- **Self-Training > Co-Training** cho dataset nÃ y (+18.5%)
- Co-Training cáº§n naturally splittable features
- Beijing Air Quality khÃ´ng phÃ¹ há»£p vá»›i Co-Training

**2. Accuracy khÃ´ng pháº£i metric tá»‘t nháº¥t**
- 20% labeled: Accuracy cao (0.5759) nhÆ°ng F1 tháº¥p (0.4896)
- F1-macro nháº¡y hÆ¡n vá»›i class imbalance

**2. Accuracy khÃ´ng pháº£i metric tá»‘t nháº¥t**
- 20% labeled: Accuracy cao (0.5759) nhÆ°ng F1 tháº¥p (0.4896)
- F1-macro nháº¡y hÆ¡n vá»›i class imbalance

**3. Quality > Quantity (Confirmed Across Multiple Experiments)**
- RandomForest: 180K labels â†’ F1 = 0.4130
- HGBC: 346K labels â†’ F1 = 0.4919
- Confidence threshold vÃ  model quality quan trá»ng

**4. Confirmation Bias Tháº­t Sá»± Tá»“n Táº¡i**
- Val F1 giáº£m sau vÃ²ng 2-3 trong táº¥t cáº£ experiments
- Early stopping critical

**5. Lá»›p Thiá»ƒu Sá»‘ HÆ°á»Ÿng Lá»£i Nhiá»u**
- Self-training giÃºp balance dataset
- F1 improvement lá»›n nháº¥t á»Ÿ minority classes

**6. Diminishing Return is Universal**
- Ï„: 0.90 optimal, khÃ´ng pháº£i 0.80 hay 0.95
- Labeled: 10% optimal, khÃ´ng pháº£i 20%
- More khÃ´ng pháº£i always better

**7. View Splitting Requirements**
- Co-Training cáº§n naturally splittable features
- Highly correlated features â†’ view splitting loses information
- Domain knowledge giÃºp nhÆ°ng khÃ´ng Ä‘á»§

### 8.5. So SÃ¡nh Final Methods

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
              FINAL RANKING (ALL 5 EXPERIMENTS)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¥‡ Self-Training (Ï„=0.90, 5%)   F1=0.5343  (+13.3%) â­
   - 5% labeled + HGBC + Fixed Ï„=0.90
   
ğŸ¥ˆ Self-Training (Optimized)    F1=0.5088  (+7.9%)
   - 10% labeled + HGBC + Aggressive Ï„
   
ğŸ¥‰ Baseline Supervised          F1=0.4715  (0%)
   - 100% labeled + RandomForest
   
4ï¸âƒ£ Co-Training (Pollutant)     F1=0.4507  (-4.4%)
   - 10% labeled + HGBC + View Splitting
   
5ï¸âƒ£ Co-Training (Current)        F1=0.4176  (-11.4%)
   - 10% labeled + HGBC + Random Views
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**Key Insight**: Self-Training clearly superior to Co-Training for Beijing Air Quality dataset!

### 8.6. Äá» Xuáº¥t CÃ´ng Viá»‡c TÆ°Æ¡ng Lai

**ÄÃ£ HoÃ n ThÃ nh âœ…:**
- âœ… So sÃ¡nh Ï„ (0.80, 0.90, 0.95)
- âœ… So sÃ¡nh kÃ­ch thÆ°á»›c labeled (5%, 10%, 20%)
- âœ… So sÃ¡nh model (HGBC, RandomForest)
- âœ… Lá»‹ch trÃ¬nh hybrid Ï„ (Fixed, Aggressive)
- âœ… View splitting strategies (Current, Pollutant-based)

**Má»Ÿ Rá»™ng Tiá»m NÄƒng ğŸ’¡:**
- ğŸ” NgÆ°á»¡ng Ï„ riÃªng cho tá»«ng lá»›p (xá»­ lÃ½ máº¥t cÃ¢n báº±ng tá»‘t hÆ¡n)
- ğŸ” Temporal/Spatial views cho Co-Training (thay vÃ¬ feature-based)
- ğŸ” Tri-Training (3+ models) thay vÃ¬ Co-Training (2 models)
- ğŸ” TÃ­ch há»£p active learning (chá»n máº«u thÃ´ng minh)
- ğŸ” Ensemble multiple Self-Training runs

---

## ğŸ“ Output Files Location

```
data/processed/
â”œâ”€â”€ self_training_experiments/
â”‚   â”œâ”€â”€ test_performance_comparison.png
â”‚   â”œâ”€â”€ pseudo_labels_over_iterations.png
â”‚   â”œâ”€â”€ validation_f1_over_iterations.png
â”‚   â””â”€â”€ comparison_summary.csv
â”‚
â”œâ”€â”€ labeled_size_experiments/
â”‚   â”œâ”€â”€ test_performance_comparison.png
â”‚   â”œâ”€â”€ learning_curves.png
â”‚   â”œâ”€â”€ pseudo_labels_comparison.png
â”‚   â”œâ”€â”€ training_data_composition.png
â”‚   â””â”€â”€ dashboard_summary.json
â”‚
â”œâ”€â”€ model_comparison_experiments/
â”‚   â”œâ”€â”€ test_performance_by_model.png
â”‚   â”œâ”€â”€ learning_curves_by_model.png
â”‚   â”œâ”€â”€ pseudo_labeling_by_model.png
â”‚   â”œâ”€â”€ per_class_f1_heatmap.png
â”‚   â””â”€â”€ dashboard_summary.json
â”‚
â”œâ”€â”€ hybrid_tau_experiments/
â”‚   â”œâ”€â”€ tau_schedules.png
â”‚   â”œâ”€â”€ test_performance_by_schedule.png
â”‚   â”œâ”€â”€ validation_curves_by_schedule.png
â”‚   â”œâ”€â”€ pseudo_labeling_activity.png
â”‚   â”œâ”€â”€ total_pseudo_labels.png
â”‚   â”œâ”€â”€ tau_performance_correlation.png
â”‚   â””â”€â”€ dashboard_summary.json
â”‚
â””â”€â”€ view_splitting_experiments/
    â”œâ”€â”€ test_performance_by_strategy.png
    â”œâ”€â”€ learning_curves_by_strategy.png
    â”œâ”€â”€ view_independence_analysis.png
    â”œâ”€â”€ comparison_with_baseline.png
    â”œâ”€â”€ view_splitting_results.json
    â”œâ”€â”€ view_splitting_summary.csv
    â””â”€â”€ dashboard_summary.json
```

---

## ğŸ“‘ Related Documents

- **[BLOG_SELF_TRAINING.md](BLOG_SELF_TRAINING.md)**: LÃ½ thuyáº¿t Self-Training (Requirement 1)
- **[BLOG_CO_TRAINING.md](BLOG_CO_TRAINING.md)**: LÃ½ thuyáº¿t Co-Training (Requirement 2)
- **[README.md](README.md)**: Project overview

---

## ğŸ“‘ Navigation

| [â† Blog 1: Self-Training](BLOG_SELF_TRAINING.md) | [â† Blog 2: Co-Training](BLOG_CO_TRAINING.md) | [â†’ README](README.md) |
|:---:|:---:|:---:|

---

<div align="center">

**Blog PhÃ¢n TÃ­ch Parameter Comparison - YÃªu cáº§u 3 (COMPLETED)**

*4 thÃ­ nghiá»‡m hoÃ n chá»‰nh: Ï„ comparison, Labeled Size, Model Comparison, Hybrid Ï„ Schedule*

*Data Mining - Air Quality Prediction Project*

**Generated**: 2026-01-28  
**Total Experiments**: 4/4 completed âœ…  
**Total Runtime**: ~34 minutes (optimized)  
**Best F1-macro**: 0.5088 (10% labeled + HGBC + Aggressive Ï„)

</div>

---
