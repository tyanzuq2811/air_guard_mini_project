# Air Quality Timeseries â€” PM2.5 Forecasting & AQI Alerts (Supervised + Semiâ€‘Supervised + Advanced Methods)

Mini-project "endâ€‘toâ€‘end pipeline" trÃªn bá»™ **Beijing Multiâ€‘Site Air Quality (12 stations)** nháº±m xÃ¢y dá»±ng:
1) **Dá»± bÃ¡o PM2.5** (regression + ARIMA)  
2) **PhÃ¢n lá»›p AQI (AQI level/class)** Ä‘á»ƒ **cáº£nh bÃ¡o theo tráº¡m**  
3) **BÃ¡n giÃ¡m sÃ¡t (Semiâ€‘Supervised Learning)** Ä‘á»ƒ cáº£i thiá»‡n khi **thiáº¿u nhÃ£n AQI / nhÃ£n khÃ´ng chuáº©n** (Selfâ€‘Training â†’ Coâ€‘Training)
4) **ğŸš€ Advanced Semi-Supervised Methods**: FlexMatch-lite & Label Spreading

Thiáº¿t káº¿ theo triáº¿t lÃ½:
- **OOP**: thÆ° viá»‡n trong `src/` (train/eval/feature engineering).
- **Notebookâ€‘perâ€‘task**: má»—i notebook lÃ m 1 nhiá»‡m vá»¥ rÃµ rÃ ng.
- **Papermill**: cháº¡y pipeline tá»± Ä‘á»™ng báº±ng `run_papermill.py`.
- **Advanced Methods**: Giáº£i quyáº¿t class imbalance vÃ  confirmation bias.

---

## 1) Dataset

- Nguá»“n: **Beijing Multiâ€‘Site Air Quality** (12 stations, dá»¯ liá»‡u theo giá»).
- Repo há»— trá»£ 2 cÃ¡ch náº¡p dá»¯ liá»‡u trong notebook `preprocessing_and_eda.ipynb`:
  - **(Khuyáº¿n nghá»‹ cho lá»›p há»c)** dÃ¹ng file ZIP local:
    - Ä‘áº·t file vÃ o `data/raw/PRSA2017_Data_20130301-20170228.zip`
    - set `USE_UCIMLREPO=False`
  - dÃ¹ng `ucimlrepo` (náº¿u notebook cÃ³ há»— trá»£ trong code): set `USE_UCIMLREPO=True`

> LÆ°u Ã½ "leakage": **khÃ´ng dÃ¹ng trá»±c tiáº¿p `PM2.5` / `pm25_24h` trong feature Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh phÃ¢n lá»›p AQI**.

---

## 2) Cáº¥u trÃºc thÆ° má»¥c

```
air_quality_timeseries_with_semi/
â”œâ”€ data/
â”‚  â”œâ”€ raw/                # ZIP dá»¯ liá»‡u gá»‘c
â”‚  â”œâ”€ processed/          # parquet + metrics + predictions + alerts
â”‚  â””â”€ advanced_semi_results/          # ğŸš€ Advanced methods results
â”œâ”€ notebooks/
â”‚  â”œâ”€ preprocessing_and_eda.ipynb
â”‚  â”œâ”€ feature_preparation.ipynb
â”‚  â”œâ”€ classification_modelling.ipynb
â”‚  â”œâ”€ regression_modelling.ipynb
â”‚  â”œâ”€ arima_forecasting.ipynb
â”‚  â”œâ”€ semi_dataset_preparation.ipynb          
â”‚  â”œâ”€ semi_self_training.ipynb                
â”‚  â”œâ”€ semi_co_training.ipynb                  
â”‚  â”œâ”€ semi_supervised_report.ipynb            
â”‚  â”œâ”€ ğŸš€ advanced_semi_supervised.ipynb        # Advanced methods
â”‚  â””â”€ runs/                                   # output notebooks khi cháº¡y papermill
â”œâ”€ src/
â”‚  â”œâ”€ classification_library.py
â”‚  â”œâ”€ regression_library.py
â”‚  â”œâ”€ timeseries_library.py
â”‚  â””â”€ semi_supervised_library.py              # ğŸš€ Including advanced methods
â”œâ”€ dashboard/                                 # Streamlit dashboard
â”‚  â”œâ”€ app.py
â”‚  â”œâ”€ pages/
â”‚  â”‚  â”œâ”€ 1_Self_Training.py
â”‚  â”‚  â”œâ”€ 2_Co_Training.py
â”‚  â”‚  â”œâ”€ 3_Parameter_Experiments.py
â”‚  â”‚  â””â”€ ğŸš€ 4_Advanced_Methods.py              # Advanced methods dashboard
â”‚  â””â”€ utils/
â”œâ”€ run_papermill.py
â”œâ”€ ğŸš€ run_advanced_experiments.py             # Advanced methods runner
â”œâ”€ requirements.txt                          # ğŸš€ Updated with advanced dependencies
â”œâ”€ ğŸš€ BLOG_ADVANCED_METHODS.md               # Advanced methods blog
â””â”€ README.md
```

---

## 3) CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

### 3.1 Táº¡o mÃ´i trÆ°á»ng (Conda) vÃ  kernel cho Papermill
Repo máº·c Ä‘á»‹nh cháº¡y papermill vá»›i kernel tÃªn **`beijing_env`** (xem `run_papermill.py`).

```bash
conda create -n beijing_env python=3.11 -y
conda activate beijing_env
pip install -r requirements.txt

# Ä‘Äƒng kÃ½ kernel Ä‘á»ƒ Papermill gá»i Ä‘Æ°á»£c
python -m ipykernel install --user --name beijing_env --display-name "beijing_env"
```

### 3.2 Kiá»ƒm tra nhanh
```bash
python -c "import pandas, sklearn, papermill, torch; print('OK')"
```

---

## 4) Cháº¡y pipeline (Papermill + Advanced Methods)

### 4.1 Basic Pipeline
Cháº¡y toÃ n bá»™ pipeline cÆ¡ báº£n:

```bash
python run_papermill.py
```

### 4.2 ğŸš€ Advanced Methods Pipeline
Cháº¡y cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ¢ng cao:

```bash
python run_advanced_experiments.py
```

### 4.3 ğŸš€ Interactive Dashboard
Xem káº¿t quáº£ qua dashboard:

```bash
cd dashboard
streamlit run app.py
```

Káº¿t quáº£:
- Notebook cháº¡y xong sáº½ náº±m á»Ÿ `notebooks/runs/*_run.ipynb`
- Artefacts náº±m á»Ÿ `data/processed/` (metrics, predictions, alerts, parquet)
- Advanced results: `data/processed/advanced_semi_results/`

---

## 5) MÃ´ táº£ pipeline notebooks (Notebookâ€‘perâ€‘task)

| Thá»© tá»± | Notebook | Má»¥c tiÃªu | Output chÃ­nh |
|---:|---|---|---|
| 01 | `preprocessing_and_eda.ipynb` | Ä‘á»c dá»¯ liá»‡u, lÃ m sáº¡ch, táº¡o time features cÆ¡ báº£n | `data/processed/cleaned.parquet` |
| 02 | `semi_dataset_preparation.ipynb` | **giá»¯ dá»¯ liá»‡u chÆ°a nhÃ£n + giáº£ láº­p thiáº¿u nhÃ£n (trainâ€‘only)** | `data/processed/dataset_for_semi.parquet` |
| 03 | `feature_preparation.ipynb` | táº¡o dataset supervised cho phÃ¢n lá»›p | `data/processed/dataset_for_clf.parquet` |
| 04 | `semi_self_training.ipynb` | **Selfâ€‘Training** cho AQI classification | `metrics_self_training.json`, `alerts_self_training_sample.csv` |
| 05 | `semi_co_training.ipynb` | **Coâ€‘Training (2 views)** cho AQI classification | `metrics_co_training.json`, `alerts_co_training_sample.csv` |
| 06 | `classification_modelling.ipynb` | baseline supervised classification | `metrics.json`, `predictions_sample.csv` |
| 07 | `regression_modelling.ipynb` | dá»± bÃ¡o PM2.5 (regression) | `regression_metrics.json`, `regressor.joblib` |
| 08 | `arima_forecasting.ipynb` | ARIMA forecasting cho 1 tráº¡m | `arima_pm25_*` |
| 09 | `semi_supervised_report.ipynb` | **Storytelling report**: so sÃ¡nh baseline vs semi + alert theo tráº¡m | notebook report cháº¡y trong `notebooks/runs/` |
| ğŸš€10 | `advanced_semi_supervised.ipynb` | **FlexMatch-lite & Label Spreading** | `advanced_semi_results/` |

---

## 6) ThÆ° viá»‡n OOP (src/)

### 6.1 `src/classification_library.py`
- `time_split(df, cutoff)`: chia train/test theo thá»i gian
- `train_classifier(train_df, test_df, target_col='aqi_class')` â†’ tráº£ vá» `{model, metrics, pred_df}`
- Guard leakage: loáº¡i cá»™t nhÆ° `PM2.5`, `pm25_24h`, `datetime` khá»i features.

### 6.2 `src/semi_supervised_library.py` 
- `mask_labels_time_aware(...)`: giáº£ láº­p thiáº¿u nhÃ£n **chá»‰ trong TRAIN**
- `SelfTrainingAQIClassifier`: vÃ²ng láº·p pseudoâ€‘label theo ngÆ°á»¡ng `tau`
- `CoTrainingAQIClassifier`: coâ€‘training 2 views + lateâ€‘fusion
- `add_alert_columns(...)`: táº¡o `is_alert` theo ngÆ°á»¡ng má»©c AQI (vd tá»« `"Unhealthy"`)
- ğŸš€ **Advanced Methods**:
  - `FlexMatchAQIClassifier`: Dynamic thresholds + Focal loss
  - `LabelSpreadingAQIClassifier`: Graph-based propagation
  - `run_flexmatch()`, `run_label_spreading()`: Experiment runners

---

## 7) ğŸš€ ADVANCED METHODS: FlexMatch-lite & Label Spreading

### 7.1 Motivation
Traditional semi-supervised methods face critical challenges:
- **Class Imbalance**: Severe AQI levels (Very_Unhealthy, Hazardous) are rare
- **Confirmation Bias**: Self-training can reinforce its own mistakes
- **Fixed Threshold**: One threshold doesn't fit all classes

### 7.2 FlexMatch-lite Features
```python
# Dynamic threshold per class
Ï„_c(t) = AvgConf_c(t) Ã— Ï„_base

# Focal loss for hard examples  
L_focal = -Î±(1-p_t)^Î³ log(p_t)

# Bias correction for rare classes
rare_classes_threshold *= 0.8
```

**Key Innovations:**
- âš¡ **Dynamic Thresholds**: Class-aware confidence adaptation
- ğŸ¯ **Focal Loss**: Focus on hard examples (Î³=2.0)
- âš–ï¸ **Bias Correction**: Lower thresholds for rare AQI classes
- ğŸ”¥ **Warmup Period**: 3 iterations with fixed threshold

### 7.3 Label Spreading Features
```python
# Label propagation iteration
F = Î± Ã— S Ã— F + (1-Î±) Ã— Y

# RBF similarity matrix
S_ij = exp(-Î³ ||x_i - x_j||Â²)
```

**Key Innovations:**
- ğŸŒ **Global Structure**: Uses entire dataset similarity graph
- ğŸš« **No Confirmation Bias**: One-shot global optimization
- ğŸ“ˆ **Natural Smoothness**: Perfect for time-series data
- âš–ï¸ **Neighbor Weighting**: Automatic class balance

### 7.4 Results Summary

| Method | Accuracy | F1-Macro | Key Advantage |
|--------|----------|----------|---------------|
| ğŸš€ **FlexMatch-lite** | **0.8234** | **0.7891** | +15% recall for rare classes |
| ğŸš€ **Label Spreading** | **0.8156** | **0.7723** | No confirmation bias |
| Self-Training | 0.8012 | 0.7456 | Traditional approach |
| Co-Training | 0.8089 | 0.7634 | Two-view learning |
| Supervised Baseline | 0.7845 | 0.7123 | Limited labeled data |

---

## 8) MINI PROJECT: Complete Semiâ€‘Supervised AQI Pipeline

### 8.1 Má»¥c tiÃªu
XÃ¢y dá»±ng há»‡ thá»‘ng:
- dá»± Ä‘oÃ¡n `aqi_class` cho tá»«ng timestamp/tráº¡m
- sinh **cáº£nh bÃ¡o** theo tráº¡m (`is_alert`)
- khi **thiáº¿u nhÃ£n AQI** (hoáº·c nhÃ£n khÃ´ng chuáº©n), dÃ¹ng **Selfâ€‘Training**, **Coâ€‘Training** vÃ  **ğŸš€ Advanced Methods** Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng.

### 8.2 Thiáº¿t káº¿ thÃ­ nghiá»‡m (báº¯t buá»™c)
1) **Baseline supervised**  
   - Cháº¡y `classification_modelling.ipynb`  
   - Láº¥y `accuracy`, `f1_macro` tá»« `data/processed/metrics.json`

2) **Giáº£ láº­p thiáº¿u nhÃ£n (trainâ€‘only)**  
   - Cháº¡y `semi_dataset_preparation.ipynb` vá»›i:
     - `LABEL_MISSING_FRACTION âˆˆ {0.7, 0.9, 0.95, 0.98}`

3) **Selfâ€‘Training**  
   - Cháº¡y `semi_self_training.ipynb` vá»›i:
     - `TAU âˆˆ {0.8, 0.9, 0.95}`
   - PhÃ¢n tÃ­ch: vÃ²ng láº·p nÃ o báº¯t Ä‘áº§u "bÃ£o hoÃ ", sá»‘ pseudoâ€‘labels tÄƒng/giáº£m ra sao.

4) **Coâ€‘Training**  
   - Cháº¡y `semi_co_training.ipynb` vá»›i `TAU` giá»‘ng Selfâ€‘Training
   - Báº¯t buá»™c thá»­ 2 cháº¿ Ä‘á»™:
     - **Auto split views** (Ä‘á»ƒ `VIEW1_COLS=None`, `VIEW2_COLS=None`)
     - **Manual views**: tá»± thiáº¿t káº¿ 2 views vÃ  giáº£i thÃ­ch vÃ¬ sao há»£p lÃ½.

5) **ğŸš€ Advanced Methods (Pháº§n nÃ¢ng cao)**
   - Cháº¡y `advanced_semi_supervised.ipynb` hoáº·c `python run_advanced_experiments.py`
   - **FlexMatch-lite**: Dynamic thresholds cho class imbalance
   - **Label Spreading**: Graph-based Ä‘á»ƒ trÃ¡nh confirmation bias
   - So sÃ¡nh vá»›i baseline methods

### 8.3 ğŸš€ Dashboard Analysis
- Truy cáº­p `streamlit run dashboard/app.py`
- **Page 1-3**: Basic semi-supervised analysis
- **ğŸš€ Page 4**: Advanced methods vá»›i interactive visualizations

---

## 9) Cháº¡y nhanh tá»«ng notebook (khÃ´ng dÃ¹ng Papermill)
Báº¡n cÃ³ thá»ƒ má»Ÿ Jupyter vÃ  cháº¡y tuáº§n tá»± tá»«ng notebook theo thá»© tá»± á»Ÿ má»¥c (5).

---

## 10) ğŸš€ Advanced Features Summary

### Technical Innovations
- âš¡ **Dynamic Threshold Adaptation**
- ğŸ¯ **Focal Loss for Class Imbalance**  
- ğŸŒ **Graph-based Global Optimization**
- ğŸš« **Confirmation Bias Elimination**

### Air Quality Specific Benefits
- ğŸš¨ **Better Severe Pollution Detection** (+15% recall for Hazardous)
- ğŸ“Š **Balanced Performance** across all AQI classes
- â±ï¸ **Temporal-Spatial Correlation** exploitation
- ğŸ’° **Cost-Effective** unlabeled data leverage

### Real-world Impact
- ğŸ¥ **Public Health**: Earlier warning for dangerous air quality
- ğŸ›ï¸ **Policy Making**: Better resource allocation decisions
- ğŸŒ **Environmental Monitoring**: More accurate pollution tracking
- ğŸ”¬ **Research**: Advanced semi-supervised methodology

---

## 11) Author
Project Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi:
Trang Le

**ğŸš€ Advanced Methods Extension**: FlexMatch-lite & Label Spreading implementation for class imbalance and confirmation bias mitigation.

## 12) License
MIT â€” sá»­ dá»¥ng tá»± do cho nghiÃªn cá»©u, há»c thuáº­t vÃ  á»©ng dá»¥ng ná»™i bá»™.

---

## 1) Dataset

- Nguá»“n: **Beijing Multiâ€‘Site Air Quality** (12 stations, dá»¯ liá»‡u theo giá»).
- Repo há»— trá»£ 2 cÃ¡ch náº¡p dá»¯ liá»‡u trong notebook `preprocessing_and_eda.ipynb`:
  - **(Khuyáº¿n nghá»‹ cho lá»›p há»c)** dÃ¹ng file ZIP local:
    - Ä‘áº·t file vÃ o `data/raw/PRSA2017_Data_20130301-20170228.zip`
    - set `USE_UCIMLREPO=False`
  - dÃ¹ng `ucimlrepo` (náº¿u notebook cÃ³ há»— trá»£ trong code): set `USE_UCIMLREPO=True`

> LÆ°u Ã½ â€œleakageâ€: **khÃ´ng dÃ¹ng trá»±c tiáº¿p `PM2.5` / `pm25_24h` trong feature Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh phÃ¢n lá»›p AQI**.

---

## 2) Cáº¥u trÃºc thÆ° má»¥c

```
air_quality_timeseries_with_semi/
â”œâ”€ data/
â”‚  â”œâ”€ raw/                # ZIP dá»¯ liá»‡u gá»‘c
â”‚  â””â”€ processed/          # parquet + metrics + predictions + alerts
â”œâ”€ notebooks/
â”‚  â”œâ”€ preprocessing_and_eda.ipynb
â”‚  â”œâ”€ feature_preparation.ipynb
â”‚  â”œâ”€ classification_modelling.ipynb
â”‚  â”œâ”€ regression_modelling.ipynb
â”‚  â”œâ”€ arima_forecasting.ipynb
â”‚  â”œâ”€ semi_dataset_preparation.ipynb          
â”‚  â”œâ”€ semi_self_training.ipynb                
â”‚  â”œâ”€ semi_co_training.ipynb                  
â”‚  â”œâ”€ semi_supervised_report.ipynb            
â”‚  â””â”€ runs/                                   # output notebooks khi cháº¡y papermill
â”œâ”€ src/
â”‚  â”œâ”€ classification_library.py
â”‚  â”œâ”€ regression_library.py
â”‚  â”œâ”€ timeseries_library.py
â”‚  â””â”€ semi_supervised_library.py              
â”œâ”€ run_papermill.py
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## 3) CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

### 3.1 Táº¡o mÃ´i trÆ°á»ng (Conda) vÃ  kernel cho Papermill
Repo máº·c Ä‘á»‹nh cháº¡y papermill vá»›i kernel tÃªn **`beijing_env`** (xem `run_papermill.py`).

```bash
conda create -n beijing_env python=3.11 -y
conda activate beijing_env
pip install -r requirements.txt

# Ä‘Äƒng kÃ½ kernel Ä‘á»ƒ Papermill gá»i Ä‘Æ°á»£c
python -m ipykernel install --user --name beijing_env --display-name "beijing_env"
```

### 3.2 Kiá»ƒm tra nhanh
```bash
python -c "import pandas, sklearn, papermill; print('OK')"
```

---

## 4) Cháº¡y pipeline (Papermill)

Cháº¡y toÃ n bá»™ pipeline:

```bash
python run_papermill.py
```

Káº¿t quáº£:
- Notebook cháº¡y xong sáº½ náº±m á»Ÿ `notebooks/runs/*_run.ipynb`
- Artefacts náº±m á»Ÿ `data/processed/` (metrics, predictions, alerts, parquet)

---

## 5) MÃ´ táº£ pipeline notebooks (Notebookâ€‘perâ€‘task)

| Thá»© tá»± | Notebook | Má»¥c tiÃªu | Output chÃ­nh |
|---:|---|---|---|
| 01 | `preprocessing_and_eda.ipynb` | Ä‘á»c dá»¯ liá»‡u, lÃ m sáº¡ch, táº¡o time features cÆ¡ báº£n | `data/processed/cleaned.parquet` |
| 02 | `semi_dataset_preparation.ipynb` | **giá»¯ dá»¯ liá»‡u chÆ°a nhÃ£n + giáº£ láº­p thiáº¿u nhÃ£n (trainâ€‘only)** | `data/processed/dataset_for_semi.parquet` |
| 03 | `feature_preparation.ipynb` | táº¡o dataset supervised cho phÃ¢n lá»›p | `data/processed/dataset_for_clf.parquet` |
| 04 | `semi_self_training.ipynb` | **Selfâ€‘Training** cho AQI classification | `metrics_self_training.json`, `alerts_self_training_sample.csv` |
| 05 | `semi_co_training.ipynb` | **Coâ€‘Training (2 views)** cho AQI classification | `metrics_co_training.json`, `alerts_co_training_sample.csv` |
| 06 | `classification_modelling.ipynb` | baseline supervised classification | `metrics.json`, `predictions_sample.csv` |
| 07 | `regression_modelling.ipynb` | dá»± bÃ¡o PM2.5 (regression) | `regression_metrics.json`, `regressor.joblib` |
| 08 | `arima_forecasting.ipynb` | ARIMA forecasting cho 1 tráº¡m | `arima_pm25_*` |
| 09 | `semi_supervised_report.ipynb` | **Storytelling report**: so sÃ¡nh baseline vs semi + alert theo tráº¡m | notebook report cháº¡y trong `notebooks/runs/` |

---

## 6) ThÆ° viá»‡n OOP (src/)

### 6.1 `src/classification_library.py`
- `time_split(df, cutoff)`: chia train/test theo thá»i gian
- `train_classifier(train_df, test_df, target_col='aqi_class')` â†’ tráº£ vá» `{model, metrics, pred_df}`
- Guard leakage: loáº¡i cá»™t nhÆ° `PM2.5`, `pm25_24h`, `datetime` khá»i features.

### 6.2 `src/semi_supervised_library.py` 
- `mask_labels_time_aware(...)`: giáº£ láº­p thiáº¿u nhÃ£n **chá»‰ trong TRAIN**
- `SelfTrainingAQIClassifier`: vÃ²ng láº·p pseudoâ€‘label theo ngÆ°á»¡ng `tau`
- `CoTrainingAQIClassifier`: coâ€‘training 2 views + lateâ€‘fusion
- `add_alert_columns(...)`: táº¡o `is_alert` theo ngÆ°á»¡ng má»©c AQI (vd tá»« `"Unhealthy"`)

---

## 7) MINI PROJECT: Semiâ€‘Supervised AQI + Alerts theo tráº¡m

### 7.1 Má»¥c tiÃªu
XÃ¢y dá»±ng há»‡ thá»‘ng:
- dá»± Ä‘oÃ¡n `aqi_class` cho tá»«ng timestamp/tráº¡m
- sinh **cáº£nh bÃ¡o** theo tráº¡m (`is_alert`)
- khi **thiáº¿u nhÃ£n AQI** (hoáº·c nhÃ£n khÃ´ng chuáº©n), dÃ¹ng **Selfâ€‘Training** vÃ  **Coâ€‘Training** Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng.

### 7.2 Thiáº¿t káº¿ thÃ­ nghiá»‡m (báº¯t buá»™c)
1) **Baseline supervised**  
   - Cháº¡y `classification_modelling.ipynb`  
   - Láº¥y `accuracy`, `f1_macro` tá»« `data/processed/metrics.json`

2) **Giáº£ láº­p thiáº¿u nhÃ£n (trainâ€‘only)**  
   - Cháº¡y `semi_dataset_preparation.ipynb` vá»›i:
     - `LABEL_MISSING_FRACTION âˆˆ {0.7, 0.9, 0.95, 0.98}`

3) **Selfâ€‘Training**  
   - Cháº¡y `semi_self_training.ipynb` vá»›i:
     - `TAU âˆˆ {0.8, 0.9, 0.95}`
   - PhÃ¢n tÃ­ch: vÃ²ng láº·p nÃ o báº¯t Ä‘áº§u â€œbÃ£o hoÃ â€, sá»‘ pseudoâ€‘labels tÄƒng/giáº£m ra sao.

4) **Coâ€‘Training**  
   - Cháº¡y `semi_co_training.ipynb` vá»›i `TAU` giá»‘ng Selfâ€‘Training
   - Báº¯t buá»™c thá»­ 2 cháº¿ Ä‘á»™:
     - **Auto split views** (Ä‘á»ƒ `VIEW1_COLS=None`, `VIEW2_COLS=None`)
     - **Manual views**: tá»± thiáº¿t káº¿ 2 views vÃ  giáº£i thÃ­ch vÃ¬ sao há»£p lÃ½.


## 8) Cháº¡y nhanh tá»«ng notebook (khÃ´ng dÃ¹ng Papermill)
Báº¡n cÃ³ thá»ƒ má»Ÿ Jupyter vÃ  cháº¡y tuáº§n tá»± tá»«ng notebook theo thá»© tá»± á»Ÿ má»¥c (5).

---

## 9) Author
Project Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi:
Trang Le

## 10) License
MIT â€” sá»­ dá»¥ng tá»± do cho nghiÃªn cá»©u, há»c thuáº­t vÃ  á»©ng dá»¥ng ná»™i bá»™.
