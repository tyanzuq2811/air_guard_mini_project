# Label Spreading: Graph-Based Semi-Supervised Learning

> **Ph∆∞∆°ng ph√°p n√¢ng cao:** So s√°nh Label Spreading v·ªõi Self-Training v√† FlexMatch

---

## M·ª•c L·ª•c

1. [Gi·ªõi Thi·ªáu](#1-gi·ªõi-thi·ªáu)
2. [Label Spreading L√† G√¨?](#2-label-spreading-l√†-g√¨)
3. [K·∫øt Qu·∫£ Th√≠ Nghi·ªám](#3-k·∫øt-qu·∫£-th√≠-nghi·ªám)
4. [So S√°nh V·ªõi Self-Training](#4-so-s√°nh-v·ªõi-self-training)
5. [Ph√¢n T√≠ch](#5-ph√¢n-t√≠ch)
6. [K·∫øt Lu·∫≠n](#6-k·∫øt-lu·∫≠n)

---

## 1. Gi·ªõi Thi·ªáu

### T·∫°i Sao C·∫ßn Label Spreading?

**H·∫°n ch·∫ø c·ªßa Self-Training:**
- ‚ùå Confirmation bias (model tin v√†o l·ªói c·ªßa ch√≠nh n√≥)
- ‚ùå Iterative process (ch·∫≠m, nhi·ªÅu v√≤ng l·∫∑p)
- ‚ùå Greedy selection (ch·ªçn theo threshold c·ª©ng)

**Label Spreading kh√°c bi·ªát:**
- ‚úÖ S·ª≠ d·ª•ng **manifold structure** c·ªßa d·ªØ li·ªáu
- ‚úÖ **Single optimization** (kh√¥ng c·∫ßn v√≤ng l·∫∑p)
- ‚úÖ T·ª± nhi√™n x·ª≠ l√Ω class imbalance qua graph

---

## 2. Label Spreading L√† G√¨?

### √ù T∆∞·ªüng C∆° B·∫£n

**Graph-based approach:**
1. X√¢y d·ª±ng **similarity graph** gi·ªØa t·∫•t c·∫£ samples (labeled + unlabeled)
2. **Lan truy·ªÅn nh√£n** qua graph d·ª±a tr√™n similarity
3. Samples g·∫ßn nhau tr√™n graph ‚Üí c√≥ nh√£n gi·ªëng nhau

**V√≠ d·ª• tr·ª±c quan:**
```
Labeled samples:     [Good]  [Moderate]  [Hazardous]
                        |         |           |
Similarity edges:      ‚Üì         ‚Üì           ‚Üì
Unlabeled samples:   [?]  ‚Üí  [?]  ‚Üí  [?]  ‚Üí  [?]
                      ‚Üì         ‚Üì           ‚Üì
After spreading:    [Good] [Moderate] [Moderate] [Hazardous]
```

### C√¥ng Th·ª©c

**Label Spreading iteration:**
```
Y^(t+1) = Œ±SY^(t) + (1-Œ±)Y^(0)
```

**Th√†nh ph·∫ßn:**
- `Y^(t)`: Label distribution t·∫°i v√≤ng t
- `S`: Similarity matrix (normalized)
- `Œ±`: Clamping factor (0-1)
  - Œ± = 0: Ch·ªâ d√πng initial labels
  - Œ± = 1: Ho√†n to√†n lan truy·ªÅn (Label Propagation)
  - Œ± = 0.2: C√¢n b·∫±ng (khuy·∫øn ngh·ªã)
- `Y^(0)`: Initial labels

### RBF Kernel

**Similarity computation:**
```
S(i,j) = exp(-Œ≥ ||x_i - x_j||¬≤)
```

**Tham s·ªë Œ≥:**
- Œ≥ nh·ªè (10): Similarity r·ªông ‚Üí lan truy·ªÅn xa
- Œ≥ l·ªõn (30): Similarity h·∫πp ‚Üí lan truy·ªÅn g·∫ßn
- Œ≥ = 20: C√¢n b·∫±ng (khuy·∫øn ngh·ªã)

### ∆Øu & Nh∆∞·ª£c ƒêi·ªÉm

| ∆Øu ƒëi·ªÉm | Nh∆∞·ª£c ƒëi·ªÉm |
|---------|------------|
| ‚úÖ S·ª≠ d·ª•ng manifold structure | ‚ùå Memory intensive O(n¬≤) |
| ‚úÖ Kh√¥ng c√≥ confirmation bias | ‚ùå Ch·∫≠m v·ªõi large datasets |
| ‚úÖ Deterministic (kh√¥ng random) | ‚ùå C·∫ßn tune hyperparameters |
| ‚úÖ X·ª≠ l√Ω class imbalance t·ªët | ‚ùå Kh√¥ng ph√π h·ª£p v·ªõi sparse data |

---

## 3. K·∫øt Qu·∫£ Th√≠ Nghi·ªám

### Thi·∫øt L·∫≠p

| Tham s·ªë | Gi√° tr·ªã |
|---------|---------|
| Labeled Data | 5% (~20K samples) |
| Unlabeled Data | 95% (sampled to 50K) |
| Kernel | RBF |
| Gamma (Œ≥) | 20.0 |
| Alpha (Œ±) | 0.2 |
| Max Iterations | 30 |

> **L∆∞u √Ω:** Do memory constraint, unlabeled data ƒë∆∞·ª£c sample xu·ªëng 50K samples (gi·ªØ to√†n b·ªô labeled data)

### Grid Search Results

| Config | Accuracy | F1-macro | Training Time |
|--------|----------|----------|---------------|
| Œ≥=10, Œ±=0.1 | 0.5845 | 0.5289 | 45s |
| **Œ≥=20, Œ±=0.2** | **0.5912** | **0.5398** | 52s |
| Œ≥=30, Œ±=0.3 | 0.5878 | 0.5356 | 48s |

**Best config:** Œ≥=20, Œ±=0.2

---

## 4. So S√°nh V·ªõi Self-Training

### Metrics Comparison

| Ph∆∞∆°ng ph√°p | Test Accuracy | Test F1-macro | Training Time | Memory |
|-------------|---------------|---------------|---------------|--------|
| **Self-Training (œÑ=0.9)** | 0.5890 | 0.5343 | ~20 min | Low |
| **FlexMatch** | 0.5928 | **0.5445** | ~25 min | Low |
| **Label Spreading** | 0.5912 | 0.5398 | **~1 min** | **High** |

![Method Comparison](./data/processed/label_spreading_experiments/method_comparison.png)

**Nh·∫≠n x√©t:**

1. **Accuracy:**
   - Label Spreading: 0.5912 (trung b√¨nh)
   - FlexMatch: 0.5928 (cao nh·∫•t, +0.27%)
   - Self-Training: 0.5890 (th·∫•p nh·∫•t)

2. **F1-macro:**
   - FlexMatch: 0.5445 (cao nh·∫•t)
   - Label Spreading: 0.5398 (trung b√¨nh, +1.03% vs Self-Training)
   - Self-Training: 0.5343 (th·∫•p nh·∫•t)

3. **Training Time:**
   - Label Spreading: **~1 min** (nhanh nh·∫•t!) ‚ö°
   - Self-Training: ~20 min
   - FlexMatch: ~25 min

4. **Memory Usage:**
   - Label Spreading: **High** (c·∫ßn sample data)
   - Self-Training/FlexMatch: Low

### Per-Class F1-Score

![Per-Class F1](./data/processed/label_spreading_experiments/per_class_f1.png)

| L·ªõp AQI | Self-Training | Label Spreading | Ch√™nh l·ªách |
|---------|---------------|-----------------|------------|
| **Good** | 0.4897 | 0.5034 | **+2.80%** ‚úÖ |
| **Moderate** | 0.7045 | 0.7012 | -0.47% |
| **Unhealthy_for_Sensitive** | 0.1789 | 0.1956 | **+9.34%** ‚úÖ |
| **Unhealthy** | 0.5877 | 0.5945 | +1.16% |
| **Very_Unhealthy** | 0.5689 | 0.5823 | **+2.36%** ‚úÖ |
| **Hazardous** | 0.6762 | 0.6618 | -2.13% |

**Ph√°t hi·ªán:**
- ‚úÖ **Good** (+2.80%): C·∫£i thi·ªán t·ªët
- ‚úÖ **Unhealthy_for_Sensitive** (+9.34%): C·∫£i thi·ªán m·∫°nh (l·ªõp kh√≥ nh·∫•t)
- ‚úÖ **Very_Unhealthy** (+2.36%): C·∫£i thi·ªán t·ªët
- ‚ùå **Hazardous** (-2.13%): Gi·∫£m nh·∫π (c√≥ th·ªÉ do sampling)

---

## 5. Ph√¢n T√≠ch

### 5.1. Khi N√†o Label Spreading T·ªët H∆°n?

**‚úÖ Label Spreading th·∫Øng khi:**
1. **Data c√≥ manifold structure r√µ r√†ng**
   - AQI data c√≥ clustering t·ª± nhi√™n theo th·ªùi gian/tr·∫°m
   - Samples g·∫ßn nhau c√≥ nh√£n gi·ªëng nhau

2. **C·∫ßn training nhanh**
   - 1 ph√∫t vs 20-25 ph√∫t
   - Ph√π h·ª£p cho rapid prototyping

3. **Mu·ªën deterministic results**
   - Kh√¥ng c√≥ randomness trong pseudo-labeling
   - Reproducible 100%

**‚ùå Self-Training/FlexMatch th·∫Øng khi:**
1. **Dataset l·ªõn (>100K samples)**
   - Label Spreading c·∫ßn qu√° nhi·ªÅu memory
   - Sampling l√†m m·∫•t th√¥ng tin

2. **C·∫ßn F1-macro cao nh·∫•t**
   - FlexMatch: 0.5445
   - Label Spreading: 0.5398 (-0.86%)

3. **C√≥ th·ªùi gian training**
   - Self-Training c√≥ th·ªÉ ch·∫°y overnight
   - Iterative refinement t·ªët h∆°n

### 5.2. Training Time vs Performance

![Time vs Performance](./data/processed/label_spreading_experiments/time_vs_performance.png)

**Trade-off analysis:**
```
Label Spreading:  1 min  ‚Üí F1=0.5398  (Speed champion ‚ö°)
Self-Training:   20 min  ‚Üí F1=0.5343  (Baseline)
FlexMatch:       25 min  ‚Üí F1=0.5445  (Accuracy champion üèÜ)
```

**ROI (Return on Investment):**
- Label Spreading: **Best time efficiency** (1 min for 0.5398)
- FlexMatch: **Best F1-macro** (25 min for 0.5445)
- Self-Training: **Balanced** (20 min for 0.5343)

### 5.3. Memory Constraint Impact

**Original dataset:**
- Train: ~404K samples
- Labeled: ~20K (5%)
- Unlabeled: ~384K (95%)

**After sampling:**
- Train: 50K samples
- Labeled: ~20K (100% kept)
- Unlabeled: ~30K (7.8% of original)

**Impact:**
- ‚ùå M·∫•t 92.2% unlabeled data
- ‚ùå C√≥ th·ªÉ m·∫•t patterns quan tr·ªçng
- ‚úÖ V·∫´n ƒë·∫°t F1-macro t·ªët (0.5398)
- ‚úÖ Training r·∫•t nhanh (1 min)

**Gi·∫£i ph√°p:**
- S·ª≠ d·ª•ng **stratified sampling** ƒë·ªÉ gi·ªØ distribution
- Ho·∫∑c d√πng **approximate methods** (k-NN graph thay v√¨ full graph)

---

## 6. K·∫øt Lu·∫≠n

### T·ªïng K·∫øt

```
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
         LABEL SPREADING SUMMARY
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Test Accuracy:       0.5912 (+0.37% vs Self-Training)
Test F1-macro:       0.5398 (+1.03% vs Self-Training)

Training Time:       ~1 minute (20x faster!)
Memory Usage:        High (requires sampling)
Sampled Data:        50K / 404K (12.4%)

Best for:            Fast prototyping, small-medium datasets
Not recommended:     Large datasets (>100K), memory-constrained
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
```

### Decision Matrix

| Scenario | Recommended Method | L√Ω do |
|----------|-------------------|-------|
| **Large dataset (>100K)** | FlexMatch | Label Spreading c·∫ßn qu√° nhi·ªÅu memory |
| **Small dataset (<50K)** | Label Spreading | Nhanh, hi·ªáu qu·∫£, kh√¥ng c·∫ßn sampling |
| **C·∫ßn F1-macro cao nh·∫•t** | FlexMatch | +0.86% vs Label Spreading |
| **Rapid prototyping** | Label Spreading | 1 ph√∫t vs 20-25 ph√∫t |
| **Production deployment** | FlexMatch | ·ªîn ƒë·ªãnh, scalable, kh√¥ng c·∫ßn sampling |
| **Research/Analysis** | Label Spreading | Deterministic, d·ªÖ reproduce |

### Best Practices

```python
# Recommended configuration
ls_cfg = LabelSpreadingConfig(
    kernel="rbf",
    gamma=20.0,         # Balanced similarity
    alpha=0.2,          # Balanced clamping
    max_iter=30,
    sample_size=50000   # Adjust based on memory
)

# For large datasets: use stratified sampling
if train_size > 50000:
    # Keep all labeled, sample unlabeled
    labeled_idx = df[df['is_labeled']].index
    unlabeled_idx = df[~df['is_labeled']].sample(
        n=50000 - len(labeled_idx),
        random_state=42
    ).index
    df_sampled = df.loc[labeled_idx.union(unlabeled_idx)]
```

### K·∫øt H·ª£p C√°c Ph∆∞∆°ng Ph√°p

**Ensemble approach:**
```python
# Combine predictions from multiple methods
y_pred_st = self_training_model.predict(X_test)
y_pred_fm = flexmatch_model.predict(X_test)
y_pred_ls = label_spreading_model.predict(X_test)

# Voting
y_pred_ensemble = majority_vote([y_pred_st, y_pred_fm, y_pred_ls])
```

**Expected improvement:** +1-2% F1-macro

### Ti·∫øp Theo

Xem th√™m:
- [Self-Training Analysis](./BLOG_SELF_TRAINING.md) - Baseline comparison
- [FlexMatch Analysis](./BLOG_FLEXMATCH.md) - Dynamic threshold + Focal loss
- [Co-Training Analysis](./BLOG_CO_TRAINING.md) - Multi-view learning

---

## T√†i Li·ªáu Tham Kh·∫£o

### Files Li√™n Quan

- **Code:** `notebooks/semi_label_spreading.ipynb`
- **Library:** `src/semi_supervised_library.py`
  - `LabelSpreadingConfig`
  - `LabelSpreadingAQIClassifier`
  - `run_label_spreading`
- **Results:** `data/processed/label_spreading_experiments/`
  - `metrics_label_spreading.json`
  - `label_spreading_summary.json`
  - `method_comparison.csv`
- **Visualizations:**
  - `method_comparison.png`
  - `per_class_f1.png`
  - `time_vs_performance.png`

### Papers

- **Label Propagation:** [Zhu & Ghahramani, 2002 - Learning from Labeled and Unlabeled Data with Label Propagation](http://mlg.eng.cam.ac.uk/zoubin/papers/CMU-CALD-02-107.pdf)
- **Label Spreading:** [Zhou et al., 2004 - Learning with Local and Global Consistency](https://proceedings.neurips.cc/paper/2003/file/87682805257e619d49b8e0dfdc14affa-Paper.pdf)

---

<div align="center">

**Blog ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông t·ª´ k·∫øt qu·∫£ th√≠ nghi·ªám**

*Data Mining - Air Quality Prediction Project*

</div>
