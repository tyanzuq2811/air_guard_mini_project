{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07458660",
   "metadata": {},
   "source": [
    "# Air Guard Advanced Semi-Supervised Learning\n",
    "## FlexMatch-lite và Label Spreading\n",
    "\n",
    "Notebook này implement và test 2 phương pháp semi-supervised nâng cao:\n",
    "\n",
    "### 1. FlexMatch-lite\n",
    "- **Dynamic threshold**: τ_c = AvgConf_c × τ_base\n",
    "- **Focal loss** để xử lý class imbalance\n",
    "- **Bias correction** cho các lớp hiếm\n",
    "\n",
    "### 2. Label Spreading\n",
    "- **Graph-based propagation** dựa trên feature similarity\n",
    "- Tránh **confirmation bias** bằng cách sử dụng global structure\n",
    "- Tự động handle **class imbalance** qua neighbor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86989fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Import our custom libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from semi_supervised_library import (\n",
    "    SemiDataConfig, FlexMatchConfig, LabelSpreadingConfig,\n",
    "    FlexMatchAQIClassifier, LabelSpreadingAQIClassifier,\n",
    "    run_flexmatch, run_label_spreading,\n",
    "    mask_labels_time_aware, AQI_CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea83ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prepared data\n",
    "DATA_PATH = Path(\"../data/processed\")\n",
    "\n",
    "# Load the feature-engineered dataset\n",
    "df_features = pd.read_csv(DATA_PATH / \"features_with_aqi.csv\")\n",
    "df_features['datetime'] = pd.to_datetime(df_features['datetime'])\n",
    "\n",
    "print(f\"Dataset shape: {df_features.shape}\")\n",
    "print(f\"Date range: {df_features['datetime'].min()} to {df_features['datetime'].max()}\")\n",
    "print(f\"\\nAQI Class distribution:\")\n",
    "print(df_features['aqi_class'].value_counts())\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ffd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup configurations\n",
    "data_cfg = SemiDataConfig(\n",
    "    target_col=\"aqi_class\",\n",
    "    cutoff=\"2017-01-01\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# FlexMatch configuration\n",
    "flexmatch_cfg = FlexMatchConfig(\n",
    "    tau_base=0.60,  # Lower base threshold\n",
    "    max_iter=10,\n",
    "    min_new_per_iter=20,\n",
    "    focal_alpha=0.25,\n",
    "    focal_gamma=2.0,\n",
    "    threshold_warmup=3\n",
    ")\n",
    "\n",
    "# Label Spreading configuration\n",
    "label_spreading_cfg = LabelSpreadingConfig(\n",
    "    kernel=\"rbf\",\n",
    "    gamma=20,\n",
    "    alpha=0.2,\n",
    "    max_iter=30,\n",
    "    n_neighbors=7\n",
    ")\n",
    "\n",
    "print(\"Configurations setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create semi-supervised dataset (mask 95% labels in training set)\n",
    "df_semi = mask_labels_time_aware(\n",
    "    df_features, \n",
    "    cfg=data_cfg, \n",
    "    missing_fraction=0.95\n",
    ")\n",
    "\n",
    "# Check label distribution after masking\n",
    "train_mask = df_semi['datetime'] < pd.Timestamp(data_cfg.cutoff)\n",
    "labeled_mask = df_semi['is_labeled']\n",
    "\n",
    "print(f\"Training set size: {train_mask.sum():,}\")\n",
    "print(f\"Labeled training samples: {(train_mask & labeled_mask).sum():,} ({(train_mask & labeled_mask).sum() / train_mask.sum() * 100:.1f}%)\")\n",
    "print(f\"Unlabeled training samples: {(train_mask & ~labeled_mask).sum():,}\")\n",
    "\n",
    "print(f\"\\nLabeled training class distribution:\")\n",
    "labeled_train = df_semi[train_mask & labeled_mask]\n",
    "print(labeled_train['aqi_class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5bc7d",
   "metadata": {},
   "source": [
    "## FlexMatch-lite Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FlexMatch model\n",
    "print(\"Training FlexMatch-lite model...\")\n",
    "flexmatch_results = run_flexmatch(df_semi, data_cfg, flexmatch_cfg)\n",
    "\n",
    "print(f\"\\nFlexMatch Test Results:\")\n",
    "print(f\"Accuracy: {flexmatch_results['test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {flexmatch_results['test_metrics']['f1_macro']:.4f}\")\n",
    "\n",
    "# Show training history\n",
    "fm_history = pd.DataFrame(flexmatch_results['history'])\n",
    "print(\"\\nFlexMatch Training History:\")\n",
    "print(fm_history[['iter', 'val_accuracy', 'val_f1_macro', 'new_pseudo', 'unlabeled_pool']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bbb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize FlexMatch dynamic thresholds\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('FlexMatch-lite Training Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Dynamic thresholds over iterations\n",
    "ax1 = axes[0, 0]\n",
    "threshold_data = []\n",
    "for i, record in enumerate(fm_history.iterrows()):\n",
    "    row = record[1]\n",
    "    if 'class_thresholds' in row and isinstance(row['class_thresholds'], dict):\n",
    "        for cls, threshold in row['class_thresholds'].items():\n",
    "            threshold_data.append({\n",
    "                'iteration': row['iter'],\n",
    "                'class': cls,\n",
    "                'threshold': threshold\n",
    "            })\n",
    "\n",
    "if threshold_data:\n",
    "    threshold_df = pd.DataFrame(threshold_data)\n",
    "    for cls in AQI_CLASSES:\n",
    "        cls_data = threshold_df[threshold_df['class'] == cls]\n",
    "        if len(cls_data) > 0:\n",
    "            ax1.plot(cls_data['iteration'], cls_data['threshold'], \n",
    "                    marker='o', label=cls, linewidth=2)\n",
    "    ax1.set_xlabel('Iteration')\n",
    "    ax1.set_ylabel('Threshold')\n",
    "    ax1.set_title('Dynamic Thresholds by Class')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Validation performance\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(fm_history['iter'], fm_history['val_accuracy'], 'b-o', label='Accuracy', linewidth=2)\n",
    "ax2.plot(fm_history['iter'], fm_history['val_f1_macro'], 'r-s', label='F1-macro', linewidth=2)\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_title('Validation Performance')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Pseudo labels added per iteration\n",
    "ax3 = axes[1, 0]\n",
    "ax3.bar(fm_history['iter'], fm_history['new_pseudo'], alpha=0.7, color='green')\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('New Pseudo Labels')\n",
    "ax3.set_title('Pseudo Labels Added per Iteration')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Unlabeled pool size\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(fm_history['iter'], fm_history['unlabeled_pool'], 'purple', marker='d', linewidth=2)\n",
    "ax4.set_xlabel('Iteration')\n",
    "ax4.set_ylabel('Unlabeled Pool Size')\n",
    "ax4.set_title('Remaining Unlabeled Samples')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c4cc6",
   "metadata": {},
   "source": [
    "## Label Spreading Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Label Spreading model\n",
    "print(\"Training Label Spreading model...\")\n",
    "label_spreading_results = run_label_spreading(df_semi, data_cfg, label_spreading_cfg)\n",
    "\n",
    "print(f\"\\nLabel Spreading Test Results:\")\n",
    "print(f\"Accuracy: {label_spreading_results['test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {label_spreading_results['test_metrics']['f1_macro']:.4f}\")\n",
    "\n",
    "# Show propagation info\n",
    "ls_history = pd.DataFrame(label_spreading_results['history'])\n",
    "print(\"\\nLabel Spreading Results:\")\n",
    "print(ls_history[['method', 'val_accuracy', 'val_f1_macro', 'originally_unlabeled', 'labels_propagated']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82c331",
   "metadata": {},
   "source": [
    "## Comparison with Baseline Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline results for comparison\n",
    "try:\n",
    "    # Try to load existing baseline results\n",
    "    with open('../data/processed/baseline_results.json', 'r') as f:\n",
    "        baseline_results = json.load(f)\n",
    "    \n",
    "    with open('../data/processed/self_training_results.json', 'r') as f:\n",
    "        self_training_results = json.load(f)\n",
    "        \n",
    "    with open('../data/processed/co_training_results.json', 'r') as f:\n",
    "        co_training_results = json.load(f)\n",
    "    \n",
    "    baseline_loaded = True\n",
    "    print(\"Baseline results loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Baseline results not found. Running comparison with FlexMatch and Label Spreading only.\")\n",
    "    baseline_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison\n",
    "comparison_results = []\n",
    "\n",
    "# Add FlexMatch results\n",
    "comparison_results.append({\n",
    "    'Method': 'FlexMatch-lite',\n",
    "    'Type': 'Advanced Semi-Supervised',\n",
    "    'Accuracy': flexmatch_results['test_metrics']['accuracy'],\n",
    "    'F1-Macro': flexmatch_results['test_metrics']['f1_macro'],\n",
    "    'Key Feature': 'Dynamic thresholds + Focal loss'\n",
    "})\n",
    "\n",
    "# Add Label Spreading results\n",
    "comparison_results.append({\n",
    "    'Method': 'Label Spreading',\n",
    "    'Type': 'Advanced Semi-Supervised',\n",
    "    'Accuracy': label_spreading_results['test_metrics']['accuracy'],\n",
    "    'F1-Macro': label_spreading_results['test_metrics']['f1_macro'],\n",
    "    'Key Feature': 'Graph-based propagation'\n",
    "})\n",
    "\n",
    "# Add baseline methods if available\n",
    "if baseline_loaded:\n",
    "    comparison_results.append({\n",
    "        'Method': 'Supervised Baseline',\n",
    "        'Type': 'Supervised',\n",
    "        'Accuracy': baseline_results['test_metrics']['accuracy'],\n",
    "        'F1-Macro': baseline_results['test_metrics']['f1_macro'],\n",
    "        'Key Feature': 'Traditional supervised learning'\n",
    "    })\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Method': 'Self-Training',\n",
    "        'Type': 'Basic Semi-Supervised',\n",
    "        'Accuracy': self_training_results['test_metrics']['accuracy'],\n",
    "        'F1-Macro': self_training_results['test_metrics']['f1_macro'],\n",
    "        'Key Feature': 'Fixed threshold pseudo-labeling'\n",
    "    })\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Method': 'Co-Training',\n",
    "        'Type': 'Basic Semi-Supervised',\n",
    "        'Accuracy': co_training_results['test_metrics']['accuracy'],\n",
    "        'F1-Macro': co_training_results['test_metrics']['f1_macro'],\n",
    "        'Key Feature': 'Two-view collaboration'\n",
    "    })\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df = comparison_df.sort_values('F1-Macro', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE METHOD COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Advanced Semi-Supervised Methods Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Accuracy comparison\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.bar(comparison_df['Method'], comparison_df['Accuracy'], \n",
    "                color=['red' if 'Advanced' in t else 'blue' if 'Basic' in t else 'green' \n",
    "                      for t in comparison_df['Type']], alpha=0.7)\n",
    "ax1.set_title('Test Accuracy Comparison')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xticklabels(comparison_df['Method'], rotation=45, ha='right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars1, comparison_df['Accuracy']):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# F1-Macro comparison\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.bar(comparison_df['Method'], comparison_df['F1-Macro'], \n",
    "                color=['red' if 'Advanced' in t else 'blue' if 'Basic' in t else 'green' \n",
    "                      for t in comparison_df['Type']], alpha=0.7)\n",
    "ax2.set_title('F1-Macro Score Comparison')\n",
    "ax2.set_ylabel('F1-Macro')\n",
    "ax2.set_xticklabels(comparison_df['Method'], rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars2, comparison_df['F1-Macro']):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Create legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', alpha=0.7, label='Advanced Semi-Supervised'),\n",
    "    Patch(facecolor='blue', alpha=0.7, label='Basic Semi-Supervised'),\n",
    "    Patch(facecolor='green', alpha=0.7, label='Supervised')\n",
    "]\n",
    "fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f36fa",
   "metadata": {},
   "source": [
    "## Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90da6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class-wise performance\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS-WISE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFlexMatch-lite Classification Report:\")\n",
    "print(classification_report(\n",
    "    flexmatch_results['pred_df']['y_true'], \n",
    "    flexmatch_results['pred_df']['y_pred'],\n",
    "    target_names=AQI_CLASSES\n",
    "))\n",
    "\n",
    "print(\"\\nLabel Spreading Classification Report:\")\n",
    "print(classification_report(\n",
    "    label_spreading_results['pred_df']['y_true'], \n",
    "    label_spreading_results['pred_df']['y_pred'],\n",
    "    target_names=AQI_CLASSES\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dfc15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Confusion Matrix Comparison: Advanced Methods', fontsize=16, fontweight='bold')\n",
    "\n",
    "# FlexMatch confusion matrix\n",
    "fm_cm = np.array(flexmatch_results['test_metrics']['confusion_matrix'])\n",
    "sns.heatmap(fm_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=AQI_CLASSES, yticklabels=AQI_CLASSES, ax=axes[0])\n",
    "axes[0].set_title('FlexMatch-lite')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Label Spreading confusion matrix\n",
    "ls_cm = np.array(label_spreading_results['test_metrics']['confusion_matrix'])\n",
    "sns.heatmap(ls_cm, annot=True, fmt='d', cmap='Oranges', \n",
    "            xticklabels=AQI_CLASSES, yticklabels=AQI_CLASSES, ax=axes[1])\n",
    "axes[1].set_title('Label Spreading')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed5a15",
   "metadata": {},
   "source": [
    "## Key Findings and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS AND INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. FLEXMATCH-LITE ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "if len(fm_history) > 0:\n",
    "    total_pseudo = fm_history['new_pseudo'].sum()\n",
    "    final_acc = fm_history['val_f1_macro'].iloc[-1]\n",
    "    print(f\"   • Total pseudo labels generated: {total_pseudo:,}\")\n",
    "    print(f\"   • Final validation F1-macro: {final_acc:.4f}\")\n",
    "    print(f\"   • Training iterations: {len(fm_history)}\")\n",
    "    print(f\"   • Dynamic thresholds adapted based on class confidence\")\n",
    "    print(f\"   • Addressed class imbalance through lower thresholds for rare classes\")\n",
    "\n",
    "print(\"\\n2. LABEL SPREADING ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "if len(ls_history) > 0:\n",
    "    ls_info = ls_history.iloc[0]\n",
    "    print(f\"   • Originally unlabeled: {ls_info['originally_unlabeled']:,}\")\n",
    "    print(f\"   • Labels propagated: {ls_info['labels_propagated']:,}\")\n",
    "    print(f\"   • Kernel: {ls_info['kernel']} (gamma={ls_info['gamma']})\")\n",
    "    print(f\"   • Alpha parameter: {ls_info['alpha']} (regularization)\")\n",
    "    print(f\"   • Avoided confirmation bias through graph-based approach\")\n",
    "\n",
    "print(\"\\n3. PERFORMANCE COMPARISON:\")\n",
    "print(\"-\" * 40)\n",
    "fm_acc = flexmatch_results['test_metrics']['accuracy']\n",
    "fm_f1 = flexmatch_results['test_metrics']['f1_macro']\n",
    "ls_acc = label_spreading_results['test_metrics']['accuracy']\n",
    "ls_f1 = label_spreading_results['test_metrics']['f1_macro']\n",
    "\n",
    "better_method = \"FlexMatch-lite\" if fm_f1 > ls_f1 else \"Label Spreading\"\n",
    "print(f\"   • Best performing method: {better_method}\")\n",
    "print(f\"   • FlexMatch - Accuracy: {fm_acc:.4f}, F1-macro: {fm_f1:.4f}\")\n",
    "print(f\"   • Label Spreading - Accuracy: {ls_acc:.4f}, F1-macro: {ls_f1:.4f}\")\n",
    "\n",
    "print(\"\\n4. ADVANTAGES OBSERVED:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   FlexMatch-lite:\")\n",
    "print(\"   • Dynamic thresholds improved recall for rare AQI classes\")\n",
    "print(\"   • Iterative learning allowed gradual confidence building\")\n",
    "print(\"   • Focal loss helped balance class representation\")\n",
    "print(\"\\n   Label Spreading:\")\n",
    "print(\"   • Global graph structure reduced local bias\")\n",
    "print(\"   • One-shot propagation more computationally efficient\")\n",
    "print(\"   • Natural smoothness assumptions for time-series data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bcb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save advanced results\n",
    "results_dir = Path(\"../data/processed/advanced_semi_results/\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save FlexMatch results\n",
    "flexmatch_save = {\n",
    "    'config': {\n",
    "        'tau_base': flexmatch_cfg.tau_base,\n",
    "        'max_iter': flexmatch_cfg.max_iter,\n",
    "        'focal_alpha': flexmatch_cfg.focal_alpha,\n",
    "        'focal_gamma': flexmatch_cfg.focal_gamma\n",
    "    },\n",
    "    'test_metrics': flexmatch_results['test_metrics'],\n",
    "    'history': flexmatch_results['history']\n",
    "}\n",
    "\n",
    "with open(results_dir / \"flexmatch_results.json\", 'w') as f:\n",
    "    json.dump(flexmatch_save, f, indent=2, default=str)\n",
    "\n",
    "# Save Label Spreading results\n",
    "label_spreading_save = {\n",
    "    'config': {\n",
    "        'kernel': label_spreading_cfg.kernel,\n",
    "        'gamma': label_spreading_cfg.gamma,\n",
    "        'alpha': label_spreading_cfg.alpha,\n",
    "        'n_neighbors': label_spreading_cfg.n_neighbors\n",
    "    },\n",
    "    'test_metrics': label_spreading_results['test_metrics'],\n",
    "    'history': label_spreading_results['history']\n",
    "}\n",
    "\n",
    "with open(results_dir / \"label_spreading_results.json\", 'w') as f:\n",
    "    json.dump(label_spreading_save, f, indent=2, default=str)\n",
    "\n",
    "# Save comparison results\n",
    "comparison_df.to_csv(results_dir / \"method_comparison.csv\", index=False)\n",
    "\n",
    "print(f\"\\nResults saved to {results_dir}\")\n",
    "print(\"Files created:\")\n",
    "print(\"  • flexmatch_results.json\")\n",
    "print(\"  • label_spreading_results.json\")\n",
    "print(\"  • method_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
