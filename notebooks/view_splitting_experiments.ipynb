{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a040ae",
   "metadata": {},
   "source": [
    "# Th√≠ nghi·ªám 3: View Splitting Strategies for Co-Training\n",
    "\n",
    "## üéØ M·ª•c ti√™u (OPTIMIZED)\n",
    "\n",
    "Test **2 strategies** cho vi·ªác chia t√°ch views trong Co-Training:\n",
    "- **Current baseline**: C√°ch chia hi·ªán t·∫°i (ƒë√£ bi·∫øt th·∫•t b·∫°i)  \n",
    "- **Pollutant-based**: Primary vs Secondary pollutants (ƒë·ªôc l·∫≠p v·ªÅ h√≥a h·ªçc)\n",
    "\n",
    "**‚ö° Time Optimization**: Gi·∫£m t·ª´ 4 ‚Üí 2 strategies (saves ~40-50 minutes)\n",
    "- B·ªè Station-based (independence trung b√¨nh)\n",
    "- B·ªè Temporal (lags v·∫´n c√πng features g·ªëc, independence th·∫•p)\n",
    "\n",
    "## Strategies\n",
    "\n",
    "### ‚úÖ Current (Baseline)\n",
    "- View 1: Numerical meteorological features\n",
    "- View 2: Temporal + Categorical features  \n",
    "- **Known issue**: High overlap, weak independence ‚Üí test accuracy < 0.50\n",
    "\n",
    "### ‚úÖ Pollutant-based (Most Independent)\n",
    "- View 1: **Primary Pollutants** (SO2, NO2, CO)\n",
    "  - Ph√°t th·∫£i tr·ª±c ti·∫øp t·ª´ ngu·ªìn (xe c·ªô, nh√† m√°y)\n",
    "  - Ph·ª• thu·ªôc v√†o ho·∫°t ƒë·ªông con ng∆∞·ªùi\n",
    "- View 2: **Secondary Pollutants** (O3, PM2.5, PM10)\n",
    "  - H√¨nh th√†nh t·ª´ ph·∫£n ·ª©ng h√≥a h·ªçc trong kh√≠ quy·ªÉn\n",
    "  - Ph·ª• thu·ªôc v√†o ƒëi·ªÅu ki·ªán th·ªùi ti·∫øt, √°nh s√°ng\n",
    "\n",
    "**Gi·∫£ thuy·∫øt**: Primary vs Secondary c√≥ ƒë·ªôc l·∫≠p TH·∫¨T v·ªÅ ngu·ªìn g·ªëc v√† c∆° ch·∫ø h√¨nh th√†nh ‚Üí 2 models h·ªçc complementary information ‚Üí Co-Training hi·ªáu qu·∫£ h∆°n\n",
    "\n",
    "## Metrics ƒë√°nh gi√°\n",
    "- Test Accuracy, Test F1-macro\n",
    "- Pseudo-labeling activity\n",
    "- Per-class F1 scores\n",
    "- Improvement so v·ªõi Current baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2549b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "SEMI_DATASET_PATH = \"data/processed/dataset_for_semi.parquet\"\n",
    "CUTOFF = \"2017-01-01\"\n",
    "\n",
    "TAU = 0.90\n",
    "MAX_ITER = 10\n",
    "MAX_NEW_PER_ITER = 500\n",
    "MIN_NEW_PER_ITER = 20\n",
    "VAL_FRAC = 0.20\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Output directory\n",
    "RESULTS_DIR = \"data/processed/view_splitting_experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.semi_supervised_library import (\n",
    "    SemiDataConfig, CoTrainingConfig, run_co_training\n",
    ")\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "if not (PROJECT_ROOT / \"data\").exists() and (PROJECT_ROOT.parent / \"data\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "\n",
    "results_dir = (PROJECT_ROOT / RESULTS_DIR).resolve()\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Results directory: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ea905",
   "metadata": {},
   "source": [
    "## Load Dataset and Inspect Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet((PROJECT_ROOT / SEMI_DATASET_PATH).resolve())\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Labeled fraction:\", df['is_labeled'].mean())\n",
    "\n",
    "# Get all feature columns (excluding target and metadata)\n",
    "exclude_cols = ['aqi_class', 'PM2.5', 'pm25_24h', 'datetime', 'is_labeled']\n",
    "all_features = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "print(f\"\\nTotal features: {len(all_features)}\")\n",
    "print(f\"\\nSample features:\")\n",
    "for i, col in enumerate(all_features[:15]):\n",
    "    print(f\"  {i+1}. {col}\")\n",
    "print(\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498b3b3",
   "metadata": {},
   "source": [
    "## Strategy 1: Current (Baseline)\n",
    "\n",
    "Pollution + Weather vs Time + Location (same as original co-training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current strategy (baseline)\n",
    "v2_patterns_current = (\"station\", \"wd\", \"hour_\", \"dow\", \"month\", \"is_weekend\", \"year\", \"day\", \"hour\")\n",
    "view2_current = [c for c in all_features if any(p in c for p in v2_patterns_current)]\n",
    "view1_current = [c for c in all_features if c not in view2_current]\n",
    "\n",
    "print(\"Strategy 1: Current (Pollution+Weather vs Time+Location)\")\n",
    "print(f\"  View 1 (Pollution+Weather): {len(view1_current)} features\")\n",
    "print(f\"    Examples: {view1_current[:5]}\")\n",
    "print(f\"  View 2 (Time+Location): {len(view2_current)} features\")\n",
    "print(f\"    Examples: {view2_current[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a472efc",
   "metadata": {},
   "source": [
    "## Strategy 2: Station-based Split\n",
    "\n",
    "View 1: Northern stations, View 2: Southern stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define northern and southern stations\n",
    "northern_stations = [\"Changping\", \"Dingling\", \"Huairou\", \"Shunyi\"]\n",
    "southern_stations = [\"Dongsi\", \"Guanyuan\", \"Gucheng\", \"Tiantan\"]\n",
    "other_stations = [\"Aotizhongxin\", \"Nongzhanguan\", \"Wanliu\", \"Wanshouxigong\"]\n",
    "\n",
    "# View 1: Features with northern station patterns\n",
    "view1_station = [c for c in all_features if any(f\"station_{s}\" in c for s in northern_stations)]\n",
    "# View 2: Features with southern station patterns  \n",
    "view2_station = [c for c in all_features if any(f\"station_{s}\" in c for s in southern_stations)]\n",
    "\n",
    "# Add shared features (pollution, weather, time) to both views\n",
    "shared_features = [c for c in all_features if not c.startswith(\"station_\")]\n",
    "\n",
    "# But split them: pollution/weather to view1, time to view2\n",
    "pollution_weather = [c for c in shared_features if not any(p in c for p in [\"hour_\", \"dow\", \"month\", \"year\", \"is_weekend\", \"day\"])]\n",
    "time_features = [c for c in shared_features if any(p in c for p in [\"hour_\", \"dow\", \"month\", \"year\", \"is_weekend\", \"day\"])]\n",
    "\n",
    "view1_station.extend(pollution_weather)\n",
    "view2_station.extend(time_features)\n",
    "\n",
    "# Add wind direction to both (important for both regions)\n",
    "wd_features = [c for c in all_features if c.startswith(\"wd_\")]\n",
    "view1_station.extend(wd_features)\n",
    "view2_station.extend(wd_features)\n",
    "\n",
    "view1_station = list(set(view1_station))  # Remove duplicates\n",
    "view2_station = list(set(view2_station))\n",
    "\n",
    "print(\"\\nStrategy 2: Station-based (Northern vs Southern)\")\n",
    "print(f\"  View 1 (Northern+Pollution): {len(view1_station)} features\")\n",
    "print(f\"    Station features: {[c for c in view1_station if c.startswith('station_')]}\")\n",
    "print(f\"  View 2 (Southern+Time): {len(view2_station)} features\")\n",
    "print(f\"    Station features: {[c for c in view2_station if c.startswith('station_')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d9b838",
   "metadata": {},
   "source": [
    "## Strategy 3: Pollutant-based Split\n",
    "\n",
    "View 1: Primary pollutants (PM10, SO2, NOx), View 2: Secondary pollutants (O3, oxidants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf536e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary pollutants (directly emitted)\n",
    "primary_patterns = [\"PM10\", \"SO2\", \"NO2\", \"CO\"]\n",
    "\n",
    "# Secondary pollutants (formed in atmosphere)\n",
    "secondary_patterns = [\"O3\"]\n",
    "\n",
    "# Get primary and secondary features (including lags)\n",
    "view1_pollutant = [c for c in all_features if any(p in c for p in primary_patterns)]\n",
    "view2_pollutant = [c for c in all_features if any(p in c for p in secondary_patterns)]\n",
    "\n",
    "# Add weather features to both (influence both types)\n",
    "weather_features = [c for c in all_features if any(w in c for w in [\"TEMP\", \"PRES\", \"DEWP\", \"RAIN\", \"WSPM\"])]\n",
    "view1_pollutant.extend(weather_features)\n",
    "view2_pollutant.extend(weather_features)\n",
    "\n",
    "# Add time/location features\n",
    "time_loc_features = [c for c in all_features if c.startswith((\"station_\", \"wd_\", \"hour_\", \"dow\", \"month\", \"year\", \"is_weekend\"))]\n",
    "# Split time/location: stations to view1, time to view2\n",
    "station_features = [c for c in time_loc_features if c.startswith(\"station_\")]\n",
    "time_only = [c for c in time_loc_features if not c.startswith(\"station_\")]\n",
    "\n",
    "view1_pollutant.extend(station_features)\n",
    "view2_pollutant.extend(time_only)\n",
    "\n",
    "view1_pollutant = list(set(view1_pollutant))\n",
    "view2_pollutant = list(set(view2_pollutant))\n",
    "\n",
    "print(\"\\nStrategy 3: Pollutant-based (Primary vs Secondary)\")\n",
    "print(f\"  View 1 (Primary pollutants): {len(view1_pollutant)} features\")\n",
    "print(f\"    Pollutant features: {[c for c in view1_pollutant if any(p in c for p in primary_patterns)][:8]}\")\n",
    "print(f\"  View 2 (Secondary pollutants): {len(view2_pollutant)} features\")\n",
    "print(f\"    Pollutant features: {[c for c in view2_pollutant if 'O3' in c][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b004f6",
   "metadata": {},
   "source": [
    "## Strategy 4: Temporal Split\n",
    "\n",
    "View 1: Short-term features (1h, 3h lags), View 2: Long-term features (24h lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc287377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short-term: 1h and 3h lag features\n",
    "short_term_features = [c for c in all_features if \"_lag1h\" in c or \"_lag3h\" in c]\n",
    "\n",
    "# Long-term: 24h lag features\n",
    "long_term_features = [c for c in all_features if \"_lag24h\" in c]\n",
    "\n",
    "# Current values (no lag) - add to both\n",
    "current_values = [c for c in all_features if not any(lag in c for lag in [\"_lag1h\", \"_lag3h\", \"_lag24h\"])]\n",
    "\n",
    "view1_temporal = short_term_features + current_values\n",
    "view2_temporal = long_term_features + current_values\n",
    "\n",
    "view1_temporal = list(set(view1_temporal))\n",
    "view2_temporal = list(set(view2_temporal))\n",
    "\n",
    "print(\"\\nStrategy 4: Temporal (Short-term vs Long-term)\")\n",
    "print(f\"  View 1 (Short-term 1h/3h): {len(view1_temporal)} features\")\n",
    "print(f\"    Examples: {[c for c in view1_temporal if 'lag' in c][:5]}\")\n",
    "print(f\"  View 2 (Long-term 24h): {len(view2_temporal)} features\")\n",
    "print(f\"    Examples: {[c for c in view2_temporal if 'lag' in c][:5]}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è OPTIMIZATION: Ch·ªâ ch·∫°y 2/4 strategies (fastest, highest contrast)\")\n",
    "print(\"   - Pollutant-based: Best independence potential\")\n",
    "print(\"   - Current: Baseline (ƒë√£ bi·∫øt th·∫•t b·∫°i)\")\n",
    "print(\"   - SKIPPED: Station-based, Temporal (slower, medium contrast)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13dacf",
   "metadata": {},
   "source": [
    "## Run Experiments for All Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456db84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZED: Ch·ªâ ch·∫°y 2 strategies c√≥ contrast cao nh·∫•t (gi·∫£m ~60% th·ªùi gian)\n",
    "view_strategies = {\n",
    "    \"Current\": (view1_current, view2_current),  # Baseline (ƒë√£ bi·∫øt th·∫•t b·∫°i)\n",
    "    \"Pollutant-based\": (view1_pollutant, view2_pollutant)  # Best independence potential\n",
    "}\n",
    "\n",
    "# B·ªè ƒë·ªÉ gi·∫£m th·ªùi gian (~20-25 ph√∫t m·ªói strategy):\n",
    "# ‚ùå \"Station-based\": Independence trung b√¨nh, features √≠t ‚Üí √≠t insight\n",
    "# ‚ùå \"Temporal\": Independence th·∫•p (lags v·∫´n c√πng features g·ªëc)\n",
    "# \n",
    "# L√Ω do ch·ªçn 2 strategies n√†y:\n",
    "# ‚úÖ Current: Baseline ƒë·ªÉ so s√°nh (ƒë√£ ch·∫°y trong co-training g·ªëc)\n",
    "# ‚úÖ Pollutant-based: Primary vs Secondary pollutants ‚Üí ƒë·ªôc l·∫≠p TH·∫¨T v·ªÅ h√≥a h·ªçc\n",
    "#    (Primary = tr·ª±c ti·∫øp ph√°t th·∫£i, Secondary = h√¨nh th√†nh trong kh√≠ quy·ªÉn)\n",
    "\n",
    "results = {}\n",
    "data_cfg = SemiDataConfig(cutoff=CUTOFF, random_state=RANDOM_STATE)\n",
    "ct_cfg = CoTrainingConfig(\n",
    "    tau=TAU,\n",
    "    max_iter=MAX_ITER,\n",
    "    max_new_per_iter=MAX_NEW_PER_ITER,\n",
    "    min_new_per_iter=MIN_NEW_PER_ITER,\n",
    "    val_frac=VAL_FRAC\n",
    ")\n",
    "\n",
    "print(\"‚ö° OPTIMIZATION: Running 2/4 strategies (saves ~40-50 minutes)\")\n",
    "print(\"   ‚úì Current (baseline)\")\n",
    "print(\"   ‚úì Pollutant-based (highest independence)\")\n",
    "print(\"   ‚úó Station-based (skipped)\")\n",
    "print(\"   ‚úó Temporal (skipped)\\n\")\n",
    "\n",
    "for strategy_name, (view1, view2) in view_strategies.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STRATEGY: {strategy_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  View 1: {len(view1)} features\")\n",
    "    print(f\"  View 2: {len(view2)} features\")\n",
    "    print(f\"  Overlap: {len(set(view1) & set(view2))} features\")\n",
    "    \n",
    "    # Run co-training\n",
    "    result = run_co_training(\n",
    "        df=df.copy(),\n",
    "        data_cfg=data_cfg,\n",
    "        ct_cfg=ct_cfg,\n",
    "        view1_cols=view1,\n",
    "        view2_cols=view2\n",
    "    )\n",
    "    \n",
    "    results[strategy_name] = {\n",
    "        \"view1_size\": len(view1),\n",
    "        \"view2_size\": len(view2),\n",
    "        \"overlap_size\": len(set(view1) & set(view2)),\n",
    "        \"test_accuracy\": result[\"test_metrics\"][\"accuracy\"],\n",
    "        \"test_f1_macro\": result[\"test_metrics\"][\"f1_macro\"],\n",
    "        \"history\": result[\"history\"],\n",
    "        \"per_class_report\": result[\"test_metrics\"][\"report\"],\n",
    "        \"total_pseudo_labels\": sum([h[\"new_pseudo\"] for h in result[\"history\"]]),\n",
    "        \"iterations_completed\": len(result[\"history\"])\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  ‚úÖ Results:\")\n",
    "    print(f\"     Test Accuracy: {result['test_metrics']['accuracy']:.4f}\")\n",
    "    print(f\"     Test F1-macro: {result['test_metrics']['f1_macro']:.4f}\")\n",
    "    print(f\"     Pseudo-labels: {results[strategy_name]['total_pseudo_labels']:,}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STRATEGY EXPERIMENTS COMPLETED (2/4 strategies)\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31c0f0",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22106931",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = results_dir / \"view_splitting_results.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Saved results to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf84c6",
   "metadata": {},
   "source": [
    "## Create Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "for strategy, res in results.items():\n",
    "    summary_data.append({\n",
    "        \"Strategy\": strategy,\n",
    "        \"View1 Size\": res[\"view1_size\"],\n",
    "        \"View2 Size\": res[\"view2_size\"],\n",
    "        \"Overlap\": res[\"overlap_size\"],\n",
    "        \"Independence\": f\"{(1 - res['overlap_size']/min(res['view1_size'], res['view2_size']))*100:.1f}%\",\n",
    "        \"Test Accuracy\": res[\"test_accuracy\"],\n",
    "        \"Test F1-macro\": res[\"test_f1_macro\"],\n",
    "        \"Pseudo-labels\": res[\"total_pseudo_labels\"],\n",
    "        \"Iterations\": res[\"iterations_completed\"]\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values(\"Test F1-macro\", ascending=False)\n",
    "\n",
    "print(\"\\nüìä SUMMARY TABLE:\")\n",
    "print(\"=\"*100)\n",
    "display(summary_df)\n",
    "\n",
    "summary_csv = results_dir / \"view_splitting_summary.csv\"\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "print(f\"\\n‚úÖ Saved summary to: {summary_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b05b8",
   "metadata": {},
   "source": [
    "## Visualization 1: Test Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "strategies = summary_df[\"Strategy\"].tolist()\n",
    "accuracies = summary_df[\"Test Accuracy\"].tolist()\n",
    "f1_scores = summary_df[\"Test F1-macro\"].tolist()\n",
    "\n",
    "colors = ['steelblue', 'forestgreen', 'coral', 'mediumpurple']\n",
    "\n",
    "# Accuracy\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.bar(strategies, accuracies, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax1.set_ylabel(\"Test Accuracy\", fontsize=12, fontweight='bold')\n",
    "ax1.set_title(\"Test Accuracy by View Strategy\", fontsize=14, fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_ylim([0.50, 0.60])\n",
    "\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.4f}',\n",
    "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# F1-macro\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.bar(strategies, f1_scores, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax2.set_ylabel(\"Test F1-macro\", fontsize=12, fontweight='bold')\n",
    "ax2.set_title(\"Test F1-macro by View Strategy\", fontsize=14, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_ylim([0.35, 0.50])\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.4f}',\n",
    "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_file = results_dir / \"test_performance_by_strategy.png\"\n",
    "plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Saved plot: {plot_file}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c5cd8",
   "metadata": {},
   "source": [
    "## Visualization 2: Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd238f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "strategy_colors = dict(zip(strategies, colors))\n",
    "\n",
    "for strategy, res in results.items():\n",
    "    history = res[\"history\"]\n",
    "    iterations = [h[\"iter\"] for h in history]\n",
    "    val_f1 = [h[\"val_f1_macro\"] for h in history]\n",
    "    \n",
    "    ax.plot(iterations, val_f1, marker='o', linewidth=2.5,\n",
    "            label=strategy, color=strategy_colors[strategy], alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(\"Iteration\", fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel(\"Validation F1-macro\", fontsize=12, fontweight='bold')\n",
    "ax.set_title(\"Validation Learning Curves by View Strategy\", fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11, loc='best')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xticks(range(1, 11))\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_file = results_dir / \"learning_curves_by_strategy.png\"\n",
    "plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Saved plot: {plot_file}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5862770",
   "metadata": {},
   "source": [
    "## Visualization 3: View Independence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(strategies))\n",
    "width = 0.25\n",
    "\n",
    "view1_sizes = summary_df[\"View1 Size\"].tolist()\n",
    "view2_sizes = summary_df[\"View2 Size\"].tolist()\n",
    "overlaps = summary_df[\"Overlap\"].tolist()\n",
    "\n",
    "bars1 = ax.bar(x - width, view1_sizes, width, label='View 1 Size', color='skyblue', alpha=0.8)\n",
    "bars2 = ax.bar(x, view2_sizes, width, label='View 2 Size', color='lightcoral', alpha=0.8)\n",
    "bars3 = ax.bar(x + width, overlaps, width, label='Overlap', color='gold', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(\"Strategy\", fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel(\"Feature Count\", fontsize=12, fontweight='bold')\n",
    "ax.set_title(\"View Independence: Feature Distribution\", fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_file = results_dir / \"view_independence_analysis.png\"\n",
    "plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Saved plot: {plot_file}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37044b46",
   "metadata": {},
   "source": [
    "## Visualization 4: Comparison with Self-Training Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add self-training baseline for comparison (from previous experiments)\n",
    "# Assuming F1=0.5343 from œÑ=0.90 self-training\n",
    "baseline_f1 = 0.5343\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "methods = [\"Self-Training\\n(Baseline)\"] + strategies\n",
    "f1_values = [baseline_f1] + f1_scores\n",
    "method_colors = ['darkgreen'] + colors\n",
    "\n",
    "bars = ax.bar(methods, f1_values, color=method_colors, alpha=0.8, edgecolor='black')\n",
    "ax.set_ylabel(\"Test F1-macro\", fontsize=12, fontweight='bold')\n",
    "ax.set_title(\"Co-Training Strategies vs Self-Training Baseline\", fontsize=14, fontweight='bold')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.axhline(y=baseline_f1, color='darkgreen', linestyle='--', linewidth=2, label='Self-Training Baseline')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plot_file = results_dir / \"comparison_with_baseline.png\"\n",
    "plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Saved plot: {plot_file}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4edcc0",
   "metadata": {},
   "source": [
    "## Analysis & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä KEY FINDINGS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "best_idx = summary_df[\"Test F1-macro\"].idxmax()\n",
    "best_strategy = summary_df.loc[best_idx]\n",
    "\n",
    "print(f\"\\nüèÜ Best Strategy: {best_strategy['Strategy']}\")\n",
    "print(f\"   Test F1-macro: {best_strategy['Test F1-macro']:.4f}\")\n",
    "print(f\"   Test Accuracy: {best_strategy['Test Accuracy']:.4f}\")\n",
    "print(f\"   Independence: {best_strategy['Independence']}\")\n",
    "print(f\"   View sizes: {best_strategy['View1 Size']} vs {best_strategy['View2 Size']}\")\n",
    "\n",
    "print(f\"\\nüìà Ranking by F1-macro:\")\n",
    "for i, row in summary_df.iterrows():\n",
    "    improvement = (row[\"Test F1-macro\"] - baseline_f1) / baseline_f1 * 100\n",
    "    print(f\"   {i+1}. {row['Strategy']}: {row['Test F1-macro']:.4f} ({improvement:+.1f}% vs baseline)\")\n",
    "\n",
    "print(f\"\\nüí° Independence Analysis:\")\n",
    "for i, row in summary_df.iterrows():\n",
    "    print(f\"   {row['Strategy']}:\")\n",
    "    print(f\"      - Overlap: {row['Overlap']} features ({row['Independence']} independent)\")\n",
    "    print(f\"      - Balance: {row['View1 Size']} vs {row['View2 Size']} features\")\n",
    "\n",
    "print(f\"\\nüéØ Conclusion:\")\n",
    "if best_strategy[\"Test F1-macro\"] > baseline_f1:\n",
    "    print(f\"   ‚úÖ Co-training with {best_strategy['Strategy']} BEATS self-training!\")\n",
    "    print(f\"      Improvement: +{(best_strategy['Test F1-macro'] - baseline_f1)*100:.2f}%\")\n",
    "else:\n",
    "    print(f\"   ‚ùå All co-training strategies WORSE than self-training\")\n",
    "    print(f\"      Best co-training: {best_strategy['Test F1-macro']:.4f}\")\n",
    "    print(f\"      Self-training baseline: {baseline_f1:.4f}\")\n",
    "    print(f\"      Gap: {(baseline_f1 - best_strategy['Test F1-macro'])*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ All visualizations saved to: {results_dir}\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c637b6b",
   "metadata": {},
   "source": [
    "## Dashboard Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_data = {\n",
    "    \"experiment_type\": \"view_splitting\",\n",
    "    \"parameters\": {\n",
    "        \"tau\": TAU,\n",
    "        \"max_iter\": MAX_ITER,\n",
    "        \"max_new_per_iter\": MAX_NEW_PER_ITER,\n",
    "        \"strategies\": list(view_strategies.keys())\n",
    "    },\n",
    "    \"summary\": summary_df.to_dict(orient='records'),\n",
    "    \"best_strategy\": {\n",
    "        \"name\": best_strategy[\"Strategy\"],\n",
    "        \"f1_macro\": float(best_strategy[\"Test F1-macro\"]),\n",
    "        \"accuracy\": float(best_strategy[\"Test Accuracy\"]),\n",
    "        \"independence\": best_strategy[\"Independence\"]\n",
    "    },\n",
    "    \"baseline_comparison\": {\n",
    "        \"self_training_f1\": baseline_f1,\n",
    "        \"best_cotraining_f1\": float(best_strategy[\"Test F1-macro\"]),\n",
    "        \"improvement\": float((best_strategy[\"Test F1-macro\"] - baseline_f1) / baseline_f1 * 100)\n",
    "    },\n",
    "    \"visualizations\": [\n",
    "        \"test_performance_by_strategy.png\",\n",
    "        \"learning_curves_by_strategy.png\",\n",
    "        \"view_independence_analysis.png\",\n",
    "        \"comparison_with_baseline.png\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "dashboard_file = results_dir / \"dashboard_summary.json\"\n",
    "with open(dashboard_file, \"w\") as f:\n",
    "    json.dump(dashboard_data, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Dashboard summary saved to: {dashboard_file}\")\n",
    "display(Markdown(f\"## Experiment Complete! ‚úÖ\\n\\nResults: `{results_dir}`\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
