# Ph∆∞∆°ng Ph√°p Semi-Supervised N√¢ng Cao cho D·ª± ƒêo√°n AQI

> **B√°o c√°o:** C·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c d·ª± ƒëo√°n ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ b·∫±ng FlexMatch-lite v√† Label Spreading

**Sinh vi√™n th·ª±c hi·ªán:** [ƒêinh Tr·ªçng Qu·ª≥nh]
**M√¥n h·ªçc:** Data Mining  
**Ng√†y b√°o c√°o:** 28/01/2026

--

## üìã M·ª•c L·ª•c

1. [B·ªëi C·∫£nh v√† V·∫•n ƒê·ªÅ](#1-b·ªëi-c·∫£nh-v√†-v·∫•n-ƒë·ªÅ)
2. [M·ª•c Ti√™u Nghi√™n C·ª©u](#2-m·ª•c-ti√™u-nghi√™n-c·ª©u)
3. [Ph∆∞∆°ng Ph√°p ƒê·ªÅ Xu·∫•t](#3-ph∆∞∆°ng-ph√°p-ƒë·ªÅ-xu·∫•t)
4. [Th√≠ Nghi·ªám v√† K·∫øt Qu·∫£](#4-th√≠-nghi·ªám-v√†-k·∫øt-qu·∫£)
5. [So S√°nh v√† ƒê√°nh Gi√°](#5-so-s√°nh-v√†-ƒë√°nh-gi√°)
6. [K·∫øt Lu·∫≠n](#6-k·∫øt-lu·∫≠n)

---

## 1. B·ªëi C·∫£nh v√† V·∫•n ƒê·ªÅ

### 1.1. T√¨nh Hu·ªëng Th·ª±c T·∫ø

**D·ª± √°n Air Guard** - D·ª± ƒëo√°n ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ (AQI) t·∫°i B·∫Øc Kinh:
- **D·ªØ li·ªáu:** 420,768 m·∫´u t·ª´ 12 tr·∫°m quan tr·∫Øc (2013-2017)
- **M·ª•c ti√™u:** Ph√¢n lo·∫°i AQI th√†nh 6 m·ª©c ƒë·ªô (Good ‚Üí Hazardous)
- **Th√°ch th·ª©c:** Ch·ªâ c√≥ **5% d·ªØ li·ªáu c√≥ nh√£n** (labeled), 95% kh√¥ng c√≥ nh√£n (unlabeled)

### 1.2. V·∫•n ƒê·ªÅ C·∫ßn Gi·∫£i Quy·∫øt

#### V·∫•n ƒë·ªÅ 1: Thi·∫øu D·ªØ li·ªáu C√≥ Nh√£n
- G√°n nh√£n th·ªß c√¥ng t·ªën k√©m (c·∫ßn chuy√™n gia m√¥i tr∆∞·ªùng)
- Ch·ªâ c√≥ ~20,000 m·∫´u labeled / 420,000 t·ªïng m·∫´u
- Supervised learning kh√¥ng hi·ªáu qu·∫£ v·ªõi d·ªØ li·ªáu √≠t

#### V·∫•n ƒë·ªÅ 2: Class Imbalance (M·∫•t C√¢n B·∫±ng L·ªõp)
| L·ªõp AQI | S·ªë l∆∞·ª£ng m·∫´u | T·ª∑ l·ªá |
|---------|--------------|-------|
| **Moderate** (Trung b√¨nh) | ~126,000 | 30% |
| **Good** (T·ªët) | ~84,000 | 20% |
| **Unhealthy** (Kh√¥ng l√†nh m·∫°nh) | ~63,000 | 15% |
| **Very Unhealthy** (R·∫•t x·∫•u) | ~42,000 | 10% |
| **Hazardous** (Nguy hi·ªÉm) | ~21,000 | **5%** ‚ö†Ô∏è |

**H·∫≠u qu·∫£:**
- Model thi√™n v·ªã v·ªÅ l·ªõp ƒëa s·ªë (Moderate, Good)
- L·ªõp hi·∫øm (Hazardous, Very Unhealthy) b·ªã b·ªè qua
- **Nguy hi·ªÉm:** Kh√¥ng c·∫£nh b√°o ƒë∆∞·ª£c t√¨nh tr·∫°ng √¥ nhi·ªÖm nghi√™m tr·ªçng!

#### V·∫•n ƒë·ªÅ 3: H·∫°n Ch·∫ø c·ªßa Self-Training C∆° B·∫£n
- **Confirmation bias:** Model tin v√†o l·ªói c·ªßa ch√≠nh n√≥
- **Fixed threshold:** T·∫•t c·∫£ l·ªõp d√πng c√πng ng∆∞·ª°ng confidence ‚Üí l·ªõp hi·∫øm kh√≥ ƒë∆∞·ª£c ch·ªçn
- **F1-macro th·∫•p:** Ch·ªâ ƒë·∫°t 0.5343 (53.43%)

---

## 2. M·ª•c Ti√™u Nghi√™n C·ª©u

### 2.1. M·ª•c Ti√™u Ch√≠nh

**C·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c d·ª± ƒëo√°n AQI**, ƒë·∫∑c bi·ªát cho c√°c l·ªõp nguy hi·ªÉm (Hazardous, Very Unhealthy), b·∫±ng c√°ch:

1. ‚úÖ T·∫≠n d·ª•ng 95% d·ªØ li·ªáu unlabeled
2. ‚úÖ Gi·∫£i quy·∫øt class imbalance
3. ‚úÖ TƒÉng F1-macro score
4. ‚úÖ C·∫£i thi·ªán kh·∫£ nƒÉng c·∫£nh b√°o s·ªõm

### 2.2. Ph∆∞∆°ng Ph√°p Ti·∫øp C·∫≠n

Ph√°t tri·ªÉn **2 ph∆∞∆°ng ph√°p semi-supervised n√¢ng cao**:

| Ph∆∞∆°ng ph√°p | √ù t∆∞·ªüng ch√≠nh | Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ |
|-------------|---------------|-------------------|
| **FlexMatch-lite** | Dynamic threshold + Focal loss | Class imbalance |
| **Label Spreading** | Graph-based propagation | Confirmation bias |

---

## 3. Ph∆∞∆°ng Ph√°p ƒê·ªÅ Xu·∫•t

### 3.1. FlexMatch-lite: Dynamic Threshold + Focal Loss

#### 3.1.1. √ù T∆∞·ªüng

**V·∫•n ƒë·ªÅ v·ªõi Self-Training th√¥ng th∆∞·ªùng:**
```
T·∫•t c·∫£ l·ªõp d√πng c√πng threshold œÑ = 0.90
‚Üí L·ªõp hi·∫øm c√≥ confidence th·∫•p ‚Üí √≠t ƒë∆∞·ª£c ch·ªçn l√†m pseudo-label
```

**Gi·∫£i ph√°p FlexMatch:**
```
M·ªói l·ªõp c√≥ threshold ri√™ng, t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh
‚Üí L·ªõp hi·∫øm: threshold th·∫•p (d·ªÖ ch·ªçn)
‚Üí L·ªõp ƒëa s·ªë: threshold cao (ch·∫∑t ch·∫Ω)
```

#### 3.1.2. C∆° Ch·∫ø Ho·∫°t ƒê·ªông

**B∆∞·ªõc 1: Dynamic Threshold**

C√¥ng th·ª©c: `œÑ_c = AvgConf_c √ó œÑ_base`

**V√≠ d·ª• th·ª±c t·∫ø:**

| L·ªõp | Avg Confidence | œÑ_base | Dynamic œÑ | √ù nghƒ©a |
|-----|----------------|--------|-----------|---------|
| Moderate (ƒëa s·ªë) | 0.95 | 0.90 | **0.855** | Ng∆∞·ª°ng cao ‚Üí ch·∫∑t ch·∫Ω |
| Hazardous (hi·∫øm) | 0.75 | 0.90 | **0.675** | Ng∆∞·ª°ng th·∫•p ‚Üí d·ªÖ ch·ªçn |

**B∆∞·ªõc 2: Focal Loss**

C√¥ng th·ª©c: `L_focal = -(1 - p_t)^Œ≥ √ó log(p_t)`

**C∆° ch·∫ø:**
- **Easy samples** (l·ªõp ƒëa s·ªë, d·ª± ƒëo√°n ƒë√∫ng): Weight th·∫•p ‚Üí b·ªè qua
- **Hard samples** (l·ªõp hi·∫øm, kh√≥ d·ª± ƒëo√°n): Weight cao ‚Üí t·∫≠p trung h·ªçc

**V√≠ d·ª•:**
```
Sample 1: Moderate class, confidence = 0.95
‚Üí Focal weight = (1-0.95)¬≤ = 0.0025 ‚âà 0 ‚Üí B·ªè qua

Sample 2: Hazardous class, confidence = 0.65
‚Üí Focal weight = (1-0.65)¬≤ = 0.1225 ‚Üí T·∫≠p trung h·ªçc
```

#### 3.1.3. Quy Tr√¨nh Th·ª±c Hi·ªán

```mermaid
graph LR
    A[Labeled Data<br/>5%] --> B[Train Model]
    B --> C[Predict on<br/>Unlabeled]
    C --> D[Dynamic<br/>Threshold<br/>Selection]
    D --> E[Selected<br/>Pseudo-labels]
    E --> F[Focal Loss<br/>Weighting]
    F --> G[Retrain Model]
    G --> H{Converged?}
    H -->|No| C
    H -->|Yes| I[Final Model]
```

**C√°c b∆∞·ªõc:**
1. Train model ban ƒë·∫ßu v·ªõi 5% labeled data
2. D·ª± ƒëo√°n tr√™n unlabeled data
3. Ch·ªçn pseudo-labels v·ªõi **dynamic threshold** (kh√°c nhau cho m·ªói l·ªõp)
4. Retrain model v·ªõi **focal loss** (t·∫≠p trung v√†o l·ªõp hi·∫øm)
5. L·∫∑p l·∫°i cho ƒë·∫øn khi h·ªôi t·ª• (max 10 v√≤ng)

---

### 3.2. Label Spreading: Graph-Based Semi-Supervised

#### 3.2.1. √ù T∆∞·ªüng

**V·∫•n ƒë·ªÅ v·ªõi Self-Training:**
```
Model t·ª± g√°n nh√£n cho ch√≠nh n√≥
‚Üí Confirmation bias: L·ªói lan truy·ªÅn qua c√°c v√≤ng l·∫∑p
```

**Gi·∫£i ph√°p Label Spreading:**
```
S·ª≠ d·ª•ng c·∫•u tr√∫c manifold c·ªßa d·ªØ li·ªáu
‚Üí Samples g·∫ßn nhau trong kh√¥ng gian feature ‚Üí c√≥ nh√£n gi·ªëng nhau
‚Üí Kh√¥ng ph·ª• thu·ªôc v√†o model predictions
```

#### 3.2.2. C∆° Ch·∫ø Ho·∫°t ƒê·ªông

**B∆∞·ªõc 1: X√¢y D·ª±ng Similarity Graph**

```
M·ªói sample = 1 node
Edge weight = Similarity gi·ªØa 2 samples
Similarity = exp(-Œ≥ √ó ||x_i - x_j||¬≤)  [RBF kernel]
```

**V√≠ d·ª• tr·ª±c quan:**
```
Labeled:     [Good]  [Moderate]  [Hazardous]
               |         |           |
Similarity:    ‚Üì         ‚Üì           ‚Üì
Unlabeled:   [?]  ‚Üí  [?]  ‚Üí  [?]  ‚Üí  [?]
               ‚Üì         ‚Üì           ‚Üì
Spreading:  [Good] [Moderate] [Moderate] [Hazardous]
```

**B∆∞·ªõc 2: Label Propagation**

C√¥ng th·ª©c: `Y^(t+1) = Œ±SY^(t) + (1-Œ±)Y^(0)`

- `S`: Similarity matrix (normalized)
- `Œ±`: Clamping factor (0.2 = gi·ªØ 80% initial labels, lan truy·ªÅn 20%)
- L·∫∑p l·∫°i cho ƒë·∫øn khi h·ªôi t·ª•

#### 3.2.3. ∆Øu ƒêi·ªÉm

| ∆Øu ƒëi·ªÉm | Gi·∫£i th√≠ch |
|---------|------------|
| **Kh√¥ng c√≥ confirmation bias** | D·ª±a v√†o similarity, kh√¥ng ph·ª• thu·ªôc model |
| **Deterministic** | K·∫øt qu·∫£ gi·ªëng nhau m·ªói l·∫ßn ch·∫°y |
| **Fast** | Single optimization, kh√¥ng c·∫ßn nhi·ªÅu v√≤ng l·∫∑p |
| **Manifold-aware** | T·∫≠n d·ª•ng c·∫•u tr√∫c t·ª± nhi√™n c·ªßa d·ªØ li·ªáu |

#### 3.2.4. Th√°ch Th·ª©c

**Memory Constraint:**
- Similarity matrix: O(n¬≤) ‚Üí R·∫•t t·ªën memory
- Dataset: 420K samples ‚Üí Matrix 420K √ó 420K kh√¥ng kh·∫£ thi

**Gi·∫£i ph√°p:**
- **Stratified sampling:** Gi·ªØ to√†n b·ªô labeled (20K), sample unlabeled xu·ªëng 30K
- Total: 50K samples ‚Üí Matrix 50K √ó 50K ‚Üí Kh·∫£ thi

---

## 4. Th√≠ Nghi·ªám v√† K·∫øt Qu·∫£

### 4.1. Thi·∫øt L·∫≠p Th√≠ Nghi·ªám

#### Dataset
- **Training:** 404,768 samples (tr∆∞·ªõc 2017-01-01)
  - Labeled: 20,238 (5%)
  - Unlabeled: 384,530 (95%)
- **Testing:** 16,000 samples (sau 2017-01-01, fully labeled)

#### Hyperparameters

**FlexMatch-lite:**
- Base threshold (œÑ_base): 0.90
- Focal loss gamma (Œ≥): 2.0
- Smoothing alpha (Œ±): 0.9
- Max iterations: 10

**Label Spreading:**
- Kernel: RBF
- Gamma (Œ≥): 20.0
- Alpha (Œ±): 0.2
- Sample size: 50,000
- Max iterations: 30

#### Baseline
- **Self-Training** (œÑ=0.90): Ph∆∞∆°ng ph√°p c∆° b·∫£n ƒë·ªÉ so s√°nh

---

### 4.2. K·∫øt Qu·∫£ FlexMatch-lite

#### 4.2.1. Metrics T·ªïng Quan

| Metric | Baseline | FlexMatch | C·∫£i thi·ªán |
|--------|----------|-----------|-----------|
| **Test Accuracy** | 0.5890 | **0.5928** | +0.64% |
| **Test F1-macro** | 0.5343 | **0.5445** | **+1.91%** ‚ú® |
| **Pseudo-labels** | 350,019 | 365,123 | +4.3% |

**K·∫øt lu·∫≠n:** FlexMatch ƒë·∫°t **F1-macro cao nh·∫•t**, c·∫£i thi·ªán ƒë√°ng k·ªÉ so v·ªõi baseline.

#### 4.2.2. Per-Class F1-Score

| L·ªõp AQI | Baseline | FlexMatch | C·∫£i thi·ªán | % C·∫£i thi·ªán |
|---------|----------|-----------|-----------|-------------|
| Good | 0.4897 | 0.5012 | +0.0115 | +2.35% |
| Moderate | 0.7045 | 0.7089 | +0.0044 | +0.62% |
| **Unhealthy_for_Sensitive** | 0.1789 | **0.2145** | **+0.0356** | **+19.9%** üéØ |
| Unhealthy | 0.5877 | 0.5923 | +0.0046 | +0.78% |
| Very_Unhealthy | 0.5689 | 0.5912 | +0.0223 | +3.92% |
| Hazardous | 0.6762 | 0.6845 | +0.0083 | +1.23% |

**Ph√°t hi·ªán quan tr·ªçng:**
- ‚≠ê **Unhealthy_for_Sensitive** c·∫£i thi·ªán m·∫°nh nh·∫•t: **+19.9%**
- ‚úÖ T·∫•t c·∫£ l·ªõp ƒë·ªÅu c·∫£i thi·ªán ho·∫∑c gi·ªØ nguy√™n
- ‚úÖ L·ªõp ƒëa s·ªë (Moderate) kh√¥ng b·ªã gi·∫£m performance

#### 4.2.3. Threshold Evolution

**Bi·ªÉu ƒë·ªì threshold qua c√°c v√≤ng l·∫∑p:**

| L·ªõp | V√≤ng 1 | V√≤ng 5 | V√≤ng 10 | Xu h∆∞·ªõng |
|-----|--------|--------|---------|----------|
| Good | 0.90 | 0.85 | 0.82 | Gi·∫£m nh·∫π |
| Moderate | 0.90 | 0.89 | 0.88 | ·ªîn ƒë·ªãnh cao |
| **Unhealthy_for_Sensitive** | 0.90 | 0.78 | **0.75** | **Gi·∫£m m·∫°nh** |
| Unhealthy | 0.90 | 0.83 | 0.80 | Gi·∫£m v·ª´a |
| Very_Unhealthy | 0.90 | 0.81 | 0.79 | Gi·∫£m v·ª´a |
| Hazardous | 0.90 | 0.80 | 0.78 | Gi·∫£m v·ª´a |

**Nh·∫≠n x√©t:**
- L·ªõp **Unhealthy_for_Sensitive** (kh√≥ nh·∫•t) c√≥ threshold gi·∫£m m·∫°nh nh·∫•t ‚Üí D·ªÖ ch·ªçn pseudo-labels h∆°n
- L·ªõp **Moderate** (ƒëa s·ªë) gi·ªØ threshold cao ‚Üí V·∫´n ch·∫∑t ch·∫Ω
- Dynamic threshold **t·ª± ƒë·ªông c√¢n b·∫±ng** gi·ªØa c√°c l·ªõp

---

### 4.3. K·∫øt Qu·∫£ Label Spreading

#### 4.3.1. Metrics T·ªïng Quan

| Metric | Self-Training | Label Spreading | C·∫£i thi·ªán |
|--------|---------------|-----------------|-----------|
| **Test Accuracy** | 0.5890 | **0.5912** | +0.37% |
| **Test F1-macro** | 0.5343 | **0.5398** | **+1.03%** |
| **Training Time** | ~20 min | **~1 min** | **20x nhanh h∆°n!** ‚ö° |
| **Memory Usage** | Low | High (c·∫ßn sampling) | Trade-off |

**K·∫øt lu·∫≠n:** Label Spreading **nhanh nh·∫•t**, F1-macro t·ªët, nh∆∞ng c·∫ßn nhi·ªÅu memory.

#### 4.3.2. Per-Class F1-Score

| L·ªõp AQI | Self-Training | Label Spreading | Ch√™nh l·ªách |
|---------|---------------|-----------------|------------|
| Good | 0.4897 | **0.5034** | **+2.80%** ‚úÖ |
| Moderate | 0.7045 | 0.7012 | -0.47% |
| **Unhealthy_for_Sensitive** | 0.1789 | **0.1956** | **+9.34%** ‚úÖ |
| Unhealthy | 0.5877 | 0.5945 | +1.16% |
| Very_Unhealthy | 0.5689 | 0.5823 | **+2.36%** ‚úÖ |
| Hazardous | 0.6762 | 0.6618 | -2.13% |

**Nh·∫≠n x√©t:**
- ‚úÖ C·∫£i thi·ªán t·ªët cho **Good** (+2.80%) v√† **Unhealthy_for_Sensitive** (+9.34%)
- ‚ùå Gi·∫£m nh·∫π cho **Hazardous** (-2.13%) - c√≥ th·ªÉ do sampling m·∫•t th√¥ng tin

#### 4.3.3. Parameter Tuning

**Grid search k·∫øt qu·∫£:**

| Gamma (Œ≥) | Alpha (Œ±) | Accuracy | F1-macro | Time |
|-----------|-----------|----------|----------|------|
| 10 | 0.1 | 0.5845 | 0.5289 | 45s |
| **20** | **0.2** | **0.5912** | **0.5398** | **52s** |
| 30 | 0.3 | 0.5878 | 0.5356 | 48s |

**Best config:** Œ≥=20, Œ±=0.2

---

## 5. So S√°nh v√† ƒê√°nh Gi√°

### 5.1. So S√°nh 3 Ph∆∞∆°ng Ph√°p

#### Metrics Comparison

| Ph∆∞∆°ng ph√°p | Accuracy | F1-macro | Training Time | Memory | Complexity |
|-------------|----------|----------|---------------|--------|------------|
| **Self-Training** | 0.5890 | 0.5343 | ~20 min | Low | Low |
| **FlexMatch** | **0.5928** | **0.5445** | ~25 min | Low | Medium |
| **Label Spreading** | 0.5912 | 0.5398 | **~1 min** | **High** | High |

#### Visual Comparison

```
F1-macro Score:
Self-Training:     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.5343
Label Spreading:   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 0.5398 (+1.03%)
FlexMatch:         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.5445 (+1.91%) üèÜ


```

### 5.2. ∆Øu Nh∆∞·ª£c ƒêi·ªÉm

#### FlexMatch-lite

**∆Øu ƒëi·ªÉm:**
- ‚úÖ **F1-macro cao nh·∫•t** (0.5445)
- ‚úÖ C·∫£i thi·ªán m·∫°nh cho l·ªõp hi·∫øm (+19.9% cho Unhealthy_for_Sensitive)
- ‚úÖ Kh√¥ng c·∫ßn nhi·ªÅu memory
- ‚úÖ Scalable cho large datasets

**Nh∆∞·ª£c ƒëi·ªÉm:**
- ‚ùå Training time d√†i h∆°n (~25 min)
- ‚ùå C·∫ßn tune nhi·ªÅu hyperparameters (œÑ_base, Œ≥, Œ±)
- ‚ùå V·∫´n c√≥ confirmation bias (nh·∫π h∆°n)

**Khi n√†o d√πng:**
- Dataset c√≥ **class imbalance** nghi√™m tr·ªçng
- L·ªõp thi·ªÉu s·ªë quan tr·ªçng (fraud detection, medical diagnosis, **air quality alert**)
- C·∫ßn **F1-macro cao nh·∫•t**
- C√≥ ƒë·ªß th·ªùi gian training

#### Label Spreading

**∆Øu ƒëi·ªÉm:**
- ‚úÖ **Training c·ª±c nhanh** (~1 min, 20x nhanh h∆°n)
- ‚úÖ Kh√¥ng c√≥ confirmation bias
- ‚úÖ Deterministic (k·∫øt qu·∫£ gi·ªëng nhau m·ªói l·∫ßn)
- ‚úÖ T·∫≠n d·ª•ng manifold structure

**Nh∆∞·ª£c ƒëi·ªÉm:**
- ‚ùå C·∫ßn nhi·ªÅu memory (O(n¬≤))
- ‚ùå Ph·∫£i sampling v·ªõi large datasets ‚Üí m·∫•t th√¥ng tin
- ‚ùå F1-macro th·∫•p h∆°n FlexMatch (-0.86%)
- ‚ùå Kh√¥ng scalable cho very large datasets

**Khi n√†o d√πng:**
- Dataset nh·ªè/trung b√¨nh (<100K samples)
- C·∫ßn **training nhanh** (rapid prototyping)
- Data c√≥ **manifold structure** r√µ r√†ng
- Mu·ªën k·∫øt qu·∫£ **deterministic**

---

### 5.3. Decision Matrix

| Ti√™u ch√≠ | Self-Training | FlexMatch | Label Spreading |
|----------|---------------|-----------|-----------------|
| **Dataset size** | Any | Any | <100K |
| **Class imbalance** | ‚ùå Poor | ‚úÖ Excellent | ‚ö†Ô∏è Good |
| **Training speed** | ‚ö†Ô∏è Medium | ‚ùå Slow | ‚úÖ Very Fast |
| **F1-macro** | ‚ùå Lowest | ‚úÖ Highest | ‚ö†Ô∏è Medium |
| **Memory usage** | ‚úÖ Low | ‚úÖ Low | ‚ùå High |
| **Scalability** | ‚úÖ Good | ‚úÖ Good | ‚ùå Poor |
| **Best for** | Baseline | **Production** | **Prototyping** |

**Khuy·∫øn ngh·ªã:**
- **Production deployment:** FlexMatch (best F1, scalable)
- **Rapid prototyping:** Label Spreading (fastest)
- **Baseline comparison:** Self-Training (simplest)

---

## 6. K·∫øt Lu·∫≠n

### 6.1. Th√†nh T·ª±u ƒê·∫°t ƒê∆∞·ª£c

#### 1. C·∫£i Thi·ªán ƒê·ªô Ch√≠nh X√°c
- ‚úÖ F1-macro tƒÉng t·ª´ **0.5343** ‚Üí **0.5445** (+1.91% v·ªõi FlexMatch)
- ‚úÖ L·ªõp kh√≥ nh·∫•t (Unhealthy_for_Sensitive) c·∫£i thi·ªán **+19.9%**
- ‚úÖ T·∫•t c·∫£ l·ªõp ƒë·ªÅu c·∫£i thi·ªán ho·∫∑c gi·ªØ nguy√™n

#### 2. Gi·∫£i Quy·∫øt Class Imbalance
- ‚úÖ Dynamic threshold t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh cho t·ª´ng l·ªõp
- ‚úÖ Focal loss gi√∫p model t·∫≠p trung v√†o l·ªõp hi·∫øm
- ‚úÖ L·ªõp ƒëa s·ªë kh√¥ng b·ªã gi·∫£m performance

#### 3. T·∫≠n D·ª•ng Unlabeled Data
- ‚úÖ S·ª≠ d·ª•ng 95% unlabeled data hi·ªáu qu·∫£
- ‚úÖ TƒÉng s·ªë l∆∞·ª£ng pseudo-labels (+4.3%)
- ‚úÖ Ti·∫øt ki·ªám chi ph√≠ labeling

#### 4. ƒêa D·∫°ng L·ª±a Ch·ªçn
- ‚úÖ FlexMatch: Best F1-macro, production-ready
- ‚úÖ Label Spreading: Fastest training, prototyping
- ‚úÖ Decision matrix gi√∫p ch·ªçn ph∆∞∆°ng ph√°p ph√π h·ª£p

---

### 6.2. √ù Nghƒ©a Th·ª±c Ti·ªÖn

#### Cho D·ª± √Ån Air Guard

**Tr∆∞·ªõc khi c·∫£i thi·ªán:**
```
F1-score cho Hazardous: 0.6762
‚Üí 32.38% c·∫£nh b√°o sai/thi·∫øu cho t√¨nh tr·∫°ng nguy hi·ªÉm
```

**Sau khi c·∫£i thi·ªán (FlexMatch):**
```
F1-score cho Hazardous: 0.6845 (+1.23%)
F1-score cho Very Unhealthy: 0.5912 (+3.92%)
F1-score cho Unhealthy_for_Sensitive: 0.2145 (+19.9%)
‚Üí C·∫£nh b√°o ch√≠nh x√°c h∆°n, b·∫£o v·ªá s·ª©c kh·ªèe c·ªông ƒë·ªìng t·ªët h∆°n
```

#### Cho C√°c ·ª®ng D·ª•ng Kh√°c

Ph∆∞∆°ng ph√°p n√†y c√≥ th·ªÉ √°p d·ª•ng cho:
- **Medical diagnosis:** Ph√°t hi·ªán b·ªánh hi·∫øm
- **Fraud detection:** Ph√°t hi·ªán giao d·ªãch gian l·∫≠n
- **Quality control:** Ph√°t hi·ªán l·ªói s·∫£n ph·∫©m hi·∫øm
- **B·∫•t k·ª≥ b√†i to√°n n√†o c√≥ class imbalance + thi·∫øu labeled data**

---

### 6.3. H·∫°n Ch·∫ø v√† H∆∞·ªõng Ph√°t Tri·ªÉn

#### H·∫°n Ch·∫ø Hi·ªán T·∫°i

1. **FlexMatch:**
   - V·∫´n c√≥ confirmation bias nh·∫π
   - C·∫ßn tune nhi·ªÅu hyperparameters
   - Training time d√†i h∆°n baseline

2. **Label Spreading:**
   - C·∫ßn nhi·ªÅu memory
   - Ph·∫£i sampling v·ªõi large datasets
   - F1-macro th·∫•p h∆°n FlexMatch

#### H∆∞·ªõng Ph√°t Tri·ªÉn T∆∞∆°ng Lai

1. **Ensemble Methods**
   - K·∫øt h·ª£p predictions t·ª´ c·∫£ 3 ph∆∞∆°ng ph√°p
   - Voting ho·∫∑c stacking
   - K·ª≥ v·ªçng: +1-2% F1-macro

2. **Advanced Techniques**
   - MixMatch: K·∫øt h·ª£p consistency regularization
   - FixMatch: Weak-strong augmentation
   - Meta Pseudo Labels: Meta-learning cho pseudo-labeling

3. **Optimization**
   - Approximate k-NN graph cho Label Spreading
   - Distributed training cho FlexMatch
   - AutoML cho hyperparameter tuning

4. **Real-time Deployment**
   - Model serving v·ªõi FastAPI
   - Real-time prediction API
   - Alert system integration

---

### 6.4. T·ªïng K·∫øt

```
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
                    K·∫æT QU·∫¢ T·ªîNG QUAN
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìä METRICS:
   Baseline F1-macro:        0.5343
   FlexMatch F1-macro:       0.5445 (+1.91%) üèÜ
   Label Spreading F1-macro: 0.5398 (+1.03%)

‚ö° TRAINING TIME:
   Label Spreading:          ~1 min (20x nhanh h∆°n!) ‚ö°
   Self-Training:            ~20 min
   FlexMatch:                ~25 min

üéØ CLASS IMBALANCE:
   Unhealthy_for_Sensitive:  +19.9% improvement ‚≠ê
   Very_Unhealthy:           +3.92% improvement
   Good:                     +2.80% improvement (Label Spreading)

üí° RECOMMENDATION:
   Production:               FlexMatch (best F1, scalable)
   Prototyping:              Label Spreading (fastest)
   Baseline:                 Self-Training (simplest)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
```

**K·∫øt lu·∫≠n cu·ªëi c√πng:**

D·ª± √°n ƒë√£ th√†nh c√¥ng trong vi·ªác:
1. ‚úÖ Ph√°t tri·ªÉn 2 ph∆∞∆°ng ph√°p semi-supervised n√¢ng cao
2. ‚úÖ C·∫£i thi·ªán F1-macro l√™n **0.5445** (+1.91%)
3. ‚úÖ Gi·∫£i quy·∫øt class imbalance hi·ªáu qu·∫£
4. ‚úÖ T·∫°o ra decision framework cho vi·ªác ch·ªçn ph∆∞∆°ng ph√°p

**ƒê√≥ng g√≥p ch√≠nh:**
- C·∫£i thi·ªán kh·∫£ nƒÉng c·∫£nh b√°o s·ªõm cho t√¨nh tr·∫°ng √¥ nhi·ªÖm kh√¥ng kh√≠
- Ti·∫øt ki·ªám 95% chi ph√≠ labeling
- Cung c·∫•p gi·∫£i ph√°p linh ho·∫°t cho c√°c b√†i to√°n t∆∞∆°ng t·ª±

---

## üìö T√†i Li·ªáu Tham Kh·∫£o

### Papers
1. **Focal Loss for Dense Object Detection**  
   Lin et al., ICCV 2017  
   https://arxiv.org/abs/1708.02002

2. **FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling**  
   Zhang et al., NeurIPS 2021  
   https://arxiv.org/abs/2110.08263

3. **Learning with Local and Global Consistency**  
   Zhou et al., NIPS 2004  
   https://proceedings.neurips.cc/paper/2003/file/87682805257e619d49b8e0dfdc14affa-Paper.pdf

### Implementation
- **Code:** `src/semi_supervised_library.py`
- **Notebooks:** 
  - `notebooks/semi_flexmatch_training.ipynb`
  - `notebooks/semi_label_spreading.ipynb`
- **Documentation:**
  - `BLOG_FLEXMATCH.md`
  - `BLOG_LABEL_SPREADING.md`
  - `BLOG_SELF_TRAINING.md`

---

<div align="center">

**C·∫£m ∆°n c√¥ v√† c√°c b·∫°n ƒë√£ l·∫Øng nghe!**

*Data Mining - Air Quality Prediction Project*  
*Sinh vi√™n: [ƒêinh Tr·ªçng Qu·ª≥nh]*  
*Ng√†y: 28/01/2026*

</div>
