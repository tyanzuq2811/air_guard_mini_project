"""
Y√™u C·∫ßu 3: So S√°nh C√°c C·∫•u H√¨nh/Tham S·ªë
=========================================
Th·ª±c hi·ªán experiments thay ƒë·ªïi tham s·ªë so v·ªõi thi·∫øt l·∫≠p g·ªëc
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from pathlib import Path
import json
from PIL import Image

# Page config
st.set_page_config(
    page_title="Y√™u C·∫ßu 3: Parameter Experiments",
    page_icon="üß™",
    layout="wide"
)

# Custom CSS
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    * {
        font-family: 'Inter', sans-serif;
    }
    
    .main-title {
        font-size: 2.5rem;
        background: linear-gradient(135deg, #0ea5e9 0%, #0284c7 50%, #0369a1 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: 700;
        margin-bottom: 1rem;
    }
    
    .exp-card {
        background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
        padding: 1.5rem;
        border-radius: 1rem;
        border-left: 4px solid #0ea5e9;
        margin: 1rem 0;
    }
    
    .success-card {
        background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%);
        border-left: 4px solid #22c55e;
    }
    </style>
""", unsafe_allow_html=True)

# Header
st.markdown('<div class="main-title">Y√™u C·∫ßu 3: So S√°nh C√°c C·∫•u H√¨nh/Tham S·ªë</div>', unsafe_allow_html=True)
st.markdown("""
Th·ª±c hi·ªán **5 experiments** thay ƒë·ªïi tham s·ªë ƒë·ªÉ hi·ªÉu r√µ t√°c ƒë·ªông c·ªßa c√°c y·∫øu t·ªë trong thu·∫≠t to√°n.
**B·∫Øt bu·ªôc**: Th·ª≠ nghi·ªám œÑ kh√°c. **M·ªü r·ªông**: Labeled size, model kh√°c, view splitting kh√°c.
""")

# Paths
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_DIR = PROJECT_ROOT / "data" / "processed"

st.markdown("---")

# ============================================================================
# SECTION 1: T·ªîNG QUAN C√ÅC EXPERIMENTS
# ============================================================================
st.markdown("## üéØ T·ªïng Quan 5 Experiments")

experiments_summary = pd.DataFrame({
    'Experiment': [
        '1. Thay ƒë·ªïi œÑ (B·∫ÆT BU·ªòC) ‚≠ê',
        '2. K√≠ch th∆∞·ªõc labeled data',
        '3. Model/Thu·∫≠t to√°n kh√°c',
        '4. Adaptive œÑ schedule',
        '5. T√°ch view kh√°c ƒëi'
    ],
    'What Changed': [
        'œÑ = 0.80 vs 0.90 vs 0.95',
        'Labeled: 5% vs 10% vs 20%',
        'HGBC vs RandomForest',
        'Fixed œÑ=0.90 vs Aggressive schedule',
        'Current views vs Pollutant-based views'
    ],
    'Best Config': [
        'œÑ = 0.90',
        '10% labeled',
        'HistGradientBoosting',
        'Aggressive schedule',
        'Pollutant-based (but still worse)'
    ],
    'F1-Macro': [
        '0.5343',
        '0.5050',
        '0.4919',
        '0.5088',
        '0.4507'
    ],
    'Impact': [
        'High (+13.3%)',
        'Medium (+8.1%)',
        'Very High (+19.1%)',
        'Low (+3.4%)',
        'Negative (-15.6%)'
    ]
})

st.dataframe(
    experiments_summary.style.apply(
        lambda x: ['background-color: #fef3c7' if '‚≠ê' in str(x['Experiment']) else '' for _ in x],
        axis=1
    ),
    use_container_width=True,
    hide_index=True
)

st.info("""
üìä **Key Insights t·ª´ t·∫•t c·∫£ experiments**:
- **Experiment 1 (œÑ)**: B·∫ÆT BU·ªòC, impact cao, œÑ=0.90 t·ªëi ∆∞u
- **Experiment 3 (Model)**: Impact L·ªöN NH·∫§T (+19.1%), model architecture critical!
- **Experiment 5 (View splitting)**: Co-Training th·∫•t b·∫°i (-15.6%), Self-Training t·ªët h∆°n
""")

st.markdown("---")

# Sub-tabs cho t·ª´ng experiment
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "Exp 1: Thay ƒê·ªïi œÑ ‚≠ê",
    "Exp 2: Labeled Size",
    "Exp 3: Model Architecture",
    "Exp 4: Adaptive œÑ",
    "Exp 5: View Splitting",
    "Summary & Recommendations"
])

# ============================================================================
# EXP 1: THAY ƒê·ªîI NG∆Ø·ª†NG œÑ (B·∫ÆT BU·ªòC)
# ============================================================================
with tab1:
    st.markdown("## Experiment 1: Thay ƒê·ªïi Ng∆∞·ª°ng Confidence œÑ")
    st.markdown("**Y√™u c·∫ßu B·∫ÆT BU·ªòC**: Th·ª≠ nghi·ªám v·ªõi gi√° tr·ªã œÑ kh√°c cho self-training v√† quan s√°t s·ª± kh√°c bi·ªát")
    
    st.markdown('<div class="exp-card">', unsafe_allow_html=True)
    st.markdown("""
    **Thi·∫øt L·∫≠p:**
    - **Baseline**: Self-Training v·ªõi œÑ = 0.90 (t·ª´ Y√™u c·∫ßu 1)
    - **Experiments**: So s√°nh 3 gi√° tr·ªã œÑ = 0.80, 0.90, 0.95
    - **Other params**: 5% labeled, HGBC, 10 iterations, Fixed schedule
    """)
    st.markdown('</div>', unsafe_allow_html=True)
    
    try:
        # Results
        tau_results = pd.DataFrame({
            'œÑ Value': ['0.80', '0.90 ‚≠ê', '0.95'],
            'Test Accuracy': [0.5941, 0.5890, 0.5931],
            'Test F1-Macro': [0.5167, 0.5343, 0.5330],
            'Pseudo-labels': [364388, 350019, 314834],
            '% Unlabeled Used': ['94.8%', '91.1%', '81.9%'],
            'Val F1 Peak': [0.7081, 0.7106, 0.6953],
            'F1 vs Baseline (0.4715)': ['+9.6%', '+13.3%', '+13.0%']
        })
        
        st.markdown("### üìä K·∫øt Qu·∫£ So S√°nh")
        
        st.dataframe(
            tau_results.style.apply(
                lambda x: ['background-color: #d1fae5; font-weight: bold' if '‚≠ê' in str(x['œÑ Value']) else '' for _ in x],
                axis=1
            ),
            use_container_width=True,
            hide_index=True
        )
        
        # Analysis
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="success-card">', unsafe_allow_html=True)
            st.markdown("""
            ### ‚úÖ S·ª± Kh√°c Bi·ªát Quan S√°t ƒê∆∞·ª£c
            
            **1. œÑ = 0.80 (Th·∫•p):**
            - **Nhi·ªÅu pseudo-labels nh·∫•t** (364K, 94.8% pool)
            - Model t·ª± tin g√°n nh√£n nhi·ªÅu
            - **NH∆ØNG F1 th·∫•p nh·∫•t** (0.5167)
            - **Nguy√™n nh√¢n**: Th√™m qu√° nhi·ªÅu labels c√≥ confidence th·∫•p ‚Üí noise tƒÉng
            
            **2. œÑ = 0.90 (Trung b√¨nh) ‚≠ê:**
            - **F1 cao nh·∫•t** (0.5343, +13.3%)
            - 350K pseudo-labels (91.1% pool)
            - **Best balance** gi·ªØa quality v√† quantity
            - Val F1 peak cao nh·∫•t (0.7106)
            
            **3. œÑ = 0.95 (Cao):**
            - **√çt pseudo-labels nh·∫•t** (314K, 81.9%)
            - Qu√° strict, b·ªè l·ª° nhi·ªÅu m·∫´u t·ªët
            - F1 = 0.5330 (ch·ªâ 0.0013 th·∫•p h∆°n œÑ=0.90)
            - Kh√¥ng c·∫£i thi·ªán ƒë√°ng k·ªÉ so v·ªõi œÑ=0.90
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="exp-card">', unsafe_allow_html=True)
            st.markdown("""
            ### üìà Trade-off: Quality vs Quantity
            
            ```
            œÑ=0.80: 364K labels ‚Üí F1=0.5167
                    ‚Üì Nhi·ªÅu nh∆∞ng ·ªìn
                    
            œÑ=0.90: 350K labels ‚Üí F1=0.5343 ‚≠ê
                    ‚Üì Sweet spot
                    
            œÑ=0.95: 315K labels ‚Üí F1=0.5330
                    ‚Üì √çt h∆°n, c·∫£i thi·ªán kh√¥ng ƒë√°ng k·ªÉ
            ```
            
            **Insights:**
            - **Quality > Quantity**: √çt labels nh∆∞ng ch·∫•t l∆∞·ª£ng cao ‚Üí F1 t·ªët h∆°n
            - **œÑ=0.90 l√† optimal**: C√¢n b·∫±ng t·ªët nh·∫•t
            - **œÑ qu√° th·∫•p**: Noise t√≠ch l≈©y ‚Üí F1 gi·∫£m
            - **œÑ qu√° cao**: B·ªè l·ª° data ‚Üí kh√¥ng c·∫£i thi·ªán th√™m
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Visualizations
        st.markdown("### üìä Bi·ªÉu ƒê·ªì So S√°nh")
        
        exp_dir = DATA_DIR / "self_training_experiments"
        
        col1, col2 = st.columns(2)
        
        with col1:
            img_path = exp_dir / "test_performance_comparison.png"
            if img_path.exists():
                st.image(str(img_path), caption="Test Performance: 3 œÑ values vs Baseline", use_container_width=True)
        
        with col2:
            img_path = exp_dir / "validation_f1_over_iterations.png"
            if img_path.exists():
                st.image(str(img_path), caption="Validation F1 Over Iterations", use_container_width=True)
        
        img_path = exp_dir / "pseudo_labels_over_iterations.png"
        if img_path.exists():
            st.image(str(img_path), caption="Pseudo-labels Per Iteration - œÑ=0.80 th√™m nhi·ªÅu nh·∫•t", use_container_width=True)
        
        st.success("""
        **‚úÖ K·∫øt Lu·∫≠n Experiment 1:**
        - **œÑ = 0.90 l√† t·ªëi ∆∞u** cho Beijing Air Quality dataset
        - C·∫£i thi·ªán **+13.3% F1** so v·ªõi baseline (0.4715 ‚Üí 0.5343)
        - S·ª± kh√°c bi·ªát r√µ r√†ng: œÑ=0.80 ·ªìn, œÑ=0.90 optimal, œÑ=0.95 kh√¥ng c·∫£i thi·ªán th√™m
        - **Quality > Quantity**: Confidence threshold quan tr·ªçng ƒë·ªÉ filter noise
        """)
    
    except Exception as e:
        st.error(f"L·ªói load Experiment 1: {str(e)}")

# ============================================================================
# EXP 2: K√çCH TH∆Ø·ªöC LABELED DATA
# ============================================================================
with tab2:
    st.markdown("## Experiment 2: Thay ƒê·ªïi K√≠ch Th∆∞·ªõc Labeled Data")
    st.markdown("**M·ª•c ti√™u**: Xem d√πng nhi·ªÅu h∆°n labeled data c√≥ c·∫£i thi·ªán ƒë√°ng k·ªÉ kh√¥ng?")
    
    st.markdown('<div class="exp-card">', unsafe_allow_html=True)
    st.markdown("""
    **Thi·∫øt L·∫≠p:**
    - **Baseline**: 5% labeled (~21K m·∫´u) t·ª´ Experiment 1
    - **Experiments**: So s√°nh 5% vs 10% vs 20% labeled data
    - **Other params**: œÑ=0.90, HGBC, 10 iterations
    """)
    st.markdown('</div>', unsafe_allow_html=True)
    
    try:
        exp_dir = DATA_DIR / "labeled_size_experiments"
        
        # Results
        labeled_results = pd.DataFrame({
            'Labeled %': ['5%', '10% ‚≠ê', '20%'],
            'Labeled Count': ['21,034', '42,068', '84,137'],
            'Test Accuracy': [0.5633, 0.5678, 0.5759],
            'Test F1-Macro': [0.4671, 0.5050, 0.4896],
            'Pseudo-labels': ['344,688', '346,372', '357,913'],
            'vs 5% F1': ['-', '+8.1%', '+4.8%']
        })
        
        st.markdown("### üìä K·∫øt Qu·∫£ So S√°nh")
        
        st.dataframe(
            labeled_results.style.apply(
                lambda x: ['background-color: #d1fae5; font-weight: bold' if '‚≠ê' in str(x['Labeled %']) else '' for _ in x],
                axis=1
            ),
            use_container_width=True,
            hide_index=True
        )
        
        # Analysis
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="success-card">', unsafe_allow_html=True)
            st.markdown("""
            ### ‚úÖ Quan S√°t Quan Tr·ªçng
            
            **1. 5% Labeled (Baseline):**
            - F1 = 0.4671
            - Model base y·∫øu nh∆∞ng self-training v·∫´n work
            - 344K pseudo-labels added
            
            **2. 10% Labeled (Sweet Spot) ‚≠ê:**
            - **F1 = 0.5050 (+8.1% vs 5%)**
            - Highest F1-Macro!
            - Model base ƒë·ªß m·∫°nh ƒë·ªÉ generate good pseudo-labels
            - **Best balance** gi·ªØa labeled v√† unlabeled
            
            **3. 20% Labeled (Diminishing Return):**
            - Accuracy cao nh·∫•t (0.5759)
            - **NH∆ØNG F1 GI·∫¢M** (0.4896, -3.1% vs 10%)
            - Model qu√° confident v·ªõi labeled ‚Üí √≠t h·ªçc t·ª´ unlabeled
            - Overfitting risk tƒÉng
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="exp-card">', unsafe_allow_html=True)
            st.markdown("""
            ### üìà Diminishing Return Pattern
            
            ```
            5% ‚Üí 10%: +8.1% F1 ‚úÖ (C·∫£i thi·ªán m·∫°nh)
            10% ‚Üí 20%: -3.1% F1 ‚ùå (Gi·∫£m!)
            ```
            
            **Gi·∫£i th√≠ch:**
            
            **5% ‚Üí 10%:**
            - Model base m·∫°nh h∆°n 2x
            - Pseudo-labels ch·∫•t l∆∞·ª£ng cao h∆°n
            - Self-training efficient h∆°n
            
            **10% ‚Üí 20%:**
            - Th√™m labeled kh√¥ng c·∫£i thi·ªán model base nhi·ªÅu
            - Model "satisfied" v·ªõi labeled data
            - √çt "hungry" cho unlabeled data
            - F1 gi·∫£m v√¨ bias v·ªÅ majority classes
            
            **‚Üí Kh√¥ng ph·∫£i c√†ng nhi·ªÅu labeled c√†ng t·ªët!**
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Visualizations
        st.markdown("### üìä Bi·ªÉu ƒê·ªì Tr·ª±c Quan")
        
        col1, col2 = st.columns(2)
        
        with col1:
            img_path = exp_dir / "test_performance_comparison.png"
            if img_path.exists():
                st.image(str(img_path), caption="Test Performance by Labeled Size", use_container_width=True)
        
        with col2:
            img_path = exp_dir / "learning_curves.png"
            if img_path.exists():
                st.image(str(img_path), caption="Learning Curves - 10% ·ªïn ƒë·ªãnh nh·∫•t", use_container_width=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            img_path = exp_dir / "pseudo_labels_comparison.png"
            if img_path.exists():
                st.image(str(img_path), caption="Pseudo-labels Activity", use_container_width=True)
        
        with col2:
            img_path = exp_dir / "training_data_composition.png"
            if img_path.exists():
                st.image(str(img_path), caption="Training Data Composition", use_container_width=True)
        
        st.success("""
        **‚úÖ K·∫øt Lu·∫≠n Experiment 2:**
        - **10% labeled l√† sweet spot** cho dataset 420K samples
        - C·∫£i thi·ªán **+8.1%** so v·ªõi 5% (0.4671 ‚Üí 0.5050)
        - **20% labeled KH√îNG t·ªët h∆°n 10%** (-3.1% F1) ‚Üí Diminishing return
        - **Data efficiency**: Ch·ªâ c·∫ßn ~42K labeled samples (10%) thay v√¨ to√†n b·ªô 420K
        - **Insight**: C√¢n b·∫±ng gi·ªØa model base strength v√† unlabeled data utilization
        """)
    
    except Exception as e:
        st.error(f"L·ªói load Experiment 2: {str(e)}")

# ============================================================================
# EXP 3: MODEL/THU·∫¨T TO√ÅN KH√ÅC
# ============================================================================
with tab3:
    st.markdown("## Experiment 3: Th·ª≠ Model/Thu·∫≠t To√°n Kh√°c")
    st.markdown("**M·ª•c ti√™u**: Th·ª≠ chuy·ªÉn sang RandomForest xem self-training c√≥ c·∫£i thi·ªán kh√°c kh√¥ng?")
    
    st.markdown('<div class="exp-card">', unsafe_allow_html=True)
    st.markdown("""
    **Thi·∫øt L·∫≠p:**
    - **Baseline**: HistGradientBoostingClassifier (HGBC) t·ª´ c√°c experiments tr∆∞·ªõc
    - **Experiment**: So s√°nh HGBC vs RandomForest (RF)
    - **Other params**: 5% labeled, œÑ=0.90, 10 iterations
    """)
    st.markdown('</div>', unsafe_allow_html=True)
    
    try:
        exp_dir = DATA_DIR / "model_comparison_experiments"
        
        # Results
        model_results = pd.DataFrame({
            'Model': ['HistGradientBoosting ‚≠ê', 'RandomForest'],
            'Test Accuracy': [0.5682, 0.5628],
            'Test F1-Macro': [0.4919, 0.4130],
            'Pseudo-labels': ['345,924', '180,363'],
            'Val F1 Peak': [0.6673, 0.5653],
            'vs RF': ['+19.1%', '-'],
            'Training Time': ['~4 min', '~12 min']
        })
        
        st.markdown("### üìä K·∫øt Qu·∫£ So S√°nh")
        
        st.dataframe(
            model_results.style.apply(
                lambda x: ['background-color: #d1fae5; font-weight: bold' if '‚≠ê' in str(x['Model']) else '' for _ in x],
                axis=1
            ),
            use_container_width=True,
            hide_index=True
        )
        
        # Analysis
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="success-card">', unsafe_allow_html=True)
            st.markdown("""
            ### üèÜ HGBC >> RandomForest (KH·ªîNG L·ªí!)
            
            **Performance Gap: +19.1% F1** (0.4919 vs 0.4130)
            
            **T·∫°i sao HGBC t·ªët h∆°n RF:**
            
            **1. Probability Calibration:**
            - HGBC: Well-calibrated probabilities
            - RF: Overconfident BUT poor calibration
            - **Impact**: HGBC pseudo-labels ch·∫•t l∆∞·ª£ng cao h∆°n
            
            **2. Pseudo-labeling Activity:**
            - HGBC: 345K labels (90% pool)
            - RF: 180K labels (47% pool, 52% √çT H∆†N!)
            - **Why**: RF probabilities kh√¥ng pass œÑ=0.90
            
            **3. Learning Trajectory:**
            - HGBC: Smooth learning, Val F1 peak 0.667
            - RF: Plateau s·ªõm, Val F1 peak ch·ªâ 0.565
            - **Impact**: HGBC t·∫≠n d·ª•ng unlabeled t·ªët h∆°n
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="exp-card">', unsafe_allow_html=True)
            st.markdown("""
            ### üîç RF Th·∫•t B·∫°i V√¨ Sao?
            
            **Problem: Too Conservative BUT Wrong Way**
            
            **1. Overconfident Predictions:**
            - RF d·ª± ƒëo√°n v·ªõi confidence cao
            - NH∆ØNG predictions sai nhi·ªÅu
            - Bagging ensemble "smooth" qu√° m·ª©c
            
            **2. Poor Probability Calibration:**
            - RF probabilities kh√¥ng reflect true uncertainty
            - Confidence 0.89 ‚Üí KH√îNG pass œÑ=0.90
            - B·ªè l·ª° nhi·ªÅu m·∫´u t·ªët
            
            **3. Kh√¥ng Selective:**
            - 180K labels c√≥ nhi·ªÅu noise
            - Quality k√©m h∆°n HGBC
            - Model h·ªçc theo wrong patterns
            
            **Insight:**
            - **Model architecture C·ª∞C K·ª≤ QUAN TR·ªåNG** cho self-training
            - C·∫ßn model v·ªõi **well-calibrated probabilities**
            - Gradient Boosting > Bagging cho semi-supervised
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Visualizations
        st.markdown("### üìä Bi·ªÉu ƒê·ªì Tr·ª±c Quan")
        
        col1, col2 = st.columns(2)
        
        with col1:
            img_path = exp_dir / "test_performance_by_model.png"
            if img_path.exists():
                st.image(str(img_path), caption="Test Performance: HGBC vs RandomForest", use_container_width=True)
        
        with col2:
            img_path = exp_dir / "learning_curves_by_model.png"
            if img_path.exists():
                st.image(str(img_path), caption="Learning Curves - HGBC ·ªïn ƒë·ªãnh, RF plateau", use_container_width=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            img_path = exp_dir / "pseudo_labeling_by_model.png"
            if img_path.exists():
                st.image(str(img_path), caption="Pseudo-labeling - HGBC th√™m 2x nhi·ªÅu h∆°n RF", use_container_width=True)
        
        with col2:
            img_path = exp_dir / "per_class_f1_heatmap.png"
            if img_path.exists():
                st.image(str(img_path), caption="Per-class F1 - HGBC ƒë·ªìng ƒë·ªÅu h∆°n", use_container_width=True)
        
        st.success("""
        **‚úÖ K·∫øt Lu·∫≠n Experiment 3:**
        - **HGBC >> RandomForest** (+19.1% F1) - **Impact L·ªöN NH·∫§T**!
        - Model architecture l√† **y·∫øu t·ªë quan tr·ªçng nh·∫•t** trong self-training
        - HGBC: Well-calibrated probabilities ‚Üí high-quality pseudo-labels
        - RF: Poor calibration ‚Üí ch·ªâ 180K labels (47% pool), quality k√©m
        - **Insight**: Gradient Boosting ph√π h·ª£p h∆°n Bagging cho semi-supervised learning
        """)
    
    except Exception as e:
        st.error(f"L·ªói load Experiment 3: {str(e)}")

# ============================================================================
# EXP 4: ADAPTIVE œÑ SCHEDULE
# ============================================================================
with tab4:
    st.markdown("## Experiment 4: Adaptive œÑ Schedule")
    st.markdown("**M·ª•c ti√™u**: Th·ª≠ œÑ adaptive (gi·∫£m d·∫ßn) thay v√¨ fixed œÑ=0.90")
    
    st.markdown('<div class="exp-card">', unsafe_allow_html=True)
    st.markdown("""
    **Thi·∫øt L·∫≠p:**
    - **Baseline**: Fixed œÑ=0.90 (constant qua 10 v√≤ng)
    - **Experiment**: Aggressive schedule (œÑ gi·∫£m t·ª´ 0.95 ‚Üí 0.80)
    - **Other params**: 10% labeled, HGBC, 10 iterations
    
    **Gi·∫£ thuy·∫øt**: Early strict (œÑ=0.95) tr√°nh bad labels, later relaxed (œÑ=0.80) maximize data usage
    """)
    st.markdown('</div>', unsafe_allow_html=True)
    
    try:
        exp_dir = DATA_DIR / "hybrid_tau_experiments"
        
        # Results
        tau_schedule_results = pd.DataFrame({
            'Schedule': ['Fixed œÑ=0.90', 'Aggressive (0.95‚Üí0.80) ‚≠ê'],
            'Test Accuracy': [0.5682, 0.5689],
            'Test F1-Macro': [0.4919, 0.5088],
            'Pseudo-labels': ['345,924', '370,727'],
            'Val F1 Peak': [0.6673, 0.6673],
            'Avg œÑ': [0.90, 0.83],
            'vs Fixed F1': ['-', '+3.4%']
        })
        
        st.markdown("### üìä K·∫øt Qu·∫£ So S√°nh")
        
        st.dataframe(
            tau_schedule_results.style.apply(
                lambda x: ['background-color: #d1fae5; font-weight: bold' if '‚≠ê' in str(x['Schedule']) else '' for _ in x],
                axis=1
            ),
            use_container_width=True,
            hide_index=True
        )
        
        # Schedule visualization
        st.markdown("### üìà L·ªãch Tr√¨nh œÑ Qua 10 V√≤ng")
        
        tau_schedule_df = pd.DataFrame({
            'Iteration': list(range(1, 11)),
            'Fixed': [0.90] * 10,
            'Aggressive': [0.95, 0.93, 0.91, 0.89, 0.87, 0.85, 0.83, 0.81, 0.80, 0.80]
        })
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=tau_schedule_df['Iteration'], y=tau_schedule_df['Fixed'], 
                                 name='Fixed', line=dict(color='#0ea5e9', dash='dash')))
        fig.add_trace(go.Scatter(x=tau_schedule_df['Iteration'], y=tau_schedule_df['Aggressive'],
                                 name='Aggressive', line=dict(color='#22c55e')))
        fig.update_layout(title='œÑ Schedule Over Iterations', xaxis_title='Iteration', yaxis_title='œÑ Value')
        st.plotly_chart(fig, use_container_width=True)
        
        # Analysis
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="success-card">', unsafe_allow_html=True)
            st.markdown("""
            ### ‚úÖ Aggressive Schedule Wins (Nh·∫π)
            
            **Performance Gain: +3.4% F1** (0.4919 ‚Üí 0.5088)
            
            **T·∫°i sao t·ªët h∆°n:**
            
            **1. Early Strict (œÑ=0.95, V√≤ng 1-3):**
            - √çt pseudo-labels (~20-30K/iter)
            - **High quality**, tr√°nh confirmation bias s·ªõm
            - Model h·ªçc foundation t·ªët
            
            **2. Later Relaxed (œÑ=0.80, V√≤ng 6-10):**
            - Nhi·ªÅu pseudo-labels (~40-50K/iter)
            - Maximize unlabeled data usage
            - Total: 370K labels (96% pool)
            
            **3. Benefit:**
            - Best of both worlds
            - Quality early + Quantity later
            - +24K pseudo-labels vs Fixed
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="exp-card">', unsafe_allow_html=True)
            st.markdown("""
            ### üìä Trade-off Analysis
            
            **Val F1 Peak: Gi·ªëng nhau (0.6673)**
            - C·∫£ 2 schedules ƒë·∫°t c√πng upper bound
            - Aggressive ƒë·∫°t peak s·ªõm h∆°n 1-2 v√≤ng
            
            **Pseudo-labeling Pattern:**
            - Fixed: Uniform ~34-35K/iteration
            - Aggressive: Ramp up t·ª´ 20K ‚Üí 50K
            - Total gap: +7% more labels
            
            **Diminishing Return of Low œÑ:**
            - œÑ=0.80 (v√≤ng 6-10) th√™m nhi·ªÅu labels
            - NH∆ØNG Test F1 ch·ªâ tƒÉng nh·∫π (+3.4%)
            - Risk: œÑ qu√° th·∫•p ‚Üí noise tƒÉng
            
            **ROI Analysis:**
            - Complexity: Cao h∆°n (c·∫ßn tune schedule)
            - Benefit: Nh·ªè (+3.4%)
            - **Recommendation**: Fixed œÑ=0.90 ƒë·ªß t·ªët v√† ƒë∆°n gi·∫£n
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Visualizations
        st.markdown("### üìä Bi·ªÉu ƒê·ªì Tr·ª±c Quan")
        
        col1, col2 = st.columns(2)
        
        with col1:
            img_path = exp_dir / "test_performance_by_schedule.png"
            if img_path.exists():
                st.image(str(img_path), caption="Test Performance: Fixed vs Aggressive", use_container_width=True)
        
        with col2:
            img_path = exp_dir / "validation_curves_by_schedule.png"
            if img_path.exists():
                st.image(str(img_path), caption="Validation Curves", use_container_width=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            img_path = exp_dir / "pseudo_labeling_activity.png"
            if img_path.exists():
                st.image(str(img_path), caption="Pseudo-labeling Activity - Aggressive ramp up", use_container_width=True)
        
        with col2:
            img_path = exp_dir / "tau_performance_correlation.png"
            if img_path.exists():
                st.image(str(img_path), caption="œÑ-Performance Correlation", use_container_width=True)
        
        st.success("""
        **‚úÖ K·∫øt Lu·∫≠n Experiment 4:**
        - **Aggressive schedule t·ªët h∆°n Fixed** (+3.4% F1) nh∆∞ng improvement nh·ªè
        - Early strict (0.95) ‚Üí Later relaxed (0.80) strategy works
        - +24K pseudo-labels (7% more) nh∆∞ng ch·ªâ +3.4% F1 ‚Üí Diminishing return
        - **Recommendation**: Fixed œÑ=0.90 ƒë·ªß t·ªët v√† ƒë∆°n gi·∫£n h∆°n
        - **ROI th·∫•p**: Complexity tƒÉng nh∆∞ng benefit nh·ªè
        """)
    
    except Exception as e:
        st.error(f"L·ªói load Experiment 4: {str(e)}")

# ============================================================================
# EXP 5: VIEW SPLITTING KH√ÅC
# ============================================================================
with tab5:
    st.markdown("## Experiment 5: T√°ch View Kh√°c ƒêi")
    st.markdown("**M·ª•c ti√™u**: Th·ª≠ t√°ch view theo pollutant types (domain knowledge) thay v√¨ random")
    
    st.markdown('<div class="exp-card">', unsafe_allow_html=True)
    st.markdown("""
    **Thi·∫øt L·∫≠p:**
    - **Baseline**: Current view splitting (random, 41-10 features, 100% independence)
    - **Experiment**: Pollutant-based views (Primary vs Secondary, 36-30 features, 33.3% independence)
    - **Other params**: 10% labeled, HGBC, œÑ=0.90, max 500/iter, 10 iterations
    
    **Gi·∫£ thuy·∫øt**: Domain knowledge ‚Üí better views ‚Üí Co-Training improves
    """)
    st.markdown('</div>', unsafe_allow_html=True)
    
    try:
        exp_dir = DATA_DIR / "view_splitting_experiments"
        summary_file = exp_dir / "dashboard_summary.json"
        
        if summary_file.exists():
            with open(summary_file, 'r') as f:
                view_data = json.load(f)
            
            # Results
            view_results = pd.DataFrame({
                'Strategy': ['Current (Random)', 'Pollutant-based ‚≠ê', 'Self-Training (Reference)'],
                'View 1 Size': ['41', '36', '51'],
                'View 2 Size': ['10', '30', 'N/A'],
                'Independence': ['100%', '33.3%', 'N/A'],
                'Test Accuracy': [0.5401, 0.5718, 0.5890],
                'Test F1-Macro': [0.4176, 0.4507, 0.5343],
                'vs Self-Training': ['-21.8%', '-15.6%', 'Baseline']
            })
            
            st.markdown("### üìä K·∫øt Qu·∫£ So S√°nh")
            
            st.dataframe(
                view_results.style.apply(
                    lambda x: [
                        'background-color: #d1fae5; font-weight: bold' if '‚≠ê' in str(x['Strategy'])
                        else 'background-color: #fee2e2' if 'Current' in str(x['Strategy'])
                        else ''
                        for _ in x
                    ],
                    axis=1
                ),
                use_container_width=True,
                hide_index=True
            )
            
            # Critical finding
            st.error("""
            **‚ùå CRITICAL FINDING: C·∫£ 2 View Splitting Strategies ƒê·ªÄU TH·∫§T B·∫†I!**
            
            - Pollutant-based (best): F1 = 0.4507 (**-15.6% vs Self-Training**)
            - Current (random): F1 = 0.4176 (**-21.8% vs Self-Training**)
            - Self-Training: F1 = 0.5343 (reference)
            
            **‚Üí Co-Training KH√îNG ph√π h·ª£p v·ªõi Beijing Air Quality dataset!**
            """)
            
            # Analysis
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown('<div class="exp-card">', unsafe_allow_html=True)
                st.markdown("""
                ### üîç T·∫°i Sao Pollutant-based T·ªët H∆°n Current?
                
                **Pollutant-based (+7.9% vs Current):**
                
                **1. Domain Knowledge:**
                - **View 1**: Primary pollutants (PM2.5, PM10, SO2, CO)
                  - C√πng ngu·ªìn th·∫£i (xe c·ªô, c√¥ng nghi·ªáp)
                  - Correlated patterns
                - **View 2**: Secondary pollutants (NO2, O3)
                  - Ph·∫£n ·ª©ng h√≥a h·ªçc trong kh√≠ quy·ªÉn
                  - Different formation mechanism
                
                **2. View C√≥ Nghƒ©a:**
                - Split theo atmospheric chemistry
                - M·ªói view c√≥ semantic meaning
                - Model h·ªçc domain-specific patterns
                
                **3. Better Balance:**
                - 36-30 features (balanced h∆°n 41-10)
                - C·∫£ 2 views c√≥ ƒë·ªß information
                """)
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="failure-card">', unsafe_allow_html=True)
                st.markdown("""
                ### ‚ùå T·∫°i Sao V·∫´n Thua Self-Training?
                
                **Root Causes:**
                
                **1. Features Highly Correlated:**
                - Primary ‚Üî Secondary pollutants: r = 0.4-0.7
                - C·∫£ 2 t·ª´ c√πng ngu·ªìn (traffic, industry)
                - Split l√†m m·∫•t th√¥ng tin quan tr·ªçng
                
                **2. View Independence Qu√° Th·∫•p (33.3%):**
                - 2 models h·ªçc similar patterns
                - Kh√¥ng ƒë·ªß diverse ƒë·ªÉ correct errors
                - Agreement mechanism fails
                
                **3. Information Loss:**
                - View 1 thi·∫øu NO2, O3 ‚Üí Kh√¥ng predict O3 spike
                - View 2 thi·∫øu PM2.5, PM10 ‚Üí Kh√¥ng predict PM peak
                - Each view "incomplete"
                
                **4. Dataset Characteristics:**
                - Low-dimensional (51 features)
                - Not naturally splittable
                - Better d√πng ALL features (Self-Training)
                """)
                st.markdown('</div>', unsafe_allow_html=True)
            
            # Visualizations
            st.markdown("### üìä Bi·ªÉu ƒê·ªì Tr·ª±c Quan")
            
            col1, col2 = st.columns(2)
            
            with col1:
                img_path = exp_dir / "test_performance_by_strategy.png"
                if img_path.exists():
                    st.image(str(img_path), caption="Test Performance: 2 Strategies", use_container_width=True)
            
            with col2:
                img_path = exp_dir / "view_independence_analysis.png"
                if img_path.exists():
                    st.image(str(img_path), caption="View Independence Analysis", use_container_width=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                img_path = exp_dir / "learning_curves_by_strategy.png"
                if img_path.exists():
                    st.image(str(img_path), caption="Learning Curves", use_container_width=True)
            
            with col2:
                img_path = exp_dir / "comparison_with_baseline.png"
                if img_path.exists():
                    st.image(str(img_path), caption="Comparison with Self-Training", use_container_width=True)
            
            st.error("""
            **‚ùå K·∫øt Lu·∫≠n Experiment 5:**
            - **Pollutant-based t·ªët h∆°n Current** (+7.9%) nh·ªù domain knowledge
            - **NH∆ØNG c·∫£ 2 ƒë·ªÅu THUA Self-Training** (-15.6% v√† -21.8%)
            - **Nguy√™n nh√¢n**: Beijing Air Quality kh√¥ng ph√π h·ª£p cho view splitting
              - Low-dimensional (51 features)
              - Highly correlated features
              - Information loss khi split
            - **Recommendation**: D√πng **Self-Training** thay v√¨ Co-Training!
            - **When Co-Training works**: Text, images, multi-modal data
            """)
        
        else:
            st.error("View splitting data not found")
    
    except Exception as e:
        st.error(f"L·ªói load Experiment 5: {str(e)}")

# ============================================================================
# SUMMARY & RECOMMENDATIONS
# ============================================================================
with tab6:
    st.markdown("## üìù Summary & Recommendations")
    
    st.markdown("### üèÜ X·∫øp H·∫°ng Impact C·ªßa C√°c Y·∫øu T·ªë")
    
    impact_df = pd.DataFrame({
        'Factor': [
            '1. Method Choice (Self vs Co) üî•',
            '2. Model Architecture (HGBC vs RF) üî•',
            '3. Labeled Data Size (5% ‚Üí 10%) üî•',
            '4. Confidence Threshold œÑ',
            '5. View Splitting Strategy',
            '6. Adaptive œÑ Schedule',
            '7. More Labeled (10% ‚Üí 20%)'
        ],
        'Best Config': [
            'Self-Training',
            'HistGradientBoosting',
            '10% labeled',
            'œÑ = 0.90',
            'Pollutant-based (still bad)',
            'Aggressive (0.95‚Üí0.80)',
            'N/A (negative)'
        ],
        'F1 Impact': [
            '+18.5%',
            '+19.1%',
            '+8.1%',
            '+13.3%',
            '-15.6%',
            '+3.4%',
            '-3.1%'
        ],
        'Priority': [
            'CRITICAL ‚≠ê‚≠ê‚≠ê',
            'CRITICAL ‚≠ê‚≠ê‚≠ê',
            'HIGH ‚≠ê‚≠ê',
            'HIGH ‚≠ê‚≠ê',
            'AVOID ‚ùå',
            'LOW ‚≠ê',
            'AVOID ‚ùå'
        ]
    })
    
    st.dataframe(
        impact_df.style.apply(
            lambda x: [
                'background-color: #fee2e2' if 'AVOID' in str(x['Priority'])
                else 'background-color: #d1fae5; font-weight: bold' if 'CRITICAL' in str(x['Priority'])
                else 'background-color: #fef3c7' if 'HIGH' in str(x['Priority'])
                else ''
                for _ in x
            ],
            axis=1
        ),
        use_container_width=True,
        hide_index=True
    )
    
    # Recommendations
    st.markdown("### ‚úÖ C·∫•u H√¨nh Khuy·∫øn Ngh·ªã")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<div class="success-card">', unsafe_allow_html=True)
        st.markdown("""
        ### üéØ Optimal Configuration
        
        **Cho Beijing Air Quality Dataset:**
        
        ```python
        METHOD = "Self-Training"  # NOT Co-Training!
        MODEL = HistGradientBoostingClassifier
        LABELED_FRACTION = 0.10  # 10% (~42K samples)
        TAU = 0.90  # Fixed (ho·∫∑c Aggressive n·∫øu mu·ªën +3.4%)
        MAX_ITER = 10
        EARLY_STOPPING = True  # Stop if Val F1 drop > 5%
        ```
        
        **Expected Performance:**
        - Test F1-Macro: ~0.505-0.534
        - Test Accuracy: ~0.568
        - Pseudo-labels: ~350K (91% unlabeled pool)
        - Training time: ~25-30 minutes
        
        **Key Decisions:**
        1. ‚úÖ Self-Training (NOT Co-Training)
        2. ‚úÖ HGBC (NOT RandomForest)
        3. ‚úÖ 10% labeled (NOT 5% ho·∫∑c 20%)
        4. ‚úÖ œÑ=0.90 (balanced)
        5. ‚úÖ Fixed schedule (simple & effective)
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="exp-card">', unsafe_allow_html=True)
        st.markdown("""
        ### üìö Lessons Learned
        
        **1. Method Choice Is Critical:**
        - Self-Training > Co-Training (+18.5%)
        - Beijing Air Quality: tabular, low-dim, correlated
        - Co-Training c·∫ßn naturally splittable features
        
        **2. Model >> Data >> Hyperparameters:**
        - Model architecture: +19.1% impact
        - Labeled size: +8.1% impact
        - œÑ schedule: +3.4% impact
        - **Invest time in model selection!**
        
        **3. Quality > Quantity:**
        - 10% labeled > 20% labeled (-3.1%)
        - HGBC 346K labels > RF 180K labels
        - œÑ=0.90 > œÑ=0.80 (less noise)
        
        **4. Diminishing Returns Are Real:**
        - 5% ‚Üí 10%: +8.1% ‚úÖ
        - 10% ‚Üí 20%: -3.1% ‚ùå
        - Not always "more is better"
        
        **5. View Independence Matters:**
        - 33.3% independence ‚Üí Co-Training fails
        - Need > 70% for Co-Training to work
        - Check correlation matrix before splitting
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    # When to use what
    st.markdown("### ü§î Decision Tree: Khi N√†o D√πng G√¨?")
    
    st.info("""
    **Flowchart Quy·∫øt ƒê·ªãnh:**
    
    ```
    START: Dataset m·ªõi
    ‚îÇ
    ‚îú‚îÄ Low-dimensional tabular? (< 100 features)
    ‚îÇ  ‚îú‚îÄ YES ‚Üí Features correlated?
    ‚îÇ  ‚îÇ  ‚îú‚îÄ YES ‚Üí Use SELF-TRAINING ‚úÖ
    ‚îÇ  ‚îÇ  ‚îî‚îÄ NO ‚Üí Try CO-TRAINING (test independence first)
    ‚îÇ  ‚îî‚îÄ NO ‚Üí High-dimensional
    ‚îÇ     ‚îî‚îÄ Naturally splittable? (text, images)
    ‚îÇ        ‚îú‚îÄ YES ‚Üí Use CO-TRAINING ‚úÖ
    ‚îÇ        ‚îî‚îÄ NO ‚Üí Use SELF-TRAINING ‚úÖ
    ‚îÇ
    ‚îú‚îÄ Model choice?
    ‚îÇ  ‚îú‚îÄ Need probability calibration? ‚Üí HGBC ‚úÖ
    ‚îÇ  ‚îî‚îÄ Speed important? ‚Üí RandomForest (accept lower F1)
    ‚îÇ
    ‚îú‚îÄ Labeled data?
    ‚îÇ  ‚îú‚îÄ < 5%: Risk of weak base model
    ‚îÇ  ‚îú‚îÄ 5-15%: Sweet spot ‚úÖ
    ‚îÇ  ‚îî‚îÄ > 20%: Diminishing return, consider supervised
    ‚îÇ
    ‚îî‚îÄ Confidence threshold?
       ‚îú‚îÄ Start with œÑ=0.90 ‚úÖ
       ‚îú‚îÄ If Val F1 drop early ‚Üí increase œÑ to 0.95
       ‚îî‚îÄ If not enough pseudo-labels ‚Üí decrease œÑ to 0.85
    ```
    """)
    
    st.success("""
    **‚úÖ Final Recommendation Cho Beijing Air Quality:**
    
    **Best Configuration:**
    - Method: **Self-Training** (NOT Co-Training)
    - Model: **HistGradientBoostingClassifier**
    - Labeled: **10%** (~42K samples)
    - œÑ: **0.90** (Fixed schedule)
    - Expected F1: **0.50-0.53** (+7-13% vs baseline)
    
    **Why This Works:**
    1. Self-Training s·ª≠ d·ª•ng ALL 51 features ‚Üí no information loss
    2. HGBC c√≥ probability calibration t·ªët ‚Üí high-quality pseudo-labels
    3. 10% labeled: balance gi·ªØa model strength v√† unlabeled utilization
    4. œÑ=0.90: optimal trade-off quality vs quantity
    
    **Implementation Priority:**
    1. ‚≠ê‚≠ê‚≠ê Choose Self-Training over Co-Training
    2. ‚≠ê‚≠ê‚≠ê Use HistGradientBoosting over RandomForest
    3. ‚≠ê‚≠ê Collect 10% labeled data (not more, not less)
    4. ‚≠ê‚≠ê Set œÑ=0.90 and monitor Val F1
    5. ‚≠ê (Optional) Try Aggressive œÑ schedule for +3.4% gain
    
    **Avoid:**
    - ‚ùå Co-Training for this dataset (view splitting fails)
    - ‚ùå RandomForest (poor probability calibration)
    - ‚ùå 20%+ labeled data (diminishing return)
    - ‚ùå œÑ < 0.85 (too much noise)
    """)

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #64748b; padding: 1rem;'>
    <p style='font-weight: 500; color: #0369a1;'>Y√™u C·∫ßu 3 Ho√†n Th√†nh | 5/5 Experiments Done | Best: Self-Training + HGBC + 10% + œÑ=0.90 | F1=0.50-0.53</p>
</div>
""", unsafe_allow_html=True)

