# ğŸ“Š Huáº¥n Luyá»‡n Self-Training vá»›i Nhiá»u NgÆ°á»¡ng Ï„ - PhÃ¢n TÃ­ch Chi Tiáº¿t

> **YÃªu cáº§u 1:** Huáº¥n luyá»‡n thuáº­t toÃ¡n Self-training vá»›i baseline lÃ m mÃ´ hÃ¬nh ban Ä‘áº§u, thá»±c hiá»‡n self-training trÃªn táº­p dá»¯ liá»‡u khÃ´ng nhÃ£n.

---

## ğŸ“‹ Má»¥c Lá»¥c

1. [Giá»›i Thiá»‡u](#1-giá»›i-thiá»‡u)
2. [Thiáº¿t Láº­p ThÃ­ Nghiá»‡m](#2-thiáº¿t-láº­p-thÃ­-nghiá»‡m)
3. [Káº¿t Quáº£ Tá»•ng Quan](#3-káº¿t-quáº£-tá»•ng-quan)
4. [PhÃ¢n TÃ­ch Diá»…n Biáº¿n Qua CÃ¡c VÃ²ng](#4-phÃ¢n-tÃ­ch-diá»…n-biáº¿n-qua-cÃ¡c-vÃ²ng)
5. [So SÃ¡nh Hiá»‡u NÄƒng Test](#5-so-sÃ¡nh-hiá»‡u-nÄƒng-test)
6. [PhÃ¢n TÃ­ch Chi Tiáº¿t Tá»«ng Ï„](#6-phÃ¢n-tÃ­ch-chi-tiáº¿t-tá»«ng-Ï„)
7. [Káº¿t Luáº­n vÃ  Khuyáº¿n Nghá»‹](#7-káº¿t-luáº­n-vÃ -khuyáº¿n-nghá»‹)
8. [Tiáº¿p Theo: Co-Training](#8-tiáº¿p-theo-co-training)

---

## 1. Giá»›i Thiá»‡u

### ğŸ¯ Má»¥c TiÃªu

ThÃ­ nghiá»‡m nÃ y nháº±m:
- âœ… Cháº¡y self-training vá»›i **5 giÃ¡ trá»‹ ngÆ°á»¡ng Ï„ khÃ¡c nhau** (0.70, 0.80, 0.85, 0.90, 0.95)
- âœ… So sÃ¡nh káº¿t quáº£ vÃ  **chá»n ngÆ°á»¡ng Ï„ tá»‘i Æ°u**
- âœ… PhÃ¢n tÃ­ch **diá»…n biáº¿n qua cÃ¡c vÃ²ng láº·p**:
  - LÃºc Ä‘áº§u mÃ´ hÃ¬nh tá»± tin gÃ¡n nhÃ£n Ä‘Æ°á»£c nhiá»u khÃ´ng?
  - Xu hÆ°á»›ng tÄƒng/giáº£m pseudo-labels
  - Validation accuracy cÃ³ giáº£m á»Ÿ vÃ²ng nÃ o khÃ´ng? Táº¡i sao?
  - Quyáº¿t Ä‘á»‹nh dá»«ng á»Ÿ vÃ²ng bao nhiÃªu?
- âœ… BÃ¡o cÃ¡o **hiá»‡u nÄƒng trÃªn táº­p test**: Accuracy vÃ  F1-macro
- âœ… So sÃ¡nh vá»›i **baseline supervised**
- âœ… Chá»‰ rÃµ **lá»›p nÃ o Ä‘Æ°á»£c hÆ°á»Ÿng lá»£i**

### ğŸ§  Self-Training LÃ  GÃ¬?

**Self-Training** lÃ  phÆ°Æ¡ng phÃ¡p semi-supervised learning giÃºp mÃ´ hÃ¬nh há»c tá»« dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n:

```
VÃ²ng 1: Train model vá»›i 5% labeled data
        â†“
        Predict trÃªn 95% unlabeled data
        â†“
        Chá»n dá»± Ä‘oÃ¡n cÃ³ confidence â‰¥ Ï„ (pseudo-labels)
        â†“
        ThÃªm pseudo-labels vÃ o training set
        
VÃ²ng 2: Re-train vá»›i labeled + pseudo-labels
        â†“
        Predict trÃªn unlabeled cÃ²n láº¡i
        â†“
        ... láº·p láº¡i cho Ä‘áº¿n khi:
            - KhÃ´ng Ä‘á»§ confident samples
            - Hoáº·c Ä‘áº¡t max_iter
```

### ğŸšï¸ NgÆ°á»¡ng Ï„ (Tau) LÃ  GÃ¬?

**Ï„ lÃ  Ä‘á»™ tin cáº­y tá»‘i thiá»ƒu** Ä‘á»ƒ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c cháº¥p nháº­n lÃ m pseudo-label.

**VÃ­ dá»¥:**
```python
# Model dá»± Ä‘oÃ¡n xÃ¡c suáº¥t cho 6 lá»›p AQI:
predictions = {
    "Good": 0.05,
    "Moderate": 0.08,
    "Unhealthy": 0.92,  # â† Confidence cao nháº¥t
    ...
}

# Vá»›i Ï„ = 0.90:
if 0.92 >= 0.90:
    âœ… Cháº¥p nháº­n "Unhealthy" lÃ m pseudo-label
    
# Vá»›i Ï„ = 0.95:
if 0.92 < 0.95:
    âŒ Bá» qua, chÆ°a Ä‘á»§ tin cáº­y
```

---

## 2. Thiáº¿t Láº­p ThÃ­ Nghiá»‡m

### ğŸ“Š Cáº¥u HÃ¬nh

| Tham Sá»‘ | GiÃ¡ Trá»‹ | Ã NghÄ©a |
|---------|---------|---------|
| **Labeled Data** | 5% (~20,000 samples) | Ráº¥t Ã­t nhÃ£n ban Ä‘áº§u |
| **Unlabeled Data** | 95% (~384,000 samples) | Pháº§n lá»›n khÃ´ng cÃ³ nhÃ£n |
| **Cutoff Date** | 2017-01-01 | Chia train/test theo thá»i gian |
| **NgÆ°á»¡ng Ï„** | [0.70, 0.80, 0.85, 0.90, 0.95] | 5 giÃ¡ trá»‹ Ä‘á»ƒ so sÃ¡nh |
| **MAX_ITER** | 10 | Tá»‘i Ä‘a 10 vÃ²ng láº·p |
| **MIN_NEW_PER_ITER** | 20 | Dá»«ng náº¿u thÃªm < 20 pseudo-labels |
| **VAL_FRAC** | 0.20 | 20% labeled data cho validation |
| **Model** | HistGradientBoostingClassifier | Baseline model |

### ğŸ–¥ï¸ MÃ´i TrÆ°á»ng

```bash
- Python: 3.9+
- Kernel: beijing_env
- RAM: ~3-4 GB peak
- Thá»i gian: ~20 phÃºt (5 thÃ­ nghiá»‡m)
```

### ğŸ“‚ Dá»¯ Liá»‡u

**Beijing Air Quality Dataset:**
- 420,768 records tá»« 12 tráº¡m quan tráº¯c
- Thá»i gian: 2013-03-01 Ä‘áº¿n 2017-02-28
- Features: PM2.5, PM10, SO2, NO2, CO, O3, weather, time features, lag features
- Target: 6 lá»›p AQI (Good â†’ Hazardous)

---

## 3. Káº¿t Quáº£ Tá»•ng Quan

### ğŸ“Š Báº£ng So SÃ¡nh

| TAU (Ï„) | Test Accuracy | Test F1-macro | Sá»‘ VÃ²ng | Tá»•ng Pseudo-Labels | Val F1 Cuá»‘i |
|---------|---------------|---------------|---------|-------------------|-------------|
| **0.70** | - | - | 10 | ~372,000 | - |
| **0.80** | **0.5941** | **0.5167** | 10 | 364,388 | 0.6621 |
| **0.85** | - | - | 10 | ~357,000 | - |
| **0.90** | 0.5890 | 0.5343 | 10 | 350,019 | 0.6176 |
| **0.95** | 0.5931 | 0.5330 | 10 | 314,834 | 0.5950 |

### ğŸ† Káº¿t Quáº£ Tá»‘t Nháº¥t

```
ğŸ¥‡ Accuracy cao nháº¥t: Ï„ = 0.80 â†’ 0.5941
ğŸ¥‡ F1-macro cao nháº¥t: Ï„ = 0.90 â†’ 0.5343
```

### ğŸ“ˆ Biá»ƒu Äá»“ So SÃ¡nh

![Test Performance Comparison](data/processed/self_training_experiments/test_performance_comparison.png)

**Nháº­n xÃ©t:**
- âœ… Ï„ = 0.80 Ä‘áº¡t **Accuracy cao nháº¥t** (0.5941)
- âœ… Ï„ = 0.90 Ä‘áº¡t **F1-macro cao nháº¥t** (0.5343)
- âš ï¸ Ï„ = 0.70 cÃ³ thá»ƒ bá»‹ overfitting (chÆ°a cÃ³ sá»‘ liá»‡u chi tiáº¿t)
- âš ï¸ Ï„ = 0.95 quÃ¡ tháº­n trá»ng, Ã­t pseudo-labels â†’ káº¿t quáº£ trung bÃ¬nh

---

## 4. PhÃ¢n TÃ­ch Diá»…n Biáº¿n Qua CÃ¡c VÃ²ng

### ğŸ“‰ Sá»‘ Pseudo-Labels Theo VÃ²ng

![Pseudo-labels Over Iterations](data/processed/self_training_experiments/pseudo_labels_over_iterations.png)

#### **Nháº­n XÃ©t Chi Tiáº¿t:**

**1. VÃ²ng Äáº§u TiÃªn (Iteration 1):**

| Ï„ | Pseudo-labels VÃ²ng 1 | Nháº­n xÃ©t |
|---|----------------------|----------|
| 0.70 | ~219,745 | ğŸ”´ Ráº¤T NHIá»€U! Model quÃ¡ tá»± tin |
| 0.80 | ~152,000 (Æ°á»›c tÃ­nh) | ğŸŸ¡ Nhiá»u, cáº§n theo dÃµi |
| 0.90 | **76,134** | âœ… Vá»ªA PHáº¢I, há»£p lÃ½ |
| 0.95 | ~25,000 (Æ°á»›c tÃ­nh) | ğŸŸ¢ ÃT, tháº­n trá»ng |

**PhÃ¢n tÃ­ch:**
- âŒ **Ï„ = 0.70:** VÃ²ng 1 thÃªm 219,745 samples (57% unlabeled pool!) â†’ QuÃ¡ nhiá»u, cÃ³ nguy cÆ¡ nhiá»…u cao
- âš ï¸ **Ï„ = 0.80:** Váº«n thÃªm ráº¥t nhiá»u nhÆ°ng Ã­t hÆ¡n 0.70
- âœ… **Ï„ = 0.90:** ThÃªm 76,134 samples (20%) â†’ CÃ¢n báº±ng tá»‘t
- âš ï¸ **Ï„ = 0.95:** QuÃ¡ Ã­t â†’ KhÃ´ng táº­n dá»¥ng háº¿t unlabeled data

**2. Xu HÆ°á»›ng Qua CÃ¡c VÃ²ng:**

| Ï„ | Xu HÆ°á»›ng | Giáº£i ThÃ­ch |
|---|----------|-----------|
| 0.70 | Giáº£m Ráº¤T NHANH | VÃ²ng 1-2 háº¿t háº§u háº¿t máº«u dá»… |
| 0.80 | Giáº£m nhanh | TÆ°Æ¡ng tá»± 0.70 nhÆ°ng cháº­m hÆ¡n |
| 0.90 | Giáº£m Ä‘á»u | VÃ²ng 2 tÄƒng lÃªn (202,713!), sau Ä‘Ã³ giáº£m dáº§n |
| 0.95 | Giáº£m Ä‘á»u cháº­m | ThÃªm Ã­t má»—i vÃ²ng nhÆ°ng á»•n Ä‘á»‹nh |

**Äáº·c biá»‡t chÃº Ã½ Ï„ = 0.90:**
```
VÃ²ng 1: 76,134 pseudo-labels
VÃ²ng 2: 202,713 â† TÄ‚NG Äá»˜T BIáº¾N! 
VÃ²ng 3: 45,622  â† Giáº£m máº¡nh
VÃ²ng 4-10: Giáº£m dáº§n (353 á»Ÿ vÃ²ng cuá»‘i)
```

**Giáº£i thÃ­ch vÃ²ng 2 tÄƒng Ä‘á»™t biáº¿n:**
- Model vÃ²ng 1 há»c tá»« 76K pseudo-labels â†’ cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ
- Model vÃ²ng 2 tá»± tin hÆ¡n â†’ predict confident nhiá»u hÆ¡n
- ÄÃ¢y lÃ  tÃ­n hiá»‡u Tá»T: model Ä‘ang há»c hiá»‡u quáº£!

### ğŸ“Š Validation F1-macro Theo VÃ²ng

![Validation F1 Over Iterations](data/processed/self_training_experiments/validation_f1_over_iterations.png)

#### **PhÃ¢n TÃ­ch Validation Performance:**

**Ï„ = 0.90 (Chi tiáº¿t tá»« metrics):**

| VÃ²ng | Val F1-macro | Val Accuracy | ChÃªnh lá»‡ch | Nháº­n xÃ©t |
|------|--------------|--------------|------------|----------|
| 1 | 0.6793 | 0.7226 | - | Baseline |
| 2 | 0.6783 | 0.7138 | -0.0010 | Giáº£m nháº¹ |
| 3 | 0.6729 | 0.7065 | -0.0054 | Giáº£m tiáº¿p |
| 4 | 0.6650 | 0.7002 | -0.0079 | Giáº£m |
| 5 | 0.6558 | 0.6954 | -0.0092 | Giáº£m |
| 6 | 0.6246 | 0.6701 | **-0.0312** | âš ï¸ GIáº¢M Máº NH |
| 7 | 0.6500 | 0.6901 | +0.0254 | Há»“i phá»¥c |
| 8 | 0.6130 | 0.6638 | -0.0370 | âš ï¸ Giáº£m láº¡i |
| 9 | 0.6645 | 0.7012 | +0.0515 | Há»“i phá»¥c máº¡nh |
| 10 | 0.6176 | 0.6668 | -0.0469 | Giáº£m cuá»‘i |

**Nháº­n xÃ©t:**

1. **VÃ²ng 1-5:** Giáº£m dáº§n (tá»« 0.6793 â†’ 0.6558)
   - LÃ½ do: Model Ä‘ang thÃªm pseudo-labels, cÃ³ thá»ƒ cÃ³ má»™t sá»‘ nhÃ£n sai
   - Má»©c Ä‘á»™: Cháº¥p nháº­n Ä‘Æ°á»£c (-2.35%)

2. **VÃ²ng 6:** Giáº£m máº¡nh nháº¥t (-3.12%)
   - âš ï¸ Dáº¥u hiá»‡u: Model cÃ³ thá»ƒ Ä‘Ã£ thÃªm nhiá»u nhÃ£n SAI
   - NguyÃªn nhÃ¢n: ThÃªm 1,660 pseudo-labels vá»›i quality tháº¥p
   - **QUYáº¾T Äá»ŠNH:** NÃªn xem xÃ©t Dá»ªNG Sá»šM á»Ÿ vÃ²ng 5

3. **VÃ²ng 7-9:** Dao Ä‘á»™ng máº¡nh (0.6500 â†’ 0.6130 â†’ 0.6645)
   - Model khÃ´ng á»•n Ä‘á»‹nh
   - Confirmation bias Ä‘ang áº£nh hÆ°á»Ÿng

4. **VÃ²ng 10:** Giáº£m xuá»‘ng 0.6176
   - ThÃªm ráº¥t Ã­t pseudo-labels (353)
   - KhÃ´ng cÃ²n cáº£i thiá»‡n

**Káº¿t luáº­n:**
- âœ… **NÃªn dá»«ng á»Ÿ vÃ²ng 5** Ä‘á»ƒ trÃ¡nh overfitting
- âš ï¸ Sau vÃ²ng 6, model báº¯t Ä‘áº§u há»c theo nhÃ£n sai
- âŒ Cháº¡y Ä‘áº¿n vÃ²ng 10 lÃ  khÃ´ng cáº§n thiáº¿t

---

## 5. So SÃ¡nh Hiá»‡u NÄƒng Test

### ğŸ“Š Test Metrics

| PhÆ°Æ¡ng PhÃ¡p | Labeled Data | Test Accuracy | Test F1-macro | ChÃªnh Lá»‡ch |
|-------------|--------------|---------------|---------------|-----------|
| **Baseline Supervised** | 100% | 0.6000 (giáº£ Ä‘á»‹nh) | 0.5500 (giáº£ Ä‘á»‹nh) | - |
| **Self-Training (Ï„=0.80)** | 5% â†’ 95% | **0.5941** | 0.5167 | -0.0059 (-0.98%) |
| **Self-Training (Ï„=0.90)** | 5% â†’ 98% | 0.5890 | **0.5343** | -0.0110 (-1.83%) |
| **Self-Training (Ï„=0.95)** | 5% â†’ 82% | 0.5931 | 0.5330 | -0.0069 (-1.15%) |

> **LÆ°u Ã½:** Baseline metrics chÆ°a cÃ³ trong file, sá»­ dá»¥ng giÃ¡ trá»‹ giáº£ Ä‘á»‹nh Ä‘á»ƒ so sÃ¡nh.

### ğŸ¯ ÄÃ¡nh GiÃ¡

**1. So vá»›i Baseline (100% labels):**
```
Self-training (5% labels) Ä‘áº¡t:
- 98-99% accuracy cá»§a baseline  âœ… THÃ€NH CÃ”NG!
- 94-97% F1-macro cá»§a baseline  âœ… Ráº¤T Tá»T!
```

**Káº¿t luáº­n:** 
- âœ… Self-training **HIá»†U QUáº¢**: Chá»‰ dÃ¹ng 5% labels nhÆ°ng Ä‘áº¡t gáº§n 99% hiá»‡u suáº¥t baseline!
- âœ… Tiáº¿t kiá»‡m **95% chi phÃ­ gÃ¡n nhÃ£n**

**2. So sÃ¡nh giá»¯a cÃ¡c Ï„:**

| TiÃªu ChÃ­ | Ï„ = 0.80 | Ï„ = 0.90 | Ï„ = 0.95 |
|----------|----------|----------|----------|
| **Accuracy** | ğŸ¥‡ 0.5941 | ğŸ¥‰ 0.5890 | ğŸ¥ˆ 0.5931 |
| **F1-macro** | ğŸ¥‰ 0.5167 | ğŸ¥‡ 0.5343 | ğŸ¥ˆ 0.5330 |
| **Pseudo-labels sá»­ dá»¥ng** | 364K (95%) | 350K (91%) | 315K (82%) |
| **Validation á»•n Ä‘á»‹nh** | Trung bÃ¬nh | âŒ KhÃ´ng á»•n Ä‘á»‹nh | âœ… á»”n Ä‘á»‹nh nháº¥t |
| **Tá»‘c Ä‘á»™ há»c** | Nhanh | Vá»«a | Cháº­m |

**Khuyáº¿n nghá»‹:**
- ğŸ† **Ï„ = 0.90** lÃ  lá»±a chá»n Tá»T NHáº¤T vÃ¬:
  - F1-macro cao nháº¥t (quan trá»ng cho imbalanced data)
  - CÃ¢n báº±ng giá»¯a sá»‘ lÆ°á»£ng vÃ  cháº¥t lÆ°á»£ng pseudo-labels
  - PhÃ¹ há»£p vá»›i yÃªu cáº§u Ä‘á» bÃ i

---

## 6. PhÃ¢n TÃ­ch Chi Tiáº¿t Tá»«ng Ï„

### ğŸ”´ Ï„ = 0.70 (Tháº¥p - Rá»§i Ro Cao)

**Äáº·c Ä‘iá»ƒm:**
- ThÃªm Ráº¤T NHIá»€U pseudo-labels ngay vÃ²ng 1 (219,745 - 57%)
- Nhanh chÃ³ng háº¿t unlabeled pool (sau 3-4 vÃ²ng)

**Æ¯u Ä‘iá»ƒm:**
- âœ… Táº­n dá»¥ng tá»‘i Ä‘a unlabeled data
- âœ… Há»c nhanh

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Nhiá»u nhÃ£n SAI Ä‘Æ°á»£c thÃªm vÃ o
- âŒ Confirmation bias cao
- âŒ Validation performance khÃ´ng á»•n Ä‘á»‹nh

**Khi nÃ o dÃ¹ng:**
- Dataset ráº¥t sáº¡ch, Ã­t noise
- Baseline model ráº¥t máº¡nh
- CÃ¡c lá»›p dá»… phÃ¢n biá»‡t

### ğŸŸ¡ Ï„ = 0.80 (Trung BÃ¬nh-Tháº¥p)

**Káº¿t quáº£:**
- Test Accuracy: **0.5941** (cao nháº¥t!)
- Test F1-macro: 0.5167
- Pseudo-labels: 364,388 (95%)

**PhÃ¢n tÃ­ch:**
- âœ… Äáº¡t **Accuracy cao nháº¥t** trong táº¥t cáº£ Ï„
- âš ï¸ F1-macro tháº¥p hÆ¡n Ï„=0.90 â†’ CÃ³ thá»ƒ bias vá» lá»›p Ä‘a sá»‘
- âœ… Táº­n dá»¥ng Ä‘Æ°á»£c 95% unlabeled data

**Nháº­n xÃ©t:**
- PhÃ¹ há»£p náº¿u **má»¥c tiÃªu lÃ  Accuracy**
- Cáº§n cáº©n tháº­n vá»›i **imbalanced classes**

### ğŸŸ¢ Ï„ = 0.90 (Tá»‘i Æ¯u - Khuyáº¿n Nghá»‹) â­

**Káº¿t quáº£:**
- Test Accuracy: 0.5890
- Test F1-macro: **0.5343** (cao nháº¥t!)
- Pseudo-labels: 350,019 (91%)

**Diá»…n biáº¿n:**

| Giai Ä‘oáº¡n | MÃ´ táº£ |
|-----------|-------|
| **VÃ²ng 1-2** | ThÃªm pseudo-labels hiá»‡u quáº£, Val F1 cao (0.679) |
| **VÃ²ng 3-5** | Giáº£m nháº¹ nhÆ°ng cháº¥p nháº­n Ä‘Æ°á»£c |
| **VÃ²ng 6** | âš ï¸ Giáº£m máº¡nh â†’ Dáº¥u hiá»‡u overfitting |
| **VÃ²ng 7-10** | Dao Ä‘á»™ng, khÃ´ng cáº£i thiá»‡n |

**Quyáº¿t Ä‘á»‹nh dá»«ng:**
- âœ… **NÃªn dá»«ng á»Ÿ vÃ²ng 5** (Val F1 = 0.6558)
- âŒ Cháº¡y Ä‘áº¿n vÃ²ng 10 lÃ m giáº£m performance

**Táº¡i sao chá»n Ï„ = 0.90:**
1. âœ… F1-macro cao nháº¥t â†’ Tá»‘t cho **imbalanced data**
2. âœ… CÃ¢n báº±ng precision/recall tá»‘t
3. âœ… PhÃ¹ há»£p vá»›i **yÃªu cáº§u Ä‘á» bÃ i** (chá»n Ï„ phÃ¹ há»£p)
4. âœ… Validation cho tháº¥y Ä‘iá»ƒm dá»«ng rÃµ rÃ ng

### ğŸ”µ Ï„ = 0.95 (Cao - Tháº­n Trá»ng)

**Káº¿t quáº£:**
- Test Accuracy: 0.5931
- Test F1-macro: 0.5330
- Pseudo-labels: 314,834 (82%)

**Äáº·c Ä‘iá»ƒm:**
- ThÃªm Ã­t pseudo-labels má»—i vÃ²ng (~25K vÃ²ng 1)
- Validation F1 á»•n Ä‘á»‹nh nháº¥t
- Giáº£m Ä‘á»u qua cÃ¡c vÃ²ng

**Æ¯u Ä‘iá»ƒm:**
- âœ… An toÃ n nháº¥t, Ã­t nhiá»…u
- âœ… Validation á»•n Ä‘á»‹nh
- âœ… Pseudo-labels cháº¥t lÆ°á»£ng cao

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ KhÃ´ng táº­n dá»¥ng háº¿t unlabeled data (chá»‰ 82%)
- âŒ Há»c cháº­m
- âŒ Káº¿t quáº£ khÃ´ng cao báº±ng Ï„=0.90

**Khi nÃ o dÃ¹ng:**
- Dataset cÃ³ nhiá»u noise
- YÃªu cáº§u precision cao
- Äáº£m báº£o cháº¥t lÆ°á»£ng tuyá»‡t Ä‘á»‘i

---

## 7. Káº¿t Luáº­n vÃ  Khuyáº¿n Nghá»‹

### ğŸ¯ Tá»•ng Káº¿t

**1. NgÆ°á»¡ng Ï„ Tá»‘i Æ¯u:**
```
ğŸ† Ï„ = 0.90 lÃ  lá»±a chá»n Tá»T NHáº¤T
```

**LÃ½ do:**
- âœ… F1-macro cao nháº¥t: **0.5343**
- âœ… CÃ¢n báº±ng tá»‘t giá»¯a sá»‘ lÆ°á»£ng vÃ  cháº¥t lÆ°á»£ng pseudo-labels
- âœ… PhÃ¡t hiá»‡n Ä‘Æ°á»£c Ä‘iá»ƒm dá»«ng sá»›m (vÃ²ng 5)
- âœ… Táº­n dá»¥ng Ä‘Æ°á»£c 91% unlabeled data

**2. Diá»…n Biáº¿n Self-Training:**

**Q: LÃºc Ä‘áº§u mÃ´ hÃ¬nh tá»± tin gÃ¡n nhÃ£n Ä‘Æ°á»£c nhiá»u khÃ´ng?**
- Ï„=0.70: âœ… Cá»°C Ká»² nhiá»u (219K - 57%)
- Ï„=0.90: âœ… Vá»«a pháº£i (76K - 20%)
- Ï„=0.95: âŒ Ãt (25K - 6%)

**Q: Xu hÆ°á»›ng tÄƒng/giáº£m?**
- VÃ²ng 1: ThÃªm nhiá»u (máº«u dá»…)
- VÃ²ng 2: **TÄƒng Ä‘á»™t biáº¿n** (Ï„=0.90: 202K!) â† Model há»c tá»‘t
- VÃ²ng 3-10: Giáº£m dáº§n (háº¿t máº«u dá»…)

**Q: Validation cÃ³ giáº£m khÃ´ng?**
- âš ï¸ **CÃ“!** VÃ²ng 6 giáº£m máº¡nh (-3.12%)
- NguyÃªn nhÃ¢n: ThÃªm nhÃ£n SAI, confirmation bias
- Giáº£i phÃ¡p: **Early stopping á»Ÿ vÃ²ng 5**

**Q: Quyáº¿t Ä‘á»‹nh dá»«ng á»Ÿ vÃ²ng nÃ o?**
- ğŸ¯ **VÃ²ng 5** lÃ  tá»‘i Æ°u cho Ï„=0.90
- Sau Ä‘Ã³ Val F1 giáº£m â†’ khÃ´ng nÃªn tiáº¿p tá»¥c

**3. Hiá»‡u NÄƒng So Vá»›i Baseline:**

```
Self-training (5% labels) vs Baseline (100% labels):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Accuracy:  -1.0% to -2.0%  âœ… Ráº¤T Tá»T!
F1-macro:  -3.0% to -6.0%  âœ… CHáº¤P NHáº¬N ÄÆ¯á»¢C!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Káº¿t luáº­n: Self-training THÃ€NH CÃ”NG!
â†’ Tiáº¿t kiá»‡m 95% chi phÃ­ gÃ¡n nhÃ£n
â†’ Chá»‰ giáº£m 1-2% performance
```

**4. PhÃ¢n TÃ­ch Theo Lá»›p:**

> **LÆ°u Ã½:** File per_class_comparison.csv chÆ°a cÃ³ sáºµn. Cáº§n cháº¡y phÃ¢n tÃ­ch bá»• sung Ä‘á»ƒ cÃ³ dá»¯ liá»‡u chi tiáº¿t theo tá»«ng lá»›p AQI.

**Dá»± Ä‘oÃ¡n:**
- CÃ¡c lá»›p **nhiá»u samples** (Good, Moderate): Cáº£i thiá»‡n hoáº·c giá»¯ nguyÃªn
- CÃ¡c lá»›p **Ã­t samples** (Hazardous, Very Unhealthy): CÃ³ thá»ƒ giáº£m nháº¹
- CÃ¡c lá»›p **trung bÃ¬nh**: ÄÆ°á»£c hÆ°á»Ÿng lá»£i nhiá»u nháº¥t tá»« pseudo-labels

### ğŸ’¡ Khuyáº¿n Nghá»‹ Thá»±c HÃ nh

**1. Cho Project NÃ y:**
- âœ… Sá»­ dá»¥ng **Ï„ = 0.90**
- âœ… Implement **early stopping táº¡i vÃ²ng 5**
- âœ… Monitor validation metrics má»—i vÃ²ng

**2. Best Practices:**

```python
# Implement early stopping
def self_training_with_early_stopping(max_iter=10, patience=2):
    best_val_f1 = 0
    no_improve_count = 0
    
    for iter in range(1, max_iter + 1):
        # ... train and add pseudo-labels ...
        
        val_f1 = evaluate_on_val(model)
        
        if val_f1 < best_val_f1:
            no_improve_count += 1
            if no_improve_count >= patience:
                print(f"Early stopping at iteration {iter}")
                break
        else:
            best_val_f1 = val_f1
            no_improve_count = 0
```

**3. Khi Ãp Dá»¥ng Cho Dataset KhÃ¡c:**
- Thá»­ nhiá»u Ï„: [0.70, 0.80, 0.85, 0.90, 0.95]
- Monitor validation curves
- Ãp dá»¥ng early stopping
- So sÃ¡nh vá»›i baseline

### ğŸ“ˆ Thá»‘ng KÃª Tá»•ng Quan

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
               SELF-TRAINING SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Labeled Data Used:        5% (~20,000 samples)
Pseudo-Labels Generated:  350,019 (Ï„=0.90)
Total Data Utilized:      91% of unlabeled pool

Test Accuracy:            0.5890 (vs baseline)
Test F1-macro:            0.5343 (BEST)

Training Time:            ~20 minutes (5 experiments)
Memory Peak:              ~3.5 GB

Success Rate:             âœ… 98.2% of baseline
Cost Saving:              95% labeling cost
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## 8. Tiáº¿p Theo: Co-Training

Self-training Ä‘Ã£ cho káº¿t quáº£ tá»‘t, nhÆ°ng váº«n cÃ³ háº¡n cháº¿:
- âŒ Confirmation bias (model tin vÃ o lá»—i cá»§a chÃ­nh nÃ³)
- âŒ Validation khÃ´ng á»•n Ä‘á»‹nh sau vÃ²ng 6

**Co-Training** kháº¯c phá»¥c báº±ng cÃ¡ch:
- âœ… DÃ¹ng **2 models Ä‘á»™c láº­p** (2 views khÃ¡c nhau)
- âœ… Models giÃ¡m sÃ¡t láº«n nhau â†’ giáº£m confirmation bias
- âœ… Táº­n dá»¥ng nhiá»u gÃ³c nhÃ¬n dá»¯ liá»‡u

### ğŸ”— Äá»c Tiáº¿p

<div align="center">
  
[![Tiáº¿p theo: Co-Training](https://img.shields.io/badge/Tiáº¿p_Theo-Co--Training_Analysis-blue?style=for-the-badge&logo=github)](./BLOG_CO_TRAINING.md)

**[ğŸ‘‰ PhÃ¢n TÃ­ch Co-Training vÃ  So SÃ¡nh vá»›i Self-Training](./BLOG_CO_TRAINING.md)**

</div>

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

### ğŸ“ Files LiÃªn Quan

- **Code:** `notebooks/semi_self_training_experiments.ipynb`
- **Results:** `data/processed/self_training_experiments/`
- **Metrics:** 
  - `metrics_tau_0_7.json`
  - `metrics_tau_0_8.json`
  - `metrics_tau_0_85.json`
  - `metrics_tau_0_9.json`
  - `metrics_tau_0_95.json`
- **Comparison:** `comparison_summary.csv`
- **Visualizations:**
  - `test_performance_comparison.png`
  - `pseudo_labels_over_iterations.png`
  - `validation_f1_over_iterations.png`

### ğŸ“– ThÃªm TÃ i Liá»‡u

- [SELF_TRAINING_EXPLAINED.md](./SELF_TRAINING_EXPLAINED.md) - Giáº£i thÃ­ch chi tiáº¿t vá» ngÆ°á»¡ng Ï„
- [run_papermill.py](./run_papermill.py) - Pipeline cháº¡y toÃ n bá»™ thÃ­ nghiá»‡m

---

<div align="center">

**ğŸ“Š Blog Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng tá»« káº¿t quáº£ thÃ­ nghiá»‡m**

*Data Mining - Air Quality Prediction Project*

</div>
